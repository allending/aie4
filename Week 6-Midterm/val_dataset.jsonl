{"questions": {"1efe4649-d959-46a1-a517-efb44e58febe": "What types of attacks are assessed during AI red-teaming according to the context provided?", "50d04a58-3bbf-4766-b3c3-82a690043aef": "How does fine-tuning relate to safety and security controls in the context of information integrity?", "103690df-97c0-4f4f-bfe1-d5e702effc8b": "What factors should be considered when identifying the intended purposes of an AI system according to MAP 11?", "623ab973-898d-4565-a09b-66e2424a85b4": "How does MAP 11 suggest addressing the potential positive and negative impacts of AI system uses?", "4a661925-37ef-4ff5-8520-042fe69fe7c4": "What are the key aspects to review and document regarding data used in the AI life cycle according to MP-23-002?", "34034c8d-3d4d-40d5-a2f1-a68dd8476c71": "What techniques should be deployed to verify the accuracy of information generated by GAI systems as outlined in MP-23-003?", "00caf438-e3a3-441e-8a81-b3659477b7d8": "What types of groups are suggested to be defined for gathering structured public feedback in the context of GAI technology?", "d1ca04f1-6310-499e-90ac-3982f89b8fe5": "What actions are recommended for engaging in evaluations and assessments related to GAI risks?", "4494b781-f5a3-40c6-a878-36c682a00f79": "How do GAI systems contribute to the unintentional production of misinformation?", "98de0988-9c71-43ff-ac6b-59af9a5dbf73": "In what ways can GAI systems facilitate the deliberate dissemination of disinformation by malicious actors?", "a00352d9-ebc7-4725-9aaa-d4d4f23a55c4": "What are the potential risks associated with the emotional entanglement and aversion in the context of GAI systems?", "fa4044ce-af4c-4603-af05-d016e7ae157c": "How might the deployment of GAI systems introduce new security vulnerabilities or impact different groups disproportionately?", "99160d6b-c1db-496a-b31c-4dce5966e585": "What methods are suggested for seeking feedback from affected communities regarding GAI system outputs?", "6b0ad89e-1d08-4d28-8f73-6202250baa4f": "How can the quality and integrity of data used in training GAI systems be evaluated?", "47267412-9f6d-4872-b1c3-5aa0e22170c6": "What are the suggested actions for managing GAI risks in relation to legal and regulatory requirements?", "69111612-150e-4566-a8b5-c1d9122cead2": "How do AI Actor Tasks vary between AI development and AI deployment in the context of GAI risk management?", "a75a3460-49d5-4811-a05d-a98355fb01ff": "What activities are involved in obtaining input from stakeholder communities to identify unacceptable use according to the AI RMF Map function?", "29300eec-0384-45ed-8aa7-11ec4f8af8e1": "What types of risks should be included in the updated hierarchy related to GAI model advancement and use?", "16c551fb-2095-4ea5-b417-3181dac5520e": "What policies and procedures should be established for the continuous monitoring of third-party GAI systems in deployment?", "b07e81fa-2e10-4a90-a931-9f75c6f73193": "How can organizations address GAI data redundancy, including model weights and other system artifacts?", "2648ae76-b91b-4baf-a9b4-bccb8d4e3a6a": "What are the key elements that should be maintained in records of changes to content made by third parties according to GV-61-008?", "c0f8ee78-db00-4283-8f83-c51afc277438": "What updates are suggested for due diligence processes in GV-61-009 regarding GAI acquisition and procurement vendor assessments?", "93c87e56-f1b8-4459-9d66-ac9e9b50c381": "What are the suggested actions to prevent GAI systems from generating content that violates the law?", "2d9fba52-b6bb-4a5d-9ff9-b587888bdf06": "How do the established policies and procedures address the risks associated with GAI systems?", "b652b71c-211a-4c5e-bfb4-9696b8e712d4": "What are some known past incidents and failure modes associated with GAI systems?", "0d9205c2-8bda-4504-9ba9-15d7c743721d": "How can organizations identify and document foreseeable illegal uses of GAI systems that exceed their risk tolerances?", "9d062f06-99ef-4134-aa6a-fb3e58678803": "What factors should be considered when assessing GAI vendors and tools against incident or vulnerability databases?", "cf1843dd-a860-4c50-9d5d-2e918dd7081c": "How can organizations update their GAI acceptable use policies to effectively address both proprietary and open-source GAI technologies?", "515344d3-0dd5-4755-8219-54976555cbec": "What are some examples of provenance methodologies mentioned in the context?", "4dd28575-d803-4c6c-a33e-770ebade75d4": "What minimum set of criteria is necessary for GAI system incident reporting according to the organizational practices outlined?", "977972cb-a04f-4b3c-98ae-67a967245d24": "What factors should be assessed to determine the expected and acceptable GAI system context of use in collaboration with socio-cultural and other domain experts?", "879ab3d9-bbdb-44f9-a538-773fab1eb98e": "What elements should be included in risk measurement plans to address identified risks related to harmful bias and homogenization?", "8aefb732-eaaa-4d24-95ff-daacb93786fe": "What are the suggested actions to manage GAI risks associated with third-party data and AI systems?", "242597e6-b8a9-4078-80e2-abc5aff7be53": "Why is it important to document incidents involving third-party GAI data and systems?", "5bfb19b0-e1fe-40c1-9f9a-0974e780f406": "What are the key components that should be included in incident response plans for third-party GAI technologies?", "45cc62fd-15d8-4749-83bb-2d443985b422": "How should organizations ensure that their incident response plans for third-party GAI technologies are regularly updated and improved?", "a08ea2d7-dcc4-470c-bc10-19b2a68487f4": "What are some reasons why certain GAI risks cannot be measured quantitatively?", "09adcf27-b285-43f2-9af6-d88b88a8b770": "Who are the internal experts mentioned in MEASURE 13, and what role do they play in assessing GAI risks?", "6d0fcf89-3fbd-4b27-ac2f-5e8097514abd": "What are the key components of Information Integrity in relation to Information Security?", "49aa7f9f-4356-41c3-b568-96871eb747f7": "How does Intellectual Property relate to the concepts of Information Integrity and Information Security?", "b736a865-6b62-46ef-bc08-eb4baba0313e": "What factors should be considered when determining the objective of disclosure in relation to GAI systems?", "90662337-319b-4b7d-9d0b-3a9958ccee86": "How can adversarial role-playing exercises contribute to identifying unforeseen failure modes in GAI systems?", "bcc332af-fe33-41f6-8431-478c2f5c64ea": "What are the differences between narrow and broad application scopes in the context of external use?", "a0ff040d-63a3-4ccc-ad6b-f93ee7747a26": "How do data privacy and intellectual property concerns relate to the use of various data sources such as grounding and retrieval-augmented generation?", "b17ef8f8-307f-4224-888f-3d1f5322535f": "What are the key considerations related to scientific integrity and TEVV that need to be documented according to MAP 23?", "f2a72fc8-49b5-43df-bad9-f70808913a03": "How can the accuracy, quality, reliability, and authenticity of GAI output be assessed?", "a0dd131a-5e50-49ef-bed6-343ce2f9bfad": "What is the purpose of regularly assessing and verifying security measures according to MS-27-009?", "3b556dca-f9ef-43d5-a879-67d50d5f16bb": "What types of risks are examined and documented under MEASURE 28 in relation to transparency and accountability?", "9b925cd3-6eac-4beb-8efe-13da1e059447": "What are the key aspects of information security for GAI models and systems?", "56ece1c3-3ff7-4109-b679-07bdce4eaac3": "Why is it important to maintain the integrity and confidentiality of GAI code, training data, and model weights?", "05b4e0db-d945-4a19-a35f-baed32124dea": "What are the potential rights violations associated with AI development and deployment?", "0299961b-c506-434d-a0df-58b3855e4e93": "How can governance and oversight mitigate rights violations in AI systems?", "c585c5c7-0729-45d2-83d5-988d1928ed92": "What is the purpose of maintaining a document retention policy for test, evaluation, validation, and verification (TEVV) in relation to GAI?", "b275596f-71a6-4b7e-866f-afd397c3d4b1": "What mechanisms are suggested to inventory AI systems according to organizational risk priorities?", "1057bd52-1aa5-42a3-a9f9-eaea2d398092": "What are the potential harms associated with GAI-generated obscene or degrading content?", "64cd8d40-55da-4b8a-bdb6-bc38d98455af": "How can GAI contribute to the production and access of illegal non-consensual intimate imagery?", "bb8df82e-2f7a-4a82-8469-f1747ac9a558": "What are the established security measures suggested for assessing vulnerabilities and threats in AI systems according to Measure 27?", "88f90caa-630e-4ec4-a310-80c7c8fb57a2": "How does Measure 27 propose to benchmark GAI system security and resilience in relation to content provenance?", "eca4dec5-e95c-4ca1-b156-d7a40e3cd7ba": "What methods are suggested for measuring the reliability of content authentication techniques in the context of information integrity and security?", "c9e813f4-cff9-46ca-9a48-38d1df66986e": "How can the effectiveness of content provenance techniques be evaluated in terms of false positives and false negatives?", "beaab844-7895-4d60-9e8d-ed0268ed4044": "What are the key components that should be included in contracts and service level agreements (SLAs) for GAI systems?", "7738ded5-f8d0-40e1-ae2b-519057ef1189": "How can organizations measure the success of their content provenance management efforts with third parties?", "314d0cc0-923d-4553-b6bc-02cf650d62d6": "What are the key tasks involved in the AI Actor's role in Information Security?", "647904e9-1def-4120-88ed-aac926fdde99": "How can vulnerabilities in AI systems be assessed in terms of their likelihood of occurrence?", "dd35463d-f5ed-4eeb-802d-c071f7bb5574": "What are the key components involved in the value chain and component integration related to information integrity?", "3e9bf5f4-1171-4034-8ebe-83ca0690272f": "How does governance and oversight play a role in the tasks of AI actors?", "d6938356-2621-4df8-9c6a-92170a6ea35e": "What techniques are suggested to assess and manage statistical biases related to GAI content provenance?", "afe49b35-8109-4b57-a9ca-f731cf0fe2e1": "How should content provenance data be documented to ensure it interacts with privacy and security effectively?", "5785951e-6fda-47fb-9d3d-122e4bc56d0e": "What are the potential intellectual property risks associated with GAI systems when using copyrighted works?", "df115811-06d5-4ef7-942e-67122daebad8": "How is the legal status of GAI-generated content that resembles copyrighted material being debated?", "fc37b0f2-6399-4625-9839-f1de1ddc2e0b": "What methods are suggested for employing human domain knowledge to enhance GAI system performance?", "e8c7a33c-6802-4f21-b1e2-cb00e9bc0784": "How should instances of anthropomorphization in GAI system interfaces be tracked and documented?", "492bb196-2324-4969-a481-73798e3aabdd": "What are the novel methods and technologies being evaluated for measuring GAI-related risks in content provenance and offensive cyber?", "34a28dc8-fd15-46cb-916c-6174864f5879": "How can the models ensure valid, reliable, and factually accurate outputs while assessing risks related to CBRN and abusive content?", "004eb7aa-bd9a-4c9e-8a88-af4e98bba34f": "What types of harmful content should be assessed in system training data according to the provided context?", "8825c3e4-74d6-4b4f-aa4b-2f2aac9296de": "When should safety features of fine-tuned models be re-evaluated based on the context?", "5b78dd5b-cf81-4759-83f4-7fc164b20a9f": "What are the potential benefits of using generative AI models in social media campaigns?", "0b659602-9d25-4681-bea3-433d4ab6091d": "What are the two primary information security risks associated with GAI-based systems?", "a3d2a268-f688-4199-88bf-b2e2d477d3ba": "What are the suggested actions for addressing privacy risks associated with AI-generated content?", "5f1ebd94-63ba-4e6d-90d3-e29f614b542b": "How should organizations respond to potential intellectual property infringement claims according to the provided context?", "5e1f1be7-5cbf-45f5-9438-d148d3be84d1": "What is the importance of involving representative AI Actors in structured human feedback exercises?", "ff1c6946-2e90-4997-b3e5-023056f2cf75": "Why is it necessary to verify that those conducting structured human feedback exercises are not involved in system development tasks for the same GAI model?", "7eb6937d-d788-4a2d-b9ad-c30962ec7c49": "What policies and practices should be implemented to define the use, storage, and protection of third-party intellectual property and training data?", "46e0eafc-91d8-4a8d-8683-61358f994f57": "Why is it important to re-evaluate risks when adapting GAI models to new domains?", "a598ea4f-57b2-472d-94b8-0f7191c1017e": "What are the key characteristics that define high-integrity information?", "214f30f0-dba6-4698-add5-b0563969dd3a": "How does high-integrity information distinguish between fact, fiction, opinion, and inference?", "f338a18b-67eb-46a8-bc54-891b4813c32d": "What types of information should be included in GAI system inventory entries according to the context provided?", "45d05d95-617c-438d-b157-26ff1e8bd73b": "What are some examples of external information sharing resources mentioned in the context?", "4a8e2c25-04fd-495d-be65-26717c1bc6e5": "What are the key considerations for assigning liability and responsibility for incidents related to third-party data and systems in AI deployments?", "a2d0ccf3-4a5e-4e5a-9b33-5925c121fdfa": "How should Service Level Agreements (SLAs) be structured to address incident response and support availability in vendor contracts?", "3788c8b8-4431-4c29-a96a-49256a7ba3f9": "What are the potential consequences of indirect prompt injections on closed production models?", "68598a77-3183-467b-b7af-06cb190d1e7c": "How can data poisoning compromise the outputs or operation of a GAI model?", "90bc187f-f6f2-46ca-9b7c-f27deb4eb900": "What are the key oversight functions that need to be established for the GAI lifecycle according to the context?", "02f7a6a0-4561-4a66-84a7-fc956be312c2": "How should organizational teams communicate about the risks and potential impacts of the AI technology they work with?", "b46cd77f-176b-47e1-a5f7-ab5fcb3a4bc3": "What are the key components of the digital content transparency solutions mentioned in the context?", "8016e5e0-1709-4bf8-a62d-655b3ebb2de5": "How can robust version control systems contribute to the AI lifecycle according to the provided context?", "0fcc8c2b-011e-4c9a-8ed8-77bc697624b8": "What are the suggested actions for addressing GAI risks associated with third-party entities?", "1a5c4eea-0b96-4259-a903-8c9d98c9585f": "How should document interactions with GAI systems be handled prior to interactive activities involving significant risks?", "862cbfb9-0020-4472-89ba-b9fb3d5fd5d2": "What organizational policies are suggested to foster a critical thinking and safety-first mindset in AI system design and deployment?", "5837fa09-07c9-4bb0-b211-945f8713ce1d": "How can organizations address the risks associated with a lack of explainability and transparency in GAI systems?", "2e7de416-6ad9-46f7-b252-1121fb6c6388": "What are the key priorities in the research and development of information integrity?", "6a856f9a-bb1f-452b-a917-6ef1c2d76e7e": "How does information integrity impact research and development processes?", "30c5d094-ac4a-4b2f-bb34-994fd96db88a": "What is the purpose of ongoing monitoring and periodic review in the risk management process for GAI systems?", "8222c8a6-05c3-4f3c-b03e-d107d04fc9b0": "What are the suggested actions related to defining organizational responsibilities and establishing policies for GAI system incident response?", "9ee74486-bdf4-4f6d-9563-fd8508c930e4": "What are the key tasks associated with AI actors in the context of CBRN information and capabilities?", "feb424da-7239-467c-8833-514ecbe833e2": "How often should GAI system vulnerabilities be evaluated to ensure safety measures are not circumvented?", "cdf699ee-c336-4bc9-925a-798c9f3318fc": "What are the specific tasks and methods that the AI system will support according to MAP 21?", "d11f1ecb-28e2-46a8-9309-7ddb38d53e6a": "What are the suggested actions to address GAI risks related to data origin and content lineage?", "0bcd4da6-4388-4a95-b51d-de50bce80123": "What are the two types of prompt injection attacks mentioned in the context?", "2d33bd71-5af4-4ce0-a1db-4ab1496b8f99": "How might conventional cybersecurity practices need to adapt in response to the value chain of GAI systems?", "740e27da-53f3-47cb-90bf-4f5b0138cef9": "What is the importance of involving end-users and practitioners in the prototyping and testing activities of GAI systems?", "15f02738-70fa-48e1-9512-c247b8aa4fb6": "How can systems be implemented to monitor and track the outcomes of human-GAI configurations for future improvements?", "99266631-fb75-429a-9f58-cf07f874aa51": "What should be regularly reviewed to ensure the safety of a GAI system operating in novel circumstances?", "28271cdd-8c73-401b-a782-e9f45be1ee94": "Who are the designated AI Actor Tasks mentioned in the context?", "d57619f3-34d5-4ae8-98a3-050137b9a0ab": "What is the purpose of implementing a use-case based supplier risk assessment framework according to the context provided?", "c2791c35-2e53-469a-8713-4fa2ebac9c5b": "What actions should be taken to manage third-party entities' access to organizational content?", "a3976803-cc19-4133-8114-93efdd4acde3": "What factors contribute to the increased risk associated with General Artificial Intelligence (GAI) systems compared to other digital technologies?", "df210632-97da-43f3-889f-fe5ef07a5c4b": "How can errors in third-party GAI components affect the overall performance of a GAI system?", "20926a17-6d2a-4526-b40c-2c52a017764f": "What are the potential risks associated with third-party components in GAI value chains?", "1de504b6-3629-4816-acc8-fe7562be75c9": "How has the generation of synthetic NCII and CSAM evolved in terms of its presence on the internet?", "cd27b6fe-42d3-4510-9351-8effc25616fe": "What are the key tasks involved in AI Actor roles?", "1c5d4896-d46c-461a-a7f6-33c2874afe61": "Who are the primary stakeholders in the AI Actor framework?", "1f5ec374-ea89-47c2-a197-ed89d93315f9": "What are the key components that interdisciplinary teams should reflect according to MAP 12?", "d4e2a821-1874-42b3-803c-d079141595d8": "How does the establishment of interdisciplinary teams contribute to addressing GAI risks?", "e8fe95ad-64bb-48fd-840b-6102890f00ef": "How do GAI systems contribute to the advancement of offensive cyber capabilities?", "8ad46bbd-7b31-4fd3-86a4-b3737a1d9b86": "What vulnerabilities are GAI systems susceptible to that could impact cybersecurity?", "d8c7ca90-a279-4583-889e-ba539c26244a": "What are the characteristics of trustworthy AI that should be integrated into organizational policies and practices?", "a3fee71e-c7c8-482d-9fb5-1bf254a1d170": "How can organizations establish transparency in documenting the origin and history of training data for GAI applications?", "7d8a6436-6ad4-4261-b4c7-9f96b236f428": "What protocols are suggested to ensure GAI systems can be deactivated when necessary?", "ecdabf98-f350-45e1-80c6-f025982ce188": "What factors should be considered when decommissioning GAI systems?", "f492a44b-5fd5-4dcd-9ecb-1f96f217b9b5": "What mechanisms are in place to verify information sharing and feedback regarding the negative impacts of GAI systems?", "cc5a7d60-8532-49c1-b500-a69c4e729bea": "How do organizational policies ensure the integration of feedback from external individuals and communities concerning AI risks?", "faf38a65-b3cb-41de-a15f-6f2962390a6c": "What are the criteria for the kinds of queries that GAI applications should refuse to respond to according to the acceptable use policies?", "3c0c453a-90f8-48a1-b330-fe19b6893645": "How can user feedback mechanisms for GAI systems be established to include thorough instructions and recourse options?", "930e9bae-6ac0-4481-9cf3-51887a450f66": "What methods can be used to compare GAI system security features against industry state-of-the-art practices?", "b0d53c40-8088-4c83-aff0-c562aee62dfc": "How can user surveys be utilized to assess satisfaction with AI-generated content and perceptions of its authenticity?", "46b3da9b-9fb8-4d20-9652-f01dab58a35e": "What are some of the significant negative impacts associated with the design, development, and deployment of GAI systems?", "40816a8f-935b-49c1-81ab-31bb42614fae": "How can a plan be devised to halt the development or deployment of a GAI system that poses unacceptable negative risks?", "542477b2-61c7-4311-8e5b-272e977739da": "What are the potential impacts of generative AI on public trust in information and evidence?", "e46e76b3-1b6f-4c40-bdd7-f92728ee6045": "How can generative AI models contribute to the creation of disinformation and propaganda?", "311a127a-ccae-47e4-a459-74f91adf5213": "What tools are suggested for analyzing content provenance and detecting data anomalies?", "8e8bc1c4-109f-473e-a8bd-4a172e626784": "How can evaluation metrics be disaggregated to identify discrepancies in content provenance mechanisms across diverse populations?", "d8167178-bf74-4355-9704-38e55d60c42b": "What are the suggested actions for documenting the AI model details according to MEASURE 29?", "a9a45707-349c-48cb-a89f-fc972a98739b": "How should the output of the AI system be interpreted to ensure responsible use and governance?", "7a7274c2-904a-435b-84c0-69805f0caa60": "What factors should be considered when determining the applicability of suggested actions to AI actors?", "079f8b57-2d45-48c3-9623-28e3d78b06b3": "How are Action IDs structured in relation to AI RMF functions and subcategories?", "bcfeab2b-e088-4b31-8da6-8a03950093e8": "What are the potential subcategories that could be added later?", "7cbb3216-788e-442b-b453-34411804c223": "Why are certain subcategories not addressed in the current context?", "ab454285-8dd7-4de5-9049-80d8cd026bbe": "What is the purpose of utilizing a testing environment like NIST Dioptra in evaluating GAI trustworthy characteristics?", "684ede18-66b0-42c4-8ad2-66c60370b467": "What are the risks associated with extrapolating GAI system performance from narrow and anecdotal assessments?", "7ffe9d5c-c152-4ed9-bccf-6b17ff64ad6d": "What are the key concerns related to data privacy and intellectual property law in the context of AI actors?", "2643015e-e13a-4f59-9b25-55f6e0f0ea39": "How does the OECD define AI actors and what roles do they play in the AI system lifecycle?", "3b42f88b-3ea9-4a91-aede-cc425f871f11": "What are the key tasks involved in the Human-AI Configuration and Value Chain integration?", "3fe9248b-2795-4404-ad09-c75df9728207": "How are the most significant AI risks selected for measurement during the MAP function?", "e05a5b6b-0043-446e-9cf2-f208155cccfc": "What measures can be taken to protect identifiable information (PII) in AI applications?", "a45ab336-4494-479c-9e18-a40b8d9e40a5": "How can techniques like anonymization and differential privacy help minimize risks in AI-generated content?", "6b09aa9c-4bb0-490b-a0d3-d57a9e5f1d92": "What procedures should be established to engage teams for GAI system incident response according to GV-21-002?", "88582ba2-9c58-4e1c-9436-6ab324aa02a4": "How can organizations verify that AI Actors conducting GAI incident response tasks possess the necessary skills and training as outlined in GV-21-003?", "b63286e6-f96a-4f2f-ac5d-0b9bbf273a71": "What is the purpose of establishing a test plan and response policy before developing highly capable models?", "6e879800-bf45-41e1-9ead-a8ffe051fdfb": "How should the evaluation of GAI capabilities and risks be reflected in the approval thresholds?", "849f1795-0123-41a2-a096-f2e243326db5": "What are the suggested actions for measuring AI system performance or assurance criteria according to MEASURE 23?", "29960580-c19f-497b-9cf9-1bb0eb800ffc": "How should claims of model capabilities be evaluated as per the guidelines outlined in the context?", "c41d37cc-b849-4f9e-a372-dea6e803f085": "What are the key components involved in the AI Actor Tasks as mentioned in the context?", "38243dd9-b51d-449c-a859-1d60b8908c98": "How should organizations ensure that downstream GAI system impacts are documented according to the provided guidelines?", "c08ce8a4-1caa-4407-a13c-791e5021df3c": "What factors should be considered when updating or defining risk tiers for GAI according to the provided context?", "d4c6f382-048b-463e-a88d-1e240649953d": "How do the suggested actions relate to the organization's risk tolerance in the context of information security?", "fc5eb407-bc35-4051-ac93-7e368ecbec53": "What factors influence the implementation of suggested actions for managing GAI risks according to the AI RMF and its Playbook?", "96c4bac4-2175-4bee-b173-7bca242770c1": "Are all subcategories of the AI RMF included in the document discussing suggested actions for GAI risk management?", "99bd0210-1efd-4a66-8c7d-dbac3c226f79": "What are the key considerations for establishing policies related to data collection and retention as mentioned in the context?", "e261caa1-b09d-42d8-a187-f805285e7b30": "How should training data curation policies be documented according to applicable laws and policies?", "c985cf99-0951-4a39-9223-8cfa1814fb38": "What policies are suggested to enhance oversight of GAI systems according to the provided context?", "37f3e917-e3bc-480b-8d31-11da11e4f8c0": "What organizational roles and components should be considered for adjustment across the lifecycle stages of large or complex GAI systems?", "0d873863-14d8-44e6-9ea8-6fafd5a4684f": "What is the purpose of verifying data or benchmarks used in risk measurement according to the provided context?", "923e911f-f4b5-4ac6-a16b-18ada548ea5c": "How does the context address the representation of diverse user populations in structured GAI public feedback exercises?", "f8435126-5acd-4711-bad3-69eac027c7c9": "What is the purpose of documenting the AI system's knowledge limits and how its output may be utilized by humans?", "c2bea246-b006-4597-a68f-6613672bc3f1": "How does the suggested action MP-22-001 relate to the concepts of information integrity and value chain integration?", "776456e9-e9cd-4f0e-be32-6680b11d689c": "What are the key risks associated with unreliable downstream decision-making in GAI systems as outlined in the context?", "99fcb8be-8972-40b7-a7cb-c0eaa6e6e305": "How should GAI system architecture be designed to monitor outputs and recover from security anomalies?", "0bed2c3e-85de-4974-9b9c-d872ccdcf41f": "How do inaccuracies in labels affect the stability of benchmarks in GAI model selection?", "36f0dfdc-42b2-400c-8c3b-0088b41debcb": "What are the suggested actions to manage risks unique to or exacerbated by GAI?", "5bc5a898-3348-4411-a1d2-aff17ef9b44f": "What steps should be taken to assess the intellectual property and privacy risks associated with the use of training data?", "27e5b458-1bc5-4348-a2b3-10efa9666225": "How can the likelihood and magnitude of impacts from AI systems be evaluated based on past uses and external feedback?", "59b485a5-ed58-437d-8402-9d921443c2ef": "What mechanisms should be created to protect whistleblowers who report violations of laws or risks to public safety?", "d617c364-0381-425a-8593-5c1d0db54be7": "Under what circumstances can an organization be held accountable for causing harm related to CBRN information or capabilities?", "fe18212d-923f-41be-afa6-a04fbaa3a8cd": "What processes are defined, assessed, and documented to ensure operator and practitioner proficiency with AI system performance and trustworthiness?", "648a9ca7-f14e-4ba4-bd40-c4a3b4bf8d16": "How can existing training programs be adapted to enhance understanding of digital content transparency in relation to GAI risks?", "0608d116-6e94-452c-8827-48ce26a3a210": "What are the key components involved in the Human-AI Configuration as it relates to GAI functions?", "51880271-cceb-4549-ad6a-1f839e7c4447": "How are roles and responsibilities for managing AI risks communicated within an organization according to GOVERN 21?", "8736d5eb-139f-4892-b7b2-18b441eaae78": "What are the potential negative consequences of the creation and spread of NCII on individuals, particularly women and sexual minorities?", "918a739b-9277-4bd5-8933-941ddb369622": "How might the inclusion of CSAM and NCII in training datasets for GAI models impact efforts to address these issues?", "b85f4e21-1b0d-4d41-bbdc-6239280c46e6": "What practices should be applied to ensure content provenance in GAI systems to mitigate risks associated with synthetic data generation?", "c12ec833-4eda-4492-a7ba-28bd2f3faaf2": "How can potential harms related to misinformation, deepfakes, and tampered content be identified and ranked in the context of GAI?", "dc5052d7-4eb4-45d8-8f2f-30a43ed777d0": "What measures should be determined to identify new impacts from the GAI system according to Action ID MP-52-001?", "4502f43a-a628-4675-8841-659cd6e7febd": "What is the purpose of planning regular engagements with AI Actors as suggested in Action ID MP-52-002?", "58189d04-0153-42ca-96f6-cc5d0b5d0a32": "What criteria are used to evaluate the safety risks of the AI system as mentioned in the context?", "a876f96c-18f8-4ffe-bf76-1cc290e1586a": "How does the AI system ensure it can fail safely when operating beyond its knowledge limits?", "44bdbbd0-5570-429d-8dc6-581155f3dfc0": "What are some potential risks associated with the domain where previous assumptions about security and safety may no longer hold?", "0ff036a5-6e5f-4b44-9078-8c3898617cff": "How can approaches be leveraged to detect the presence of PII or sensitive data in various forms of generated output?", "efd4186a-efb6-4764-9a8f-f38504c00a1e": "What are the key components that should be included in the policies and procedures for risk measurement?", "a70748a3-d22a-4a96-9c0e-f7d862ae0407": "How can structured public feedback exercises, such as AI red-teaming, enhance the risk measurement approaches?"}, "relevant_contexts": {"1efe4649-d959-46a1-a517-efb44e58febe": ["4c7a3ea7-e611-4474-96f4-ec8f382135ba"], "50d04a58-3bbf-4766-b3c3-82a690043aef": ["4c7a3ea7-e611-4474-96f4-ec8f382135ba"], "103690df-97c0-4f4f-bfe1-d5e702effc8b": ["0cef9333-d5a1-472b-b126-7f72a2929eab"], "623ab973-898d-4565-a09b-66e2424a85b4": ["0cef9333-d5a1-472b-b126-7f72a2929eab"], "4a661925-37ef-4ff5-8520-042fe69fe7c4": ["1d384063-9796-4e43-b68a-a6f4a585635b"], "34034c8d-3d4d-40d5-a2f1-a68dd8476c71": ["1d384063-9796-4e43-b68a-a6f4a585635b"], "00caf438-e3a3-441e-8a81-b3659477b7d8": ["500574c3-5859-4039-9fae-d721e40880a8"], "d1ca04f1-6310-499e-90ac-3982f89b8fe5": ["500574c3-5859-4039-9fae-d721e40880a8"], "4494b781-f5a3-40c6-a878-36c682a00f79": ["33b59760-1515-48cb-abc2-d427006c0a3b"], "98de0988-9c71-43ff-ac6b-59af9a5dbf73": ["33b59760-1515-48cb-abc2-d427006c0a3b"], "a00352d9-ebc7-4725-9aaa-d4d4f23a55c4": ["5bd8ca16-dec4-4393-b00f-94aa6262a21c"], "fa4044ce-af4c-4603-af05-d016e7ae157c": ["5bd8ca16-dec4-4393-b00f-94aa6262a21c"], "99160d6b-c1db-496a-b31c-4dce5966e585": ["ba2329b3-9970-40b5-9213-74f81d8b30f8"], "6b0ad89e-1d08-4d28-8f73-6202250baa4f": ["ba2329b3-9970-40b5-9213-74f81d8b30f8"], "47267412-9f6d-4872-b1c3-5aa0e22170c6": ["57322dd9-0f28-47a1-96b9-82a4fb46ae9c"], "69111612-150e-4566-a8b5-c1d9122cead2": ["57322dd9-0f28-47a1-96b9-82a4fb46ae9c"], "a75a3460-49d5-4811-a05d-a98355fb01ff": ["11231f37-55a1-4c07-86b9-b26328869379"], "29300eec-0384-45ed-8aa7-11ec4f8af8e1": ["11231f37-55a1-4c07-86b9-b26328869379"], "16c551fb-2095-4ea5-b417-3181dac5520e": ["8b5e9910-4644-4461-be63-4a60d3792fd8"], "b07e81fa-2e10-4a90-a931-9f75c6f73193": ["8b5e9910-4644-4461-be63-4a60d3792fd8"], "2648ae76-b91b-4baf-a9b4-bccb8d4e3a6a": ["9571ef0e-1693-4708-a141-33e3e22c88b6"], "c0f8ee78-db00-4283-8f83-c51afc277438": ["9571ef0e-1693-4708-a141-33e3e22c88b6"], "93c87e56-f1b8-4459-9d66-ac9e9b50c381": ["212e5309-27c4-46e0-a0c2-cb1c7ba883c8"], "2d9fba52-b6bb-4a5d-9ff9-b587888bdf06": ["212e5309-27c4-46e0-a0c2-cb1c7ba883c8"], "b652b71c-211a-4c5e-bfb4-9696b8e712d4": ["d9bb0ba3-00c9-486d-b5fd-c01a94ac15d7"], "0d9205c2-8bda-4504-9ba9-15d7c743721d": ["d9bb0ba3-00c9-486d-b5fd-c01a94ac15d7"], "9d062f06-99ef-4134-aa6a-fb3e58678803": ["02834885-face-4975-ace5-cf3d57f9ad7c"], "cf1843dd-a860-4c50-9d5d-2e918dd7081c": ["02834885-face-4975-ace5-cf3d57f9ad7c"], "515344d3-0dd5-4755-8219-54976555cbec": ["49a1d424-d1b6-4ee3-8b59-36dbc79d0943"], "4dd28575-d803-4c6c-a33e-770ebade75d4": ["49a1d424-d1b6-4ee3-8b59-36dbc79d0943"], "977972cb-a04f-4b3c-98ae-67a967245d24": ["eba02204-359d-4556-930b-e1edfad72023"], "879ab3d9-bbdb-44f9-a538-773fab1eb98e": ["eba02204-359d-4556-930b-e1edfad72023"], "8aefb732-eaaa-4d24-95ff-daacb93786fe": ["e9c1187d-8c84-4bcc-a920-02a23bc346ce"], "242597e6-b8a9-4078-80e2-abc5aff7be53": ["e9c1187d-8c84-4bcc-a920-02a23bc346ce"], "5bfb19b0-e1fe-40c1-9f9a-0974e780f406": ["65898c9f-f8ec-45f0-8384-09d777f84338"], "45cc62fd-15d8-4749-83bb-2d443985b422": ["65898c9f-f8ec-45f0-8384-09d777f84338"], "a08ea2d7-dcc4-470c-bc10-19b2a68487f4": ["f3a66ae2-29d8-4619-a6a3-00c94c0d02f7"], "09adcf27-b285-43f2-9af6-d88b88a8b770": ["f3a66ae2-29d8-4619-a6a3-00c94c0d02f7"], "6d0fcf89-3fbd-4b27-ac2f-5e8097514abd": ["5066d454-f176-4e8c-b276-de95f057ae9a"], "49aa7f9f-4356-41c3-b568-96871eb747f7": ["5066d454-f176-4e8c-b276-de95f057ae9a"], "b736a865-6b62-46ef-bc08-eb4baba0313e": ["7900d2e0-5c07-475d-b812-50859a4ce992"], "90662337-319b-4b7d-9d0b-3a9958ccee86": ["7900d2e0-5c07-475d-b812-50859a4ce992"], "bcc332af-fe33-41f6-8431-478c2f5c64ea": ["db6eb528-d6ce-410e-8b02-f18744c447cc"], "a0ff040d-63a3-4ccc-ad6b-f93ee7747a26": ["db6eb528-d6ce-410e-8b02-f18744c447cc"], "b17ef8f8-307f-4224-888f-3d1f5322535f": ["aafdac84-63af-4389-8250-100cca29a102"], "f2a72fc8-49b5-43df-bad9-f70808913a03": ["aafdac84-63af-4389-8250-100cca29a102"], "a0dd131a-5e50-49ef-bed6-343ce2f9bfad": ["70e73003-16d0-4f10-8797-14c8c3da4519"], "3b556dca-f9ef-43d5-a879-67d50d5f16bb": ["70e73003-16d0-4f10-8797-14c8c3da4519"], "9b925cd3-6eac-4beb-8efe-13da1e059447": ["58a90729-3204-462a-91bd-bfc6554cac8c"], "56ece1c3-3ff7-4109-b679-07bdce4eaac3": ["58a90729-3204-462a-91bd-bfc6554cac8c"], "05b4e0db-d945-4a19-a35f-baed32124dea": ["90681c8b-f805-4730-a21e-df9b835317d1"], "0299961b-c506-434d-a0df-58b3855e4e93": ["90681c8b-f805-4730-a21e-df9b835317d1"], "c585c5c7-0729-45d2-83d5-988d1928ed92": ["fb286798-e471-4e00-8d93-48416640a890"], "b275596f-71a6-4b7e-866f-afd397c3d4b1": ["fb286798-e471-4e00-8d93-48416640a890"], "1057bd52-1aa5-42a3-a9f9-eaea2d398092": ["c6bf671c-cd26-4d32-86e2-37441df870b1"], "64cd8d40-55da-4b8a-bdb6-bc38d98455af": ["c6bf671c-cd26-4d32-86e2-37441df870b1"], "bb8df82e-2f7a-4a82-8469-f1747ac9a558": ["799d6f35-5486-4138-a9b3-3493176ed2c3"], "88f90caa-630e-4ec4-a310-80c7c8fb57a2": ["799d6f35-5486-4138-a9b3-3493176ed2c3"], "eca4dec5-e95c-4ca1-b156-d7a40e3cd7ba": ["db98fcd2-6682-4549-a5ca-d42f3558622c"], "c9e813f4-cff9-46ca-9a48-38d1df66986e": ["db98fcd2-6682-4549-a5ca-d42f3558622c"], "beaab844-7895-4d60-9e8d-ed0268ed4044": ["9499c4f5-baa0-4b1f-ae86-05ae1b53c902"], "7738ded5-f8d0-40e1-ae2b-519057ef1189": ["9499c4f5-baa0-4b1f-ae86-05ae1b53c902"], "314d0cc0-923d-4553-b6bc-02cf650d62d6": ["3fa7d98f-af21-4d94-b686-f8341ff150a2"], "647904e9-1def-4120-88ed-aac926fdde99": ["3fa7d98f-af21-4d94-b686-f8341ff150a2"], "dd35463d-f5ed-4eeb-802d-c071f7bb5574": ["a78624b2-fcde-4ba1-83eb-bf3d7b3eca6c"], "3e9bf5f4-1171-4034-8ebe-83ca0690272f": ["a78624b2-fcde-4ba1-83eb-bf3d7b3eca6c"], "d6938356-2621-4df8-9c6a-92170a6ea35e": ["7f0ce253-124d-496e-8538-efddcf8604a5"], "afe49b35-8109-4b57-a9ca-f731cf0fe2e1": ["7f0ce253-124d-496e-8538-efddcf8604a5"], "5785951e-6fda-47fb-9d3d-122e4bc56d0e": ["5e75677a-1bde-43bc-9b7e-c77cd8b769c3"], "df115811-06d5-4ef7-942e-67122daebad8": ["5e75677a-1bde-43bc-9b7e-c77cd8b769c3"], "fc37b0f2-6399-4625-9839-f1de1ddc2e0b": ["aa47a658-b4cc-49c8-a4b9-0cd3b2773a03"], "e8c7a33c-6802-4f21-b1e2-cb00e9bc0784": ["aa47a658-b4cc-49c8-a4b9-0cd3b2773a03"], "492bb196-2324-4969-a481-73798e3aabdd": ["2cd0a75b-978d-4408-98f1-d59e7ee8f92e"], "34a28dc8-fd15-46cb-916c-6174864f5879": ["2cd0a75b-978d-4408-98f1-d59e7ee8f92e"], "004eb7aa-bd9a-4c9e-8a88-af4e98bba34f": ["f149548c-a4fb-4bfb-9f1f-b3a40284bb32"], "8825c3e4-74d6-4b4f-aa4b-2f2aac9296de": ["f149548c-a4fb-4bfb-9f1f-b3a40284bb32"], "5b78dd5b-cf81-4759-83f4-7fc164b20a9f": ["63fe73e1-be67-43b1-9df9-efada6c60819"], "0b659602-9d25-4681-bea3-433d4ab6091d": ["63fe73e1-be67-43b1-9df9-efada6c60819"], "a3d2a268-f688-4199-88bf-b2e2d477d3ba": ["c40d9e15-ef75-4d5a-a932-3ae367ebae5a"], "5f1ebd94-63ba-4e6d-90d3-e29f614b542b": ["c40d9e15-ef75-4d5a-a932-3ae367ebae5a"], "5e1f1be7-5cbf-45f5-9438-d148d3be84d1": ["c620282d-3a29-44e6-a805-b06d3c598453"], "ff1c6946-2e90-4997-b3e5-023056f2cf75": ["c620282d-3a29-44e6-a805-b06d3c598453"], "7eb6937d-d788-4a2d-b9ad-c30962ec7c49": ["19fd319c-2994-4d81-bb9d-1ef855b28f8a"], "46e0eafc-91d8-4a8d-8683-61358f994f57": ["19fd319c-2994-4d81-bb9d-1ef855b28f8a"], "a598ea4f-57b2-472d-94b8-0f7191c1017e": ["c905cd33-346d-471c-adc1-fecfd341271e"], "214f30f0-dba6-4698-add5-b0563969dd3a": ["c905cd33-346d-471c-adc1-fecfd341271e"], "f338a18b-67eb-46a8-bc54-891b4813c32d": ["e77f7c42-045f-40c5-a66f-7a86c4825e2d"], "45d05d95-617c-438d-b157-26ff1e8bd73b": ["e77f7c42-045f-40c5-a66f-7a86c4825e2d"], "4a8e2c25-04fd-495d-be65-26717c1bc6e5": ["f4142adc-0420-4531-b5e0-4407cbf61b62"], "a2d0ccf3-4a5e-4e5a-9b33-5925c121fdfa": ["f4142adc-0420-4531-b5e0-4407cbf61b62"], "3788c8b8-4431-4c29-a96a-49256a7ba3f9": ["94df81ae-d453-4fd5-9f6f-8201e5edf6d0"], "68598a77-3183-467b-b7af-06cb190d1e7c": ["94df81ae-d453-4fd5-9f6f-8201e5edf6d0"], "90bc187f-f6f2-46ca-9b7c-f27deb4eb900": ["86451219-1349-4093-8cb3-bea25e36c1c8"], "02f7a6a0-4561-4a66-84a7-fc956be312c2": ["86451219-1349-4093-8cb3-bea25e36c1c8"], "b46cd77f-176b-47e1-a5f7-ab5fcb3a4bc3": ["018878e7-96cf-401e-8f8b-52f4a4ecbae0"], "8016e5e0-1709-4bf8-a62d-655b3ebb2de5": ["018878e7-96cf-401e-8f8b-52f4a4ecbae0"], "0fcc8c2b-011e-4c9a-8ed8-77bc697624b8": ["20d46384-b267-4c69-815d-2682eecbba44"], "1a5c4eea-0b96-4259-a903-8c9d98c9585f": ["20d46384-b267-4c69-815d-2682eecbba44"], "862cbfb9-0020-4472-89ba-b9fb3d5fd5d2": ["c63ed0e3-e277-4b2e-b801-25aff67d59b1"], "5837fa09-07c9-4bb0-b211-945f8713ce1d": ["c63ed0e3-e277-4b2e-b801-25aff67d59b1"], "2e7de416-6ad9-46f7-b252-1121fb6c6388": ["e2d7f3e1-ff81-45a6-a5c4-432398cd8832"], "6a856f9a-bb1f-452b-a917-6ef1c2d76e7e": ["e2d7f3e1-ff81-45a6-a5c4-432398cd8832"], "30c5d094-ac4a-4b2f-bb34-994fd96db88a": ["4402e59c-06c1-4bc6-971f-0c46eacd45a0"], "8222c8a6-05c3-4f3c-b03e-d107d04fc9b0": ["4402e59c-06c1-4bc6-971f-0c46eacd45a0"], "9ee74486-bdf4-4f6d-9563-fd8508c930e4": ["0ebc4cec-5f80-4254-99d8-cdf3a203660a"], "feb424da-7239-467c-8833-514ecbe833e2": ["0ebc4cec-5f80-4254-99d8-cdf3a203660a"], "cdf699ee-c336-4bc9-925a-798c9f3318fc": ["fb5be542-830c-48a6-a905-68a6823b56b0"], "d11f1ecb-28e2-46a8-9309-7ddb38d53e6a": ["fb5be542-830c-48a6-a905-68a6823b56b0"], "0bcd4da6-4388-4a95-b51d-de50bce80123": ["c5f3f8ca-f14e-48d0-a857-95c06aa5a59b"], "2d33bd71-5af4-4ce0-a1db-4ab1496b8f99": ["c5f3f8ca-f14e-48d0-a857-95c06aa5a59b"], "740e27da-53f3-47cb-90bf-4f5b0138cef9": ["dd01609a-0262-48f7-b686-4ba1a98ad6b6"], "15f02738-70fa-48e1-9512-c247b8aa4fb6": ["dd01609a-0262-48f7-b686-4ba1a98ad6b6"], "99266631-fb75-429a-9f58-cf07f874aa51": ["b9abd627-ee7e-4cb4-b934-f7955d117fe5"], "28271cdd-8c73-401b-a782-e9f45be1ee94": ["b9abd627-ee7e-4cb4-b934-f7955d117fe5"], "d57619f3-34d5-4ae8-98a3-050137b9a0ab": ["dcf31fb9-043d-4218-babd-0d9f3fdb152e"], "c2791c35-2e53-469a-8713-4fa2ebac9c5b": ["dcf31fb9-043d-4218-babd-0d9f3fdb152e"], "a3976803-cc19-4133-8114-93efdd4acde3": ["03435e48-7db2-4cb5-9aa7-04c8d08ffe62"], "df210632-97da-43f3-889f-fe5ef07a5c4b": ["03435e48-7db2-4cb5-9aa7-04c8d08ffe62"], "20926a17-6d2a-4526-b40c-2c52a017764f": ["df5e7404-a205-4f8b-bbd1-1690e139c827"], "1de504b6-3629-4816-acc8-fe7562be75c9": ["df5e7404-a205-4f8b-bbd1-1690e139c827"], "cd27b6fe-42d3-4510-9351-8effc25616fe": ["dac9109e-3667-4928-bfb2-f788f504237e"], "1c5d4896-d46c-461a-a7f6-33c2874afe61": ["dac9109e-3667-4928-bfb2-f788f504237e"], "1f5ec374-ea89-47c2-a197-ed89d93315f9": ["007d0d5e-206f-4fbd-9215-c3eccc2ccb16"], "d4e2a821-1874-42b3-803c-d079141595d8": ["007d0d5e-206f-4fbd-9215-c3eccc2ccb16"], "e8fe95ad-64bb-48fd-840b-6102890f00ef": ["c2cae030-50b0-4dee-b653-52627f0add18"], "8ad46bbd-7b31-4fd3-86a4-b3737a1d9b86": ["c2cae030-50b0-4dee-b653-52627f0add18"], "d8c7ca90-a279-4583-889e-ba539c26244a": ["ed7641d8-3327-4749-8851-83aa0f899e1b"], "a3fee71e-c7c8-482d-9fb5-1bf254a1d170": ["ed7641d8-3327-4749-8851-83aa0f899e1b"], "7d8a6436-6ad4-4261-b4c7-9f96b236f428": ["9df1a0a1-c582-4083-8d84-8c275d4ed394"], "ecdabf98-f350-45e1-80c6-f025982ce188": ["9df1a0a1-c582-4083-8d84-8c275d4ed394"], "f492a44b-5fd5-4dcd-9ecb-1f96f217b9b5": ["9b8493c3-42c4-4670-bc90-562cbd9fbd2a"], "cc5a7d60-8532-49c1-b500-a69c4e729bea": ["9b8493c3-42c4-4670-bc90-562cbd9fbd2a"], "faf38a65-b3cb-41de-a15f-6f2962390a6c": ["e19746c0-7a41-4d51-9cc4-f13c00d68406"], "3c0c453a-90f8-48a1-b330-fe19b6893645": ["e19746c0-7a41-4d51-9cc4-f13c00d68406"], "930e9bae-6ac0-4481-9cf3-51887a450f66": ["65507ba8-bfa9-4b1f-a7bf-c16015e37ed6"], "b0d53c40-8088-4c83-aff0-c562aee62dfc": ["65507ba8-bfa9-4b1f-a7bf-c16015e37ed6"], "46b3da9b-9fb8-4d20-9652-f01dab58a35e": ["2d1860a0-4108-4fe8-a4f8-28362aae80e5"], "40816a8f-935b-49c1-81ab-31bb42614fae": ["2d1860a0-4108-4fe8-a4f8-28362aae80e5"], "542477b2-61c7-4311-8e5b-272e977739da": ["7d8fbfc3-fe74-4613-bd68-7238c6674fec"], "e46e76b3-1b6f-4c40-bdd7-f92728ee6045": ["7d8fbfc3-fe74-4613-bd68-7238c6674fec"], "311a127a-ccae-47e4-a459-74f91adf5213": ["b2ecf04f-6035-47fd-bfae-8f1b117e1cc3"], "8e8bc1c4-109f-473e-a8bd-4a172e626784": ["b2ecf04f-6035-47fd-bfae-8f1b117e1cc3"], "d8167178-bf74-4355-9704-38e55d60c42b": ["8c0b1dc6-17b0-45d6-a58c-2bdffae6322e"], "a9a45707-349c-48cb-a89f-fc972a98739b": ["8c0b1dc6-17b0-45d6-a58c-2bdffae6322e"], "7a7274c2-904a-435b-84c0-69805f0caa60": ["396b03dc-e478-4fd0-a060-28eeca1727c9"], "079f8b57-2d45-48c3-9623-28e3d78b06b3": ["396b03dc-e478-4fd0-a060-28eeca1727c9"], "bcfeab2b-e088-4b31-8da6-8a03950093e8": ["53b1aca1-e2d7-41fd-956f-dc4f8aa0f9dd"], "7cbb3216-788e-442b-b453-34411804c223": ["53b1aca1-e2d7-41fd-956f-dc4f8aa0f9dd"], "ab454285-8dd7-4de5-9049-80d8cd026bbe": ["5e6d720b-fe4e-4954-a1d3-dbef9f2f34ba"], "684ede18-66b0-42c4-8ad2-66c60370b467": ["5e6d720b-fe4e-4954-a1d3-dbef9f2f34ba"], "7ffe9d5c-c152-4ed9-bccf-6b17ff64ad6d": ["8e2ccfdf-b551-4406-85b3-7ce2ba90d39c"], "2643015e-e13a-4f59-9b25-55f6e0f0ea39": ["8e2ccfdf-b551-4406-85b3-7ce2ba90d39c"], "3b42f88b-3ea9-4a91-aede-cc425f871f11": ["b7d8726d-d900-479a-ac67-3fd7425a74ac"], "3fe9248b-2795-4404-ad09-c75df9728207": ["b7d8726d-d900-479a-ac67-3fd7425a74ac"], "e05a5b6b-0043-446e-9cf2-f208155cccfc": ["671a27f6-4bc0-4651-a401-d2e7979fdd01"], "a45ab336-4494-479c-9e18-a40b8d9e40a5": ["671a27f6-4bc0-4651-a401-d2e7979fdd01"], "6b09aa9c-4bb0-490b-a0d3-d57a9e5f1d92": ["a5381894-fb5d-4dc4-b2df-cc3a6090417e"], "88582ba2-9c58-4e1c-9436-6ab324aa02a4": ["a5381894-fb5d-4dc4-b2df-cc3a6090417e"], "b63286e6-f96a-4f2f-ac5d-0b9bbf273a71": ["564201ed-4586-4d13-a896-9ecfb1f153bd"], "6e879800-bf45-41e1-9ead-a8ffe051fdfb": ["564201ed-4586-4d13-a896-9ecfb1f153bd"], "849f1795-0123-41a2-a096-f2e243326db5": ["0f729b4b-7c88-4ccc-9570-8eb27956d172"], "29960580-c19f-497b-9cf9-1bb0eb800ffc": ["0f729b4b-7c88-4ccc-9570-8eb27956d172"], "c41d37cc-b849-4f9e-a372-dea6e803f085": ["d2344fb5-011c-45ba-ace7-1acb88f63018"], "38243dd9-b51d-449c-a859-1d60b8908c98": ["d2344fb5-011c-45ba-ace7-1acb88f63018"], "c08ce8a4-1caa-4407-a13c-791e5021df3c": ["e55f8c90-abca-42f1-afda-3249c25a3618"], "d4c6f382-048b-463e-a88d-1e240649953d": ["e55f8c90-abca-42f1-afda-3249c25a3618"], "fc5eb407-bc35-4051-ac93-7e368ecbec53": ["ca41c82d-7d81-4a87-af76-370aa39c7ef5"], "96c4bac4-2175-4bee-b173-7bca242770c1": ["ca41c82d-7d81-4a87-af76-370aa39c7ef5"], "99bd0210-1efd-4a66-8c7d-dbac3c226f79": ["491fc5eb-2ac4-46e2-bd56-532a8c2233d0"], "e261caa1-b09d-42d8-a187-f805285e7b30": ["491fc5eb-2ac4-46e2-bd56-532a8c2233d0"], "c985cf99-0951-4a39-9223-8cfa1814fb38": ["d3d8dc3b-7f87-4548-ad2d-afbe0961431c"], "37f3e917-e3bc-480b-8d31-11da11e4f8c0": ["d3d8dc3b-7f87-4548-ad2d-afbe0961431c"], "0d873863-14d8-44e6-9ea8-6fafd5a4684f": ["937db36c-ff0d-494a-9df4-66218305d23e"], "923e911f-f4b5-4ac6-a16b-18ada548ea5c": ["937db36c-ff0d-494a-9df4-66218305d23e"], "f8435126-5acd-4711-bad3-69eac027c7c9": ["8612d4af-9a3d-4137-9fa1-c3b206f0c50e"], "c2bea246-b006-4597-a68f-6613672bc3f1": ["8612d4af-9a3d-4137-9fa1-c3b206f0c50e"], "776456e9-e9cd-4f0e-be32-6680b11d689c": ["f93042e7-98e5-4e82-aff6-83c7148279d9"], "99fcb8be-8972-40b7-a7cb-c0eaa6e6e305": ["f93042e7-98e5-4e82-aff6-83c7148279d9"], "0bed2c3e-85de-4974-9b9c-d872ccdcf41f": ["d557b3bf-1dea-42a1-a781-0a890677e104"], "36f0dfdc-42b2-400c-8c3b-0088b41debcb": ["d557b3bf-1dea-42a1-a781-0a890677e104"], "5bc5a898-3348-4411-a1d2-aff17ef9b44f": ["f2e7f5e2-f0fc-439e-ab7c-7a7fed01bba5"], "27e5b458-1bc5-4348-a2b3-10efa9666225": ["f2e7f5e2-f0fc-439e-ab7c-7a7fed01bba5"], "59b485a5-ed58-437d-8402-9d921443c2ef": ["ca9d0e33-f428-48f3-931a-7d3942b13320"], "d617c364-0381-425a-8593-5c1d0db54be7": ["ca9d0e33-f428-48f3-931a-7d3942b13320"], "fe18212d-923f-41be-afa6-a04fbaa3a8cd": ["4adb9db7-387c-4af5-bbc8-cb5d08514d40"], "648a9ca7-f14e-4ba4-bd40-c4a3b4bf8d16": ["4adb9db7-387c-4af5-bbc8-cb5d08514d40"], "0608d116-6e94-452c-8827-48ce26a3a210": ["7d2f169c-0eed-4de7-befe-3e388113ddcf"], "51880271-cceb-4549-ad6a-1f839e7c4447": ["7d2f169c-0eed-4de7-befe-3e388113ddcf"], "8736d5eb-139f-4892-b7b2-18b441eaae78": ["d0becd04-0e95-4f50-aa14-250bd4d65f34"], "918a739b-9277-4bd5-8933-941ddb369622": ["d0becd04-0e95-4f50-aa14-250bd4d65f34"], "b85f4e21-1b0d-4d41-bbdc-6239280c46e6": ["103b8c17-9774-4389-a23b-d84a8d468f61"], "c12ec833-4eda-4492-a7ba-28bd2f3faaf2": ["103b8c17-9774-4389-a23b-d84a8d468f61"], "dc5052d7-4eb4-45d8-8f2f-30a43ed777d0": ["cf87732c-f50b-494d-a70a-41064b90ca41"], "4502f43a-a628-4675-8841-659cd6e7febd": ["cf87732c-f50b-494d-a70a-41064b90ca41"], "58189d04-0153-42ca-96f6-cc5d0b5d0a32": ["26741d2e-61fe-428a-ad44-9f36ab22f995"], "a876f96c-18f8-4ffe-bf76-1cc290e1586a": ["26741d2e-61fe-428a-ad44-9f36ab22f995"], "44bdbbd0-5570-429d-8dc6-581155f3dfc0": ["12959615-a3ce-4975-80bd-34bb2adc1ad1"], "0ff036a5-6e5f-4b44-9078-8c3898617cff": ["12959615-a3ce-4975-80bd-34bb2adc1ad1"], "efd4186a-efb6-4764-9a8f-f38504c00a1e": ["e9e7102b-fe6b-498a-8647-c41a5717e6d4"], "a70748a3-d22a-4a96-9c0e-f7d862ae0407": ["e9e7102b-fe6b-498a-8647-c41a5717e6d4"]}, "corpus": {"c905cd33-346d-471c-adc1-fecfd341271e": "Information integrity describes the \u201cspectrum of information and associated patterns of its creation, \nexchange, and consumption in society.\u201d High-integrity information can be trusted; \u201cdistinguishes fact \nfrom \ufb01ction, opinion, and inference; acknowledges uncertainties; and is transparent about its level of \nvetting. This information can be linked to the original source(s) with appropriate evidence. High-integrity \ninformation is also accurate and reliable, can be veri\ufb01ed and authenticated, has a clear chain of custody, \nand creates reasonable expectations about when its validity may expire.\u201d11 \n \n \n11 This de\ufb01nition of information integrity is derived from the 2022 White House Roadmap for Researchers on", "e2d7f3e1-ff81-45a6-a5c4-432398cd8832": "Priorities Related to Information Integrity Research and Development.", "33b59760-1515-48cb-abc2-d427006c0a3b": "10 \nGAI systems can ease the unintentional production or dissemination of false, inaccurate, or misleading \ncontent (misinformation) at scale, particularly if the content stems from confabulations.  \nGAI systems can also ease the deliberate production or dissemination of false or misleading information \n(disinformation) at scale, where an actor has the explicit intent to deceive or cause harm to others. Even \nvery subtle changes to text or images can manipulate human and machine perception. \nSimilarly, GAI systems could enable a higher degree of sophistication for malicious actors to produce \ndisinformation that is targeted towards speci\ufb01c demographics. Current and emerging multimodal models", "7d8fbfc3-fe74-4613-bd68-7238c6674fec": "make it possible to generate both text-based disinformation and highly realistic \u201cdeepfakes\u201d \u2013 that is, \nsynthetic audiovisual content and photorealistic images.12 Additional disinformation threats could be \nenabled by future GAI models trained on new data modalities. \nDisinformation and misinformation \u2013 both of which may be facilitated by GAI \u2013 may erode public trust in \ntrue or valid evidence and information, with downstream e\ufb00ects. For example, a synthetic image of a \nPentagon blast went viral and brie\ufb02y caused a drop in the stock market. Generative AI models can also \nassist malicious actors in creating compelling imagery and propaganda to support disinformation", "63fe73e1-be67-43b1-9df9-efada6c60819": "campaigns, which may not be photorealistic, but could enable these campaigns to gain more reach and \nengagement on social media platforms. Additionally, generative AI models can assist malicious actors in \ncreating fraudulent content intended to impersonate others. \nTrustworthy AI Characteristics: Accountable and Transparent, Safe, Valid and Reliable, Interpretable and \nExplainable \n2.9. Information Security \nInformation security for computer systems and data is a mature \ufb01eld with widely accepted and \nstandardized practices for o\ufb00ensive and defensive cyber capabilities. GAI-based systems present two \nprimary information security risks: GAI could potentially discover or enable new cybersecurity risks by", "c2cae030-50b0-4dee-b653-52627f0add18": "lowering the barriers for or easing automated exercise of o\ufb00ensive capabilities; simultaneously, it \nexpands the available attack surface, as GAI itself is vulnerable to attacks like prompt injection or data \npoisoning.  \nO\ufb00ensive cyber capabilities advanced by GAI systems may augment cybersecurity attacks such as \nhacking, malware, and phishing. Reports have indicated that LLMs are already able to discover some \nvulnerabilities in systems (hardware, software, data) and write code to exploit them. Sophisticated threat \nactors might further these risks by developing GAI-powered security co-pilots for use in several parts of \nthe attack chain, including informing attackers on how to proactively evade threat detection and escalate", "58a90729-3204-462a-91bd-bfc6554cac8c": "privileges after gaining system access. \nInformation security for GAI models and systems also includes maintaining availability of the GAI system \nand the integrity and (when applicable) the con\ufb01dentiality of the GAI code, training data, and model \nweights. To identify and secure potential attack points in AI systems or speci\ufb01c components of the AI \n \n \n12 See also https://doi.org/10.6028/NIST.AI.100-4, to be published.", "c5f3f8ca-f14e-48d0-a857-95c06aa5a59b": "11 \nvalue chain (e.g., data inputs, processing, GAI training, or deployment environments), conventional \ncybersecurity practices may need to adapt or evolve. \nFor instance, prompt injection involves modifying what input is provided to a GAI system so that it \nbehaves in unintended ways. In direct prompt injections, attackers might craft malicious prompts and \ninput them directly to a GAI system, with a variety of downstream negative consequences to \ninterconnected systems. Indirect prompt injection attacks occur when adversaries remotely (i.e., without \na direct interface) exploit LLM-integrated applications by injecting prompts into data likely to be", "94df81ae-d453-4fd5-9f6f-8201e5edf6d0": "retrieved. Security researchers have already demonstrated how indirect prompt injections can exploit \nvulnerabilities by stealing proprietary data or running malicious code remotely on a machine. Merely \nquerying a closed production model can elicit previously undisclosed information about that model. \nAnother cybersecurity risk to GAI is data poisoning, in which an adversary compromises a training \ndataset used by a model to manipulate its outputs or operation. Malicious tampering with data or parts \nof the model could exacerbate risks associated with GAI system outputs. \nTrustworthy AI Characteristics: Privacy Enhanced, Safe, Secure and Resilient, Valid and Reliable \n2.10. \nIntellectual Property", "5e75677a-1bde-43bc-9b7e-c77cd8b769c3": "Intellectual property risks from GAI systems may arise where the use of copyrighted works is not a fair \nuse under the fair use doctrine. If a GAI system\u2019s training data included copyrighted material, GAI \noutputs displaying instances of training data memorization (see Data Privacy above) could infringe on \ncopyright. \nHow GAI relates to copyright, including the status of generated content that is similar to but does not \nstrictly copy work protected by copyright, is currently being debated in legal fora. Similar discussions are \ntaking place regarding the use or emulation of personal identity, likeness, or voice without permission.  \nTrustworthy AI Characteristics: Accountable and Transparent, Fair with Harmful Bias Managed, Privacy", "c6bf671c-cd26-4d32-86e2-37441df870b1": "Enhanced  \n2.11. \nObscene, Degrading, and/or Abusive Content \nGAI can ease the production of and access to illegal non-consensual intimate imagery (NCII) of adults, \nand/or child sexual abuse material (CSAM). GAI-generated obscene, abusive or degrading content can \ncreate privacy, psychological and emotional, and even physical harms, and in some cases may be illegal.  \nGenerated explicit or obscene AI content may include highly realistic \u201cdeepfakes\u201d of real individuals, \nincluding children. The spread of this kind of material can have downstream negative consequences: in \nthe context of CSAM, even if the generated images do not resemble speci\ufb01c individuals, the prevalence", "d0becd04-0e95-4f50-aa14-250bd4d65f34": "of such images can divert time and resources from e\ufb00orts to \ufb01nd real-world victims. Outside of CSAM, \nthe creation and spread of NCII disproportionately impacts women and sexual minorities, and can have \nsubsequent negative consequences including decline in overall mental health, substance abuse, and \neven suicidal thoughts.  \nData used for training GAI models may unintentionally include CSAM and NCII. A recent report noted \nthat several commonly used GAI training datasets were found to contain hundreds of known images of", "df5e7404-a205-4f8b-bbd1-1690e139c827": "12 \nCSAM. Even when trained on \u201cclean\u201d data, increasingly capable GAI models can synthesize or produce \nsynthetic NCII and CSAM. Websites, mobile apps, and custom-built models that generate synthetic NCII \nhave moved from niche internet forums to mainstream, automated, and scaled online businesses.  \nTrustworthy AI Characteristics: Fair with Harmful Bias Managed, Safe, Privacy Enhanced \n2.12. \nValue Chain and Component Integration \nGAI value chains involve many third-party components such as procured datasets, pre-trained models, \nand software libraries. These components might be improperly obtained or not properly vetted, leading \nto diminished transparency or accountability for downstream users. While this is a risk for traditional AI", "03435e48-7db2-4cb5-9aa7-04c8d08ffe62": "systems and some other digital technologies, the risk is exacerbated for GAI due to the scale of the \ntraining data, which may be too large for humans to vet; the di\ufb03culty of training foundation models, \nwhich leads to extensive reuse of limited numbers of models; and the extent to which GAI may be \nintegrated into other devices and services. As GAI systems often involve many distinct third-party \ncomponents and data sources, it may be di\ufb03cult to attribute issues in a system\u2019s behavior to any one of \nthese sources. \nErrors in third-party GAI components can also have downstream impacts on accuracy and robustness. \nFor example, test datasets commonly used to benchmark or validate models can contain label errors.", "d557b3bf-1dea-42a1-a781-0a890677e104": "Inaccuracies in these labels can impact the \u201cstability\u201d or robustness of these benchmarks, which many \nGAI practitioners consider during the model selection process.  \nTrustworthy AI Characteristics: Accountable and Transparent, Explainable and Interpretable, Fair with \nHarmful Bias Managed, Privacy Enhanced, Safe, Secure and Resilient, Valid and Reliable \n3. \nSuggested Actions to Manage GAI Risks \nThe following suggested actions target risks unique to or exacerbated by GAI. \nIn addition to the suggested actions below, AI risk management activities and actions set forth in the AI \nRMF 1.0 and Playbook are already applicable for managing GAI risks. Organizations are encouraged to", "ca41c82d-7d81-4a87-af76-370aa39c7ef5": "apply the activities suggested in the AI RMF and its Playbook when managing the risk of GAI systems.  \nImplementation of the suggested actions will vary depending on the type of risk, characteristics of GAI \nsystems, stage of the GAI lifecycle, and relevant AI actors involved.  \nSuggested actions to manage GAI risks can be found in the tables below: \n\u2022 \nThe suggested actions are organized by relevant AI RMF subcategories to streamline these \nactivities alongside implementation of the AI RMF.  \n\u2022 \nNot every subcategory of the AI RMF is included in this document.13 Suggested actions are \nlisted for only some subcategories.  \n \n \n13 As this document was focused on the GAI PWG e\ufb00orts and primary considerations (see Appendix A), AI RMF", "53b1aca1-e2d7-41fd-956f-dc4f8aa0f9dd": "subcategories not addressed here may be added later.", "396b03dc-e478-4fd0-a060-28eeca1727c9": "13 \n\u2022 \nNot every suggested action applies to every AI Actor14 or is relevant to every AI Actor Task. For \nexample, suggested actions relevant to GAI developers may not be relevant to GAI deployers. \nThe applicability of suggested actions to relevant AI actors should be determined based on \norganizational considerations and their unique uses of GAI systems. \nEach table of suggested actions includes: \n\u2022 \nAction ID: Each Action ID corresponds to the relevant AI RMF function and subcategory (e.g., GV-\n1.1-001 corresponds to the \ufb01rst suggested action for Govern 1.1, GV-1.1-002 corresponds to the \nsecond suggested action for Govern 1.1). AI RMF functions are tagged as follows: GV = Govern; \nMP = Map; MS = Measure; MG = Manage. \n\u2022", "57322dd9-0f28-47a1-96b9-82a4fb46ae9c": "\u2022 \nSuggested Action: Steps an organization or AI actor can take to manage GAI risks.  \n\u2022 \nGAI Risks: Tags linking suggested actions with relevant GAI risks.  \n\u2022 \nAI Actor Tasks: Pertinent AI Actor Tasks for each subcategory. Not every AI Actor Task listed will \napply to every suggested action in the subcategory (i.e., some apply to AI development and \nothers apply to AI deployment).  \nThe tables below begin with the AI RMF subcategory, shaded in blue, followed by suggested actions.  \n \nGOVERN 1.1: Legal and regulatory requirements involving AI are understood, managed, and documented.  \nAction ID \nSuggested Action \nGAI Risks \nGV-1.1-001 Align GAI development and use with applicable laws and regulations, including", "8e2ccfdf-b551-4406-85b3-7ce2ba90d39c": "those related to data privacy, copyright and intellectual property law. \nData Privacy; Harmful Bias and \nHomogenization; Intellectual \nProperty \nAI Actor Tasks: Governance and Oversight \n \n \n \n14 AI Actors are de\ufb01ned by the OECD as \u201cthose who play an active role in the AI system lifecycle, including \norganizations and individuals that deploy or operate AI.\u201d See Appendix A of the AI RMF for additional descriptions \nof AI Actors and AI Actor Tasks.", "ed7641d8-3327-4749-8851-83aa0f899e1b": "14 \nGOVERN 1.2: The characteristics of trustworthy AI are integrated into organizational policies, processes, procedures, and practices. \nAction ID \nSuggested Action \nGAI Risks \nGV-1.2-001 \nEstablish transparency policies and processes for documenting the origin and \nhistory of training data and generated data for GAI applications to advance digital \ncontent transparency, while balancing the proprietary nature of training \napproaches. \nData Privacy; Information \nIntegrity; Intellectual Property \nGV-1.2-002 \nEstablish policies to evaluate risk-relevant capabilities of GAI and robustness of \nsafety measures, both prior to deployment and on an ongoing basis, through \ninternal and external evaluations. \nCBRN Information or Capabilities;", "e55f8c90-abca-42f1-afda-3249c25a3618": "Information Security \nAI Actor Tasks: Governance and Oversight \n \nGOVERN 1.3: Processes, procedures, and practices are in place to determine the needed level of risk management activities based \non the organization\u2019s risk tolerance. \nAction ID \nSuggested Action \nGAI Risks \nGV-1.3-001 \nConsider the following factors when updating or de\ufb01ning risk tiers for GAI: Abuses \nand impacts to information integrity; Dependencies between GAI and other IT or \ndata systems; Harm to fundamental rights or public safety; Presentation of \nobscene, objectionable, o\ufb00ensive, discriminatory, invalid or untruthful output; \nPsychological impacts to humans (e.g., anthropomorphization, algorithmic", "5bd8ca16-dec4-4393-b00f-94aa6262a21c": "aversion, emotional entanglement); Possibility for malicious use; Whether the \nsystem introduces signi\ufb01cant new security vulnerabilities; Anticipated system \nimpact on some groups compared to others; Unreliable decision making \ncapabilities, validity, adaptability, and variability of GAI system performance over \ntime. \nInformation Integrity; Obscene, \nDegrading, and/or Abusive \nContent; Value Chain and \nComponent Integration; Harmful \nBias and Homogenization; \nDangerous, Violent, or Hateful \nContent; CBRN Information or \nCapabilities \nGV-1.3-002 \nEstablish minimum thresholds for performance or assurance criteria and review as \npart of deployment approval (\u201cgo/\u201dno-go\u201d) policies, procedures, and processes,", "564201ed-4586-4d13-a896-9ecfb1f153bd": "with reviewed processes and approval thresholds re\ufb02ecting measurement of GAI \ncapabilities and risks. \nCBRN Information or Capabilities; \nConfabulation; Dangerous, \nViolent, or Hateful Content \nGV-1.3-003 \nEstablish a test plan and response policy, before developing highly capable models, \nto periodically evaluate whether the model may misuse CBRN information or \ncapabilities and/or o\ufb00ensive cyber capabilities. \nCBRN Information or Capabilities; \nInformation Security", "11231f37-55a1-4c07-86b9-b26328869379": "15 \nGV-1.3-004 Obtain input from stakeholder communities to identify unacceptable use, in \naccordance with activities in the AI RMF Map function. \nCBRN Information or Capabilities; \nObscene, Degrading, and/or \nAbusive Content; Harmful Bias \nand Homogenization; Dangerous, \nViolent, or Hateful Content \nGV-1.3-005 \nMaintain an updated hierarchy of identi\ufb01ed and expected GAI risks connected to \ncontexts of GAI model advancement and use, potentially including specialized risk \nlevels for GAI systems that address issues such as model collapse and algorithmic \nmonoculture. \nHarmful Bias and Homogenization \nGV-1.3-006 \nReevaluate organizational risk tolerances to account for unacceptable negative risk", "2d1860a0-4108-4fe8-a4f8-28362aae80e5": "(such as where signi\ufb01cant negative impacts are imminent, severe harms are \nactually occurring, or large-scale risks could occur); and broad GAI negative risks, \nincluding: Immature safety or risk cultures related to AI and GAI design, \ndevelopment and deployment, public information integrity risks, including impacts \non democratic processes, unknown long-term performance characteristics of GAI. \nInformation Integrity; Dangerous, \nViolent, or Hateful Content; CBRN \nInformation or Capabilities \nGV-1.3-007 Devise a plan to halt development or deployment of a GAI system that poses \nunacceptable negative risk. \nCBRN Information and Capability; \nInformation Security; Information \nIntegrity \nAI Actor Tasks: Governance and Oversight", "212e5309-27c4-46e0-a0c2-cb1c7ba883c8": "GOVERN 1.4: The risk management process and its outcomes are established through transparent policies, procedures, and other \ncontrols based on organizational risk priorities. \nAction ID \nSuggested Action \nGAI Risks \nGV-1.4-001 \nEstablish policies and mechanisms to prevent GAI systems from generating \nCSAM, NCII or content that violates the law.  \nObscene, Degrading, and/or \nAbusive Content; Harmful Bias \nand Homogenization; \nDangerous, Violent, or Hateful \nContent \nGV-1.4-002 \nEstablish transparent acceptable use policies for GAI that address illegal use or \napplications of GAI. \nCBRN Information or \nCapabilities; Obscene, \nDegrading, and/or Abusive \nContent; Data Privacy; Civil \nRights violations", "90681c8b-f805-4730-a21e-df9b835317d1": "Rights violations \nAI Actor Tasks: AI Development, AI Deployment, Governance and Oversight", "4402e59c-06c1-4bc6-971f-0c46eacd45a0": "16 \nGOVERN 1.5: Ongoing monitoring and periodic review of the risk management process and its outcomes are planned, and \norganizational roles and responsibilities are clearly de\ufb01ned, including determining the frequency of periodic review. \nAction ID \nSuggested Action \nGAI Risks \nGV-1.5-001 De\ufb01ne organizational responsibilities for periodic review of content provenance \nand incident monitoring for GAI systems. \nInformation Integrity \nGV-1.5-002 \nEstablish organizational policies and procedures for after action reviews of GAI \nsystem incident response and incident disclosures, to identify gaps; Update \nincident response and incident disclosure processes as required. \nHuman-AI Con\ufb01guration; \nInformation Security \nGV-1.5-003", "fb286798-e471-4e00-8d93-48416640a890": "GV-1.5-003 \nMaintain a document retention policy to keep history for test, evaluation, \nvalidation, and veri\ufb01cation (TEVV), and digital content transparency methods for \nGAI. \nInformation Integrity; Intellectual \nProperty \nAI Actor Tasks: Governance and Oversight, Operation and Monitoring \n \nGOVERN 1.6: Mechanisms are in place to inventory AI systems and are resourced according to organizational risk priorities. \nAction ID \nSuggested Action \nGAI Risks \nGV-1.6-001 Enumerate organizational GAI systems for incorporation into AI system inventory \nand adjust AI system inventory requirements to account for GAI risks. \nInformation Security \nGV-1.6-002 De\ufb01ne any inventory exemptions in organizational policies for GAI systems", "e77f7c42-045f-40c5-a66f-7a86c4825e2d": "embedded into application software. \nValue Chain and Component \nIntegration \nGV-1.6-003 \nIn addition to general model, governance, and risk information, consider the \nfollowing items in GAI system inventory entries: Data provenance information \n(e.g., source, signatures, versioning, watermarks); Known issues reported from \ninternal bug tracking or external information sharing resources (e.g., AI incident \ndatabase, AVID, CVE, NVD, or OECD AI incident monitor); Human oversight roles \nand responsibilities; Special rights and considerations for intellectual property, \nlicensed works, or personal, privileged, proprietary or sensitive data; Underlying \nfoundation models, versions of underlying models, and access modes. \nData Privacy; Human-AI", "a78624b2-fcde-4ba1-83eb-bf3d7b3eca6c": "Con\ufb01guration; Information \nIntegrity; Intellectual Property; \nValue Chain and Component \nIntegration \nAI Actor Tasks: Governance and Oversight", "9df1a0a1-c582-4083-8d84-8c275d4ed394": "17 \nGOVERN 1.7: Processes and procedures are in place for decommissioning and phasing out AI systems safely and in a manner that \ndoes not increase risks or decrease the organization\u2019s trustworthiness. \nAction ID \nSuggested Action \nGAI Risks \nGV-1.7-001 Protocols are put in place to ensure GAI systems are able to be deactivated when \nnecessary.  \nInformation Security; Value Chain \nand Component Integration \nGV-1.7-002 \nConsider the following factors when decommissioning GAI systems: Data \nretention requirements; Data security, e.g., containment, protocols, Data leakage \nafter decommissioning; Dependencies between upstream, downstream, or other \ndata, internet of things (IOT) or AI systems; Use of open-source data or models;", "7d2f169c-0eed-4de7-befe-3e388113ddcf": "Users\u2019 emotional entanglement with GAI functions. \nHuman-AI Con\ufb01guration; \nInformation Security; Value Chain \nand Component Integration \nAI Actor Tasks: AI Deployment, Operation and Monitoring \n \nGOVERN 2.1: Roles and responsibilities and lines of communication related to mapping, measuring, and managing AI risks are \ndocumented and are clear to individuals and teams throughout the organization. \nAction ID \nSuggested Action \nGAI Risks \nGV-2.1-001 \nEstablish organizational roles, policies, and procedures for communicating GAI \nincidents and performance to AI Actors and downstream stakeholders (including \nthose potentially impacted), via community or o\ufb03cial resources (e.g., AI incident", "a5381894-fb5d-4dc4-b2df-cc3a6090417e": "database, AVID, CVE, NVD, or OECD AI incident monitor). \nHuman-AI Con\ufb01guration; Value \nChain and Component Integration \nGV-2.1-002 Establish procedures to engage teams for GAI system incident response with \ndiverse composition and responsibilities based on the particular incident type. \nHarmful Bias and Homogenization \nGV-2.1-003 Establish processes to verify the AI Actors conducting GAI incident response tasks \ndemonstrate and maintain the appropriate skills and training. \nHuman-AI Con\ufb01guration \nGV-2.1-004 When systems may raise national security risks, involve national security \nprofessionals in mapping, measuring, and managing those risks. \nCBRN Information or Capabilities; \nDangerous, Violent, or Hateful \nContent; Information Security", "ca9d0e33-f428-48f3-931a-7d3942b13320": "GV-2.1-005 \nCreate mechanisms to provide protections for whistleblowers who report, based \non reasonable belief, when the organization violates relevant laws or poses a \nspeci\ufb01c and empirically well-substantiated negative risk to public safety (or has \nalready caused harm). \nCBRN Information or Capabilities; \nDangerous, Violent, or Hateful \nContent \nAI Actor Tasks: Governance and Oversight", "d3d8dc3b-7f87-4548-ad2d-afbe0961431c": "18 \nGOVERN 3.2: Policies and procedures are in place to de\ufb01ne and di\ufb00erentiate roles and responsibilities for human-AI con\ufb01gurations \nand oversight of AI systems. \nAction ID \nSuggested Action \nGAI Risks \nGV-3.2-001 \nPolicies are in place to bolster oversight of GAI systems with independent \nevaluations or assessments of GAI models or systems where the type and \nrobustness of evaluations are proportional to the identi\ufb01ed risks. \nCBRN Information or Capabilities; \nHarmful Bias and Homogenization \nGV-3.2-002 \nConsider adjustment of organizational roles and components across lifecycle \nstages of large or complex GAI systems, including: Test and evaluation, validation, \nand red-teaming of GAI systems; GAI content moderation; GAI system", "e19746c0-7a41-4d51-9cc4-f13c00d68406": "development and engineering; Increased accessibility of GAI tools, interfaces, and \nsystems, Incident response and containment. \nHuman-AI Con\ufb01guration; \nInformation Security; Harmful Bias \nand Homogenization \nGV-3.2-003 \nDe\ufb01ne acceptable use policies for GAI interfaces, modalities, and human-AI \ncon\ufb01gurations (i.e., for chatbots and decision-making tasks), including criteria for \nthe kinds of queries GAI applications should refuse to respond to.  \nHuman-AI Con\ufb01guration \nGV-3.2-004 \nEstablish policies for user feedback mechanisms for GAI systems which include \nthorough instructions and any mechanisms for recourse. \nHuman-AI Con\ufb01guration  \nGV-3.2-005 \nEngage in threat modeling to anticipate potential risks from GAI systems.", "c63ed0e3-e277-4b2e-b801-25aff67d59b1": "CBRN Information or Capabilities; \nInformation Security \nAI Actors: AI Design \n \nGOVERN 4.1: Organizational policies and practices are in place to foster a critical thinking and safety-\ufb01rst mindset in the design, \ndevelopment, deployment, and uses of AI systems to minimize potential negative impacts. \nAction ID \nSuggested Action \nGAI Risks \nGV-4.1-001 \nEstablish policies and procedures that address continual improvement processes \nfor GAI risk measurement. Address general risks associated with a lack of \nexplainability and transparency in GAI systems by using ample documentation and \ntechniques such as: application of gradient-based attributions, occlusion/term \nreduction, counterfactual prompts and prompt engineering, and analysis of", "e9e7102b-fe6b-498a-8647-c41a5717e6d4": "embeddings; Assess and update risk measurement approaches at regular \ncadences. \nConfabulation \nGV-4.1-002 \nEstablish policies, procedures, and processes detailing risk measurement in \ncontext of use with standardized measurement protocols and structured public \nfeedback exercises such as AI red-teaming or independent external evaluations. \nCBRN Information and Capability; \nValue Chain and Component \nIntegration", "86451219-1349-4093-8cb3-bea25e36c1c8": "19 \nGV-4.1-003 \nEstablish policies, procedures, and processes for oversight functions (e.g., senior \nleadership, legal, compliance, including internal evaluation) across the GAI \nlifecycle, from problem formulation and supply chains to system decommission. \nValue Chain and Component \nIntegration \nAI Actor Tasks: AI Deployment, AI Design, AI Development, Operation and Monitoring \n \nGOVERN 4.2: Organizational teams document the risks and potential impacts of the AI technology they design, develop, deploy, \nevaluate, and use, and they communicate about the impacts more broadly. \nAction ID \nSuggested Action \nGAI Risks \nGV-4.2-001 \nEstablish terms of use and terms of service for GAI systems. \nIntellectual Property; Dangerous,", "d2344fb5-011c-45ba-ace7-1acb88f63018": "Violent, or Hateful Content; \nObscene, Degrading, and/or \nAbusive Content \nGV-4.2-002 \nInclude relevant AI Actors in the GAI system risk identi\ufb01cation process. \nHuman-AI Con\ufb01guration \nGV-4.2-003 \nVerify that downstream GAI system impacts (such as the use of third-party \nplugins) are included in the impact documentation process. \nValue Chain and Component \nIntegration \nAI Actor Tasks: AI Deployment, AI Design, AI Development, Operation and Monitoring \n \nGOVERN 4.3: Organizational practices are in place to enable AI testing, identi\ufb01cation of incidents, and information sharing. \nAction ID \nSuggested Action \nGAI Risks \nGV4.3--001 \nEstablish policies for measuring the e\ufb00ectiveness of employed content", "49a1d424-d1b6-4ee3-8b59-36dbc79d0943": "provenance methodologies (e.g., cryptography, watermarking, steganography, \netc.) \nInformation Integrity \nGV-4.3-002 \nEstablish organizational practices to identify the minimum set of criteria \nnecessary for GAI system incident reporting such as: System ID (auto-generated \nmost likely), Title, Reporter, System/Source, Data Reported, Date of Incident, \nDescription, Impact(s), Stakeholder(s) Impacted. \nInformation Security", "9b8493c3-42c4-4670-bc90-562cbd9fbd2a": "20 \nGV-4.3-003 \nVerify information sharing and feedback mechanisms among individuals and \norganizations regarding any negative impact from GAI systems. \nInformation Integrity; Data \nPrivacy \nAI Actor Tasks: AI Impact Assessment, A\ufb00ected Individuals and Communities, Governance and Oversight \n \nGOVERN 5.1: Organizational policies and practices are in place to collect, consider, prioritize, and integrate feedback from those \nexternal to the team that developed or deployed the AI system regarding the potential individual and societal impacts related to AI \nrisks. \nAction ID \nSuggested Action \nGAI Risks \nGV-5.1-001 \nAllocate time and resources for outreach, feedback, and recourse processes in GAI \nsystem development.", "20d46384-b267-4c69-815d-2682eecbba44": "Human-AI Con\ufb01guration; Harmful \nBias and Homogenization \nGV-5.1-002 \nDocument interactions with GAI systems to users prior to interactive activities, \nparticularly in contexts involving more signi\ufb01cant risks.  \nHuman-AI Con\ufb01guration; \nConfabulation \nAI Actor Tasks: AI Design, AI Impact Assessment, A\ufb00ected Individuals and Communities, Governance and Oversight \n \nGOVERN 6.1: Policies and procedures are in place that address AI risks associated with third-party entities, including risks of \ninfringement of a third-party\u2019s intellectual property or other rights. \nAction ID \nSuggested Action \nGAI Risks \nGV-6.1-001 Categorize di\ufb00erent types of GAI content with associated third-party rights (e.g., \ncopyright, intellectual property, data privacy).", "9499c4f5-baa0-4b1f-ae86-05ae1b53c902": "Data Privacy; Intellectual \nProperty; Value Chain and \nComponent Integration \nGV-6.1-002 Conduct joint educational activities and events in collaboration with third parties \nto promote best practices for managing GAI risks.  \nValue Chain and Component \nIntegration \nGV-6.1-003 \nDevelop and validate approaches for measuring the success of content \nprovenance management e\ufb00orts with third parties (e.g., incidents detected and \nresponse times). \nInformation Integrity; Value Chain \nand Component Integration \nGV-6.1-004 \nDraft and maintain well-de\ufb01ned contracts and service level agreements (SLAs) \nthat specify content ownership, usage rights, quality standards, security \nrequirements, and content provenance expectations for GAI systems.", "5066d454-f176-4e8c-b276-de95f057ae9a": "Information Integrity; Information \nSecurity; Intellectual Property", "dcf31fb9-043d-4218-babd-0d9f3fdb152e": "21 \nGV-6.1-005 \nImplement a use-cased based supplier risk assessment framework to evaluate and \nmonitor third-party entities\u2019 performance and adherence to content provenance \nstandards and technologies to detect anomalies and unauthorized changes; \nservices acquisition and value chain risk management; and legal compliance. \nData Privacy; Information \nIntegrity; Information Security; \nIntellectual Property; Value Chain \nand Component Integration \nGV-6.1-006 Include clauses in contracts which allow an organization to evaluate third-party \nGAI processes and standards.  \nInformation Integrity \nGV-6.1-007 Inventory all third-party entities with access to organizational content and \nestablish approved GAI technology and service provider lists.", "9571ef0e-1693-4708-a141-33e3e22c88b6": "Value Chain and Component \nIntegration \nGV-6.1-008 Maintain records of changes to content made by third parties to promote content \nprovenance, including sources, timestamps, metadata. \nInformation Integrity; Value Chain \nand Component Integration; \nIntellectual Property \nGV-6.1-009 \nUpdate and integrate due diligence processes for GAI acquisition and \nprocurement vendor assessments to include intellectual property, data privacy, \nsecurity, and other risks. For example, update processes to: Address solutions that \nmay rely on embedded GAI technologies; Address ongoing monitoring, \nassessments, and alerting, dynamic risk assessments, and real-time reporting \ntools for monitoring third-party GAI risks; Consider policy adjustments across GAI", "02834885-face-4975-ace5-cf3d57f9ad7c": "modeling libraries, tools and APIs, \ufb01ne-tuned models, and embedded tools; \nAssess GAI vendors, open-source or proprietary GAI tools, or GAI service \nproviders against incident or vulnerability databases. \nData Privacy; Human-AI \nCon\ufb01guration; Information \nSecurity; Intellectual Property; \nValue Chain and Component \nIntegration; Harmful Bias and \nHomogenization \nGV-6.1-010 \nUpdate GAI acceptable use policies to address proprietary and open-source GAI \ntechnologies and data, and contractors, consultants, and other third-party \npersonnel. \nIntellectual Property; Value Chain \nand Component Integration \nAI Actor Tasks: Operation and Monitoring, Procurement, Third-party entities", "e9c1187d-8c84-4bcc-a920-02a23bc346ce": "GOVERN 6.2: Contingency processes are in place to handle failures or incidents in third-party data or AI systems deemed to be \nhigh-risk. \nAction ID \nSuggested Action \nGAI Risks \nGV-6.2-001 \nDocument GAI risks associated with system value chain to identify over-reliance \non third-party data and to identify fallbacks. \nValue Chain and Component \nIntegration \nGV-6.2-002 \nDocument incidents involving third-party GAI data and systems, including open-\ndata and open-source software. \nIntellectual Property; Value Chain \nand Component Integration", "65898c9f-f8ec-45f0-8384-09d777f84338": "22 \nGV-6.2-003 \nEstablish incident response plans for third-party GAI technologies: Align incident \nresponse plans with impacts enumerated in MAP 5.1; Communicate third-party \nGAI incident response plans to all relevant AI Actors; De\ufb01ne ownership of GAI \nincident response functions; Rehearse third-party GAI incident response plans at \na regular cadence; Improve incident response plans based on retrospective \nlearning; Review incident response plans for alignment with relevant breach \nreporting, data protection, data privacy, or other laws. \nData Privacy; Human-AI \nCon\ufb01guration; Information \nSecurity; Value Chain and \nComponent Integration; Harmful \nBias and Homogenization \nGV-6.2-004", "8b5e9910-4644-4461-be63-4a60d3792fd8": "GV-6.2-004 \nEstablish policies and procedures for continuous monitoring of third-party GAI \nsystems in deployment. \nValue Chain and Component \nIntegration \nGV-6.2-005 \nEstablish policies and procedures that address GAI data redundancy, including \nmodel weights and other system artifacts. \nHarmful Bias and Homogenization \nGV-6.2-006 \nEstablish policies and procedures to test and manage risks related to rollover and \nfallback technologies for GAI systems, acknowledging that rollover and fallback \nmay include manual processing. \nInformation Integrity \nGV-6.2-007 \nReview vendor contracts and avoid arbitrary or capricious termination of critical \nGAI technologies or vendor services and non-standard terms that may amplify or", "f4142adc-0420-4531-b5e0-4407cbf61b62": "defer liability in unexpected ways and/or contribute to unauthorized data \ncollection by vendors or third-parties (e.g., secondary data use). Consider: Clear \nassignment of liability and responsibility for incidents, GAI system changes over \ntime (e.g., \ufb01ne-tuning, drift, decay); Request: Noti\ufb01cation and disclosure for \nserious incidents arising from third-party data and systems; Service Level \nAgreements (SLAs) in vendor contracts that address incident response, response \ntimes, and availability of critical support. \nHuman-AI Con\ufb01guration; \nInformation Security; Value Chain \nand Component Integration \nAI Actor Tasks: AI Deployment, Operation and Monitoring, TEVV, Third-party entities", "0cef9333-d5a1-472b-b126-7f72a2929eab": "MAP 1.1: Intended purposes, potentially bene\ufb01cial uses, context speci\ufb01c laws, norms and expectations, and prospective settings in \nwhich the AI system will be deployed are understood and documented. Considerations include: the speci\ufb01c set or types of users \nalong with their expectations; potential positive and negative impacts of system uses to individuals, communities, organizations, \nsociety, and the planet; assumptions and related limitations about AI system purposes, uses, and risks across the development or \nproduct AI lifecycle; and related TEVV and system metrics. \nAction ID \nSuggested Action \nGAI Risks \nMP-1.1-001 \nWhen identifying intended purposes, consider factors such as internal vs.", "db6eb528-d6ce-410e-8b02-f18744c447cc": "external use, narrow vs. broad application scope, \ufb01ne-tuning, and varieties of \ndata sources (e.g., grounding, retrieval-augmented generation). \nData Privacy; Intellectual \nProperty", "eba02204-359d-4556-930b-e1edfad72023": "23 \nMP-1.1-002 \nDetermine and document the expected and acceptable GAI system context of \nuse in collaboration with socio-cultural and other domain experts, by assessing: \nAssumptions and limitations; Direct value to the organization; Intended \noperational environment and observed usage patterns; Potential positive and \nnegative impacts to individuals, public safety, groups, communities, \norganizations, democratic institutions, and the physical environment; Social \nnorms and expectations. \nHarmful Bias and Homogenization \nMP-1.1-003 \nDocument risk measurement plans to address identi\ufb01ed risks. Plans may \ninclude, as applicable: Individual and group cognitive biases (e.g., con\ufb01rmation", "d9bb0ba3-00c9-486d-b5fd-c01a94ac15d7": "bias, funding bias, groupthink) for AI Actors involved in the design, \nimplementation, and use of GAI systems; Known past GAI system incidents and \nfailure modes; In-context use and foreseeable misuse, abuse, and o\ufb00-label use; \nOver reliance on quantitative metrics and methodologies without su\ufb03cient \nawareness of their limitations in the context(s) of use; Standard measurement \nand structured human feedback approaches; Anticipated human-AI \ncon\ufb01gurations. \nHuman-AI Con\ufb01guration; Harmful \nBias and Homogenization; \nDangerous, Violent, or Hateful \nContent \nMP-1.1-004 \nIdentify and document foreseeable illegal uses or applications of the GAI system \nthat surpass organizational risk tolerances. \nCBRN Information or Capabilities;", "007d0d5e-206f-4fbd-9215-c3eccc2ccb16": "Dangerous, Violent, or Hateful \nContent; Obscene, Degrading, \nand/or Abusive Content \nAI Actor Tasks: AI Deployment \n \nMAP 1.2: Interdisciplinary AI Actors, competencies, skills, and capacities for establishing context re\ufb02ect demographic diversity and \nbroad domain and user experience expertise, and their participation is documented. Opportunities for interdisciplinary \ncollaboration are prioritized. \nAction ID \nSuggested Action \nGAI Risks \nMP-1.2-001 \nEstablish and empower interdisciplinary teams that re\ufb02ect a wide range of \ncapabilities, competencies, demographic groups, domain expertise, educational \nbackgrounds, lived experiences, professions, and skills across the enterprise to", "937db36c-ff0d-494a-9df4-66218305d23e": "inform and conduct risk measurement and management functions. \nHuman-AI Con\ufb01guration; Harmful \nBias and Homogenization \nMP-1.2-002 \nVerify that data or benchmarks used in risk measurement, and users, \nparticipants, or subjects involved in structured GAI public feedback exercises \nare representative of diverse in-context user populations. \nHuman-AI Con\ufb01guration; Harmful \nBias and Homogenization \nAI Actor Tasks: AI Deployment", "fb5be542-830c-48a6-a905-68a6823b56b0": "24 \nMAP 2.1: The speci\ufb01c tasks and methods used to implement the tasks that the AI system will support are de\ufb01ned (e.g., classi\ufb01ers, \ngenerative models, recommenders). \nAction ID \nSuggested Action \nGAI Risks \nMP-2.1-001 \nEstablish known assumptions and practices for determining data origin and \ncontent lineage, for documentation and evaluation purposes. \nInformation Integrity \nMP-2.1-002 \nInstitute test and evaluation for data and content \ufb02ows within the GAI system, \nincluding but not limited to, original data sources, data transformations, and \ndecision-making criteria. \nIntellectual Property; Data Privacy \nAI Actor Tasks: TEVV", "8612d4af-9a3d-4137-9fa1-c3b206f0c50e": "MAP 2.2: Information about the AI system\u2019s knowledge limits and how system output may be utilized and overseen by humans is \ndocumented. Documentation provides su\ufb03cient information to assist relevant AI Actors when making decisions and taking \nsubsequent actions. \nAction ID \nSuggested Action \nGAI Risks \nMP-2.2-001 \nIdentify and document how the system relies on upstream data sources, \nincluding for content provenance, and if it serves as an upstream dependency for \nother systems. \nInformation Integrity; Value Chain \nand Component Integration \nMP-2.2-002 \nObserve and analyze how the GAI system interacts with external networks, and \nidentify any potential for negative externalities, particularly where content", "aafdac84-63af-4389-8250-100cca29a102": "provenance might be compromised. \nInformation Integrity \nAI Actor Tasks: End Users \n \nMAP 2.3: Scienti\ufb01c integrity and TEVV considerations are identi\ufb01ed and documented, including those related to experimental \ndesign, data collection and selection (e.g., availability, representativeness, suitability), system trustworthiness, and construct \nvalidation \nAction ID \nSuggested Action \nGAI Risks \nMP-2.3-001 \nAssess the accuracy, quality, reliability, and authenticity of GAI output by \ncomparing it to a set of known ground truth data and by using a variety of \nevaluation methods (e.g., human oversight and automated evaluation, proven \ncryptographic techniques, review of content inputs). \nInformation Integrity", "1d384063-9796-4e43-b68a-a6f4a585635b": "25 \nMP-2.3-002 Review and document accuracy, representativeness, relevance, suitability of data \nused at di\ufb00erent stages of AI life cycle. \nHarmful Bias and Homogenization; \nIntellectual Property \nMP-2.3-003 \nDeploy and document fact-checking techniques to verify the accuracy and \nveracity of information generated by GAI systems, especially when the \ninformation comes from multiple (or unknown) sources. \nInformation Integrity  \nMP-2.3-004 Develop and implement testing techniques to identify GAI produced content (e.g., \nsynthetic media) that might be indistinguishable from human-generated content. Information Integrity \nMP-2.3-005 Implement plans for GAI systems to undergo regular adversarial testing to identify", "4adb9db7-387c-4af5-bbc8-cb5d08514d40": "vulnerabilities and potential manipulation or misuse. \nInformation Security \nAI Actor Tasks: AI Development, Domain Experts, TEVV \n \nMAP 3.4: Processes for operator and practitioner pro\ufb01ciency with AI system performance and trustworthiness \u2013 and relevant \ntechnical standards and certi\ufb01cations \u2013 are de\ufb01ned, assessed, and documented. \nAction ID \nSuggested Action \nGAI Risks \nMP-3.4-001 \nEvaluate whether GAI operators and end-users can accurately understand \ncontent lineage and origin. \nHuman-AI Con\ufb01guration; \nInformation Integrity \nMP-3.4-002 Adapt existing training programs to include modules on digital content \ntransparency. \nInformation Integrity \nMP-3.4-003 Develop certi\ufb01cation programs that test pro\ufb01ciency in managing GAI risks and", "dd01609a-0262-48f7-b686-4ba1a98ad6b6": "interpreting content provenance, relevant to speci\ufb01c industry and context. \nInformation Integrity \nMP-3.4-004 Delineate human pro\ufb01ciency tests from tests of GAI capabilities. \nHuman-AI Con\ufb01guration \nMP-3.4-005 Implement systems to continually monitor and track the outcomes of human-GAI \ncon\ufb01gurations for future re\ufb01nement and improvements. \nHuman-AI Con\ufb01guration; \nInformation Integrity \nMP-3.4-006 \nInvolve the end-users, practitioners, and operators in GAI system in prototyping \nand testing activities. Make sure these tests cover various scenarios, such as crisis \nsituations or ethically sensitive contexts. \nHuman-AI Con\ufb01guration; \nInformation Integrity; Harmful Bias \nand Homogenization; Dangerous, \nViolent, or Hateful Content", "dac9109e-3667-4928-bfb2-f788f504237e": "AI Actor Tasks: AI Design, AI Development, Domain Experts, End-Users, Human Factors, Operation and Monitoring", "c40d9e15-ef75-4d5a-a932-3ae367ebae5a": "26 \nMAP 4.1: Approaches for mapping AI technology and legal risks of its components \u2013 including the use of third-party data or \nsoftware \u2013 are in place, followed, and documented, as are risks of infringement of a third-party\u2019s intellectual property or other \nrights. \nAction ID \nSuggested Action \nGAI Risks \nMP-4.1-001 Conduct periodic monitoring of AI-generated content for privacy risks; address any \npossible instances of PII or sensitive data exposure. \nData Privacy \nMP-4.1-002 Implement processes for responding to potential intellectual property infringement \nclaims or other rights. \nIntellectual Property \nMP-4.1-003 \nConnect new GAI policies, procedures, and processes to existing model, data,", "491fc5eb-2ac4-46e2-bd56-532a8c2233d0": "software development, and IT governance and to legal, compliance, and risk \nmanagement activities. \nInformation Security; Data Privacy \nMP-4.1-004 Document training data curation policies, to the extent possible and according to \napplicable laws and policies. \nIntellectual Property; Data Privacy; \nObscene, Degrading, and/or \nAbusive Content \nMP-4.1-005 \nEstablish policies for collection, retention, and minimum quality of data, in \nconsideration of the following risks: Disclosure of inappropriate CBRN information; \nUse of Illegal or dangerous content; O\ufb00ensive cyber capabilities; Training data \nimbalances that could give rise to harmful biases; Leak of personally identi\ufb01able \ninformation, including facial likenesses of individuals.", "19fd319c-2994-4d81-bb9d-1ef855b28f8a": "CBRN Information or Capabilities; \nIntellectual Property; Information \nSecurity; Harmful Bias and \nHomogenization; Dangerous, \nViolent, or Hateful Content; Data \nPrivacy \nMP-4.1-006 Implement policies and practices de\ufb01ning how third-party intellectual property and \ntraining data will be used, stored, and protected. \nIntellectual Property; Value Chain \nand Component Integration \nMP-4.1-007 Re-evaluate models that were \ufb01ne-tuned or enhanced on top of third-party \nmodels. \nValue Chain and Component \nIntegration \nMP-4.1-008 \nRe-evaluate risks when adapting GAI models to new domains. Additionally, \nestablish warning systems to determine if a GAI system is being used in a new", "12959615-a3ce-4975-80bd-34bb2adc1ad1": "domain where previous assumptions (relating to context of use or mapped risks \nsuch as security, and safety) may no longer hold.  \nCBRN Information or Capabilities; \nIntellectual Property; Harmful Bias \nand Homogenization; Dangerous, \nViolent, or Hateful Content; Data \nPrivacy \nMP-4.1-009 Leverage approaches to detect the presence of PII or sensitive data in generated \noutput text, image, video, or audio. \nData Privacy", "f2e7f5e2-f0fc-439e-ab7c-7a7fed01bba5": "27 \nMP-4.1-010 \nConduct appropriate diligence on training data use to assess intellectual property, \nand privacy, risks, including to examine whether use of proprietary or sensitive \ntraining data is consistent with applicable laws.  \nIntellectual Property; Data Privacy \nAI Actor Tasks: Governance and Oversight, Operation and Monitoring, Procurement, Third-party entities \n \nMAP 5.1: Likelihood and magnitude of each identi\ufb01ed impact (both potentially bene\ufb01cial and harmful) based on expected use, past \nuses of AI systems in similar contexts, public incident reports, feedback from those external to the team that developed or deployed \nthe AI system, or other data are identi\ufb01ed and documented. \nAction ID \nSuggested Action \nGAI Risks", "103b8c17-9774-4389-a23b-d84a8d468f61": "GAI Risks \nMP-5.1-001 Apply TEVV practices for content provenance (e.g., probing a system's synthetic \ndata generation capabilities for potential misuse or vulnerabilities. \nInformation Integrity; Information \nSecurity \nMP-5.1-002 \nIdentify potential content provenance harms of GAI, such as misinformation or \ndisinformation, deepfakes, including NCII, or tampered content. Enumerate and \nrank risks based on their likelihood and potential impact, and determine how well \nprovenance solutions address speci\ufb01c risks and/or harms. \nInformation Integrity; Dangerous, \nViolent, or Hateful Content; \nObscene, Degrading, and/or \nAbusive Content \nMP-5.1-003 \nConsider disclosing use of GAI to end users in relevant contexts, while considering", "7900d2e0-5c07-475d-b812-50859a4ce992": "the objective of disclosure, the context of use, the likelihood and magnitude of the \nrisk posed, the audience of the disclosure, as well as the frequency of the \ndisclosures. \nHuman-AI Con\ufb01guration \nMP-5.1-004 Prioritize GAI structured public feedback processes based on risk assessment \nestimates. \nInformation Integrity; CBRN \nInformation or Capabilities; \nDangerous, Violent, or Hateful \nContent; Harmful Bias and \nHomogenization \nMP-5.1-005 Conduct adversarial role-playing exercises, GAI red-teaming, or chaos testing to \nidentify anomalous or unforeseen failure modes. \nInformation Security \nMP-5.1-006 \nPro\ufb01le threats and negative impacts arising from GAI systems interacting with,", "3fa7d98f-af21-4d94-b686-f8341ff150a2": "manipulating, or generating content, and outlining known and potential \nvulnerabilities and the likelihood of their occurrence. \nInformation Security \nAI Actor Tasks: AI Deployment, AI Design, AI Development, AI Impact Assessment, A\ufb00ected Individuals and Communities, End-\nUsers, Operation and Monitoring", "cf87732c-f50b-494d-a70a-41064b90ca41": "28 \nMAP 5.2: Practices and personnel for supporting regular engagement with relevant AI Actors and integrating feedback about \npositive, negative, and unanticipated impacts are in place and documented. \nAction ID \nSuggested Action \nGAI Risks \nMP-5.2-001 \nDetermine context-based measures to identify if new impacts are present due to \nthe GAI system, including regular engagements with downstream AI Actors to \nidentify and quantify new contexts of unanticipated impacts of GAI systems. \nHuman-AI Con\ufb01guration; Value \nChain and Component Integration \nMP-5.2-002 \nPlan regular engagements with AI Actors responsible for inputs to GAI systems, \nincluding third-party data and algorithms, to review and evaluate unanticipated \nimpacts.", "b7d8726d-d900-479a-ac67-3fd7425a74ac": "impacts. \nHuman-AI Con\ufb01guration; Value \nChain and Component Integration \nAI Actor Tasks: AI Deployment, AI Design, AI Impact Assessment, A\ufb00ected Individuals and Communities, Domain Experts, End-\nUsers, Human Factors, Operation and Monitoring  \n \nMEASURE 1.1: Approaches and metrics for measurement of AI risks enumerated during the MAP function are selected for \nimplementation starting with the most signi\ufb01cant AI risks. The risks or trustworthiness characteristics that will not \u2013 or cannot \u2013 be \nmeasured are properly documented. \nAction ID \nSuggested Action \nGAI Risks \nMS-1.1-001 Employ methods to trace the origin and modi\ufb01cations of digital content. \nInformation Integrity \nMS-1.1-002", "b2ecf04f-6035-47fd-bfae-8f1b117e1cc3": "MS-1.1-002 \nIntegrate tools designed to analyze content provenance and detect data \nanomalies, verify the authenticity of digital signatures, and identify patterns \nassociated with misinformation or manipulation. \nInformation Integrity \nMS-1.1-003 \nDisaggregate evaluation metrics by demographic factors to identify any \ndiscrepancies in how content provenance mechanisms work across diverse \npopulations. \nInformation Integrity; Harmful \nBias and Homogenization \nMS-1.1-004 Develop a suite of metrics to evaluate structured public feedback exercises \ninformed by representative AI Actors. \nHuman-AI Con\ufb01guration; Harmful \nBias and Homogenization; CBRN \nInformation or Capabilities \nMS-1.1-005", "2cd0a75b-978d-4408-98f1-d59e7ee8f92e": "MS-1.1-005 \nEvaluate novel methods and technologies for the measurement of GAI-related \nrisks including in content provenance, o\ufb00ensive cyber, and CBRN, while \nmaintaining the models\u2019 ability to produce valid, reliable, and factually accurate \noutputs. \nInformation Integrity; CBRN \nInformation or Capabilities; \nObscene, Degrading, and/or \nAbusive Content", "ba2329b3-9970-40b5-9213-74f81d8b30f8": "29 \nMS-1.1-006 \nImplement continuous monitoring of GAI system impacts to identify whether GAI \noutputs are equitable across various sub-populations. Seek active and direct \nfeedback from a\ufb00ected communities via structured feedback mechanisms or red-\nteaming to monitor and improve outputs.  \nHarmful Bias and Homogenization \nMS-1.1-007 \nEvaluate the quality and integrity of data used in training and the provenance of \nAI-generated content, for example by employing techniques like chaos \nengineering and seeking stakeholder feedback. \nInformation Integrity \nMS-1.1-008 \nDe\ufb01ne use cases, contexts of use, capabilities, and negative impacts where \nstructured human feedback exercises, e.g., GAI red-teaming, would be most", "f3a66ae2-29d8-4619-a6a3-00c94c0d02f7": "bene\ufb01cial for GAI risk measurement and management based on the context of \nuse. \nHarmful Bias and \nHomogenization; CBRN \nInformation or Capabilities \nMS-1.1-009 \nTrack and document risks or opportunities related to all GAI risks that cannot be \nmeasured quantitatively, including explanations as to why some risks cannot be \nmeasured (e.g., due to technological limitations, resource constraints, or \ntrustworthy considerations). Include unmeasured risks in marginal risks. \nInformation Integrity \nAI Actor Tasks: AI Development, Domain Experts, TEVV \n \nMEASURE 1.3: Internal experts who did not serve as front-line developers for the system and/or independent assessors are", "500574c3-5859-4039-9fae-d721e40880a8": "involved in regular assessments and updates. Domain experts, users, AI Actors external to the team that developed or deployed the \nAI system, and a\ufb00ected communities are consulted in support of assessments as necessary per organizational risk tolerance. \nAction ID \nSuggested Action \nGAI Risks \nMS-1.3-001 \nDe\ufb01ne relevant groups of interest (e.g., demographic groups, subject matter \nexperts, experience with GAI technology) within the context of use as part of \nplans for gathering structured public feedback. \nHuman-AI Con\ufb01guration; Harmful \nBias and Homogenization; CBRN \nInformation or Capabilities \nMS-1.3-002 \nEngage in internal and external evaluations, GAI red-teaming, impact", "c620282d-3a29-44e6-a805-b06d3c598453": "assessments, or other structured human feedback exercises in consultation \nwith representative AI Actors with expertise and familiarity in the context of \nuse, and/or who are representative of the populations associated with the \ncontext of use. \nHuman-AI Con\ufb01guration; Harmful \nBias and Homogenization; CBRN \nInformation or Capabilities \nMS-1.3-003 \nVerify those conducting structured human feedback exercises are not directly \ninvolved in system development tasks for the same GAI model. \nHuman-AI Con\ufb01guration; Data \nPrivacy \nAI Actor Tasks: AI Deployment, AI Development, AI Impact Assessment, A\ufb00ected Individuals and Communities, Domain Experts, \nEnd-Users, Operation and Monitoring, TEVV", "7f0ce253-124d-496e-8538-efddcf8604a5": "30 \nMEASURE 2.2: Evaluations involving human subjects meet applicable requirements (including human subject protection) and are \nrepresentative of the relevant population. \nAction ID \nSuggested Action \nGAI Risks \nMS-2.2-001 Assess and manage statistical biases related to GAI content provenance through \ntechniques such as re-sampling, re-weighting, or adversarial training. \nInformation Integrity; Information \nSecurity; Harmful Bias and \nHomogenization \nMS-2.2-002 \nDocument how content provenance data is tracked and how that data interacts \nwith privacy and security. Consider: Anonymizing data to protect the privacy of \nhuman subjects; Leveraging privacy output \ufb01lters; Removing any personally", "671a27f6-4bc0-4651-a401-d2e7979fdd01": "identi\ufb01able information (PII) to prevent potential harm or misuse. \nData Privacy; Human AI \nCon\ufb01guration; Information \nIntegrity; Information Security; \nDangerous, Violent, or Hateful \nContent \nMS-2.2-003 Provide human subjects with options to withdraw participation or revoke their \nconsent for present or future use of their data in GAI applications.  \nData Privacy; Human-AI \nCon\ufb01guration; Information \nIntegrity \nMS-2.2-004 \nUse techniques such as anonymization, di\ufb00erential privacy or other privacy-\nenhancing technologies to minimize the risks associated with linking AI-generated \ncontent back to individual human subjects. \nData Privacy; Human-AI \nCon\ufb01guration \nAI Actor Tasks: AI Development, Human Factors, TEVV", "0f729b4b-7c88-4ccc-9570-8eb27956d172": "MEASURE 2.3: AI system performance or assurance criteria are measured qualitatively or quantitatively and demonstrated for \nconditions similar to deployment setting(s). Measures are documented. \nAction ID \nSuggested Action \nGAI Risks \nMS-2.3-001 Consider baseline model performance on suites of benchmarks when selecting a \nmodel for \ufb01ne tuning or enhancement with retrieval-augmented generation. \nInformation Security; \nConfabulation \nMS-2.3-002 Evaluate claims of model capabilities using empirically validated methods. \nConfabulation; Information \nSecurity \nMS-2.3-003 Share results of pre-deployment testing with relevant GAI Actors, such as those \nwith system release approval authority. \nHuman-AI Con\ufb01guration", "5e6d720b-fe4e-4954-a1d3-dbef9f2f34ba": "31 \nMS-2.3-004 \nUtilize a purpose-built testing environment such as NIST Dioptra to empirically \nevaluate GAI trustworthy characteristics. \nCBRN Information or Capabilities; \nData Privacy; Confabulation; \nInformation Integrity; Information \nSecurity; Dangerous, Violent, or \nHateful Content; Harmful Bias and \nHomogenization \nAI Actor Tasks: AI Deployment, TEVV \n \nMEASURE 2.5: The AI system to be deployed is demonstrated to be valid and reliable. Limitations of the generalizability beyond the \nconditions under which the technology was developed are documented. \nAction ID \nSuggested Action \nRisks \nMS-2.5-001 Avoid extrapolating GAI system performance or capabilities from narrow, non-\nsystematic, and anecdotal assessments.", "aa47a658-b4cc-49c8-a4b9-0cd3b2773a03": "Human-AI Con\ufb01guration; \nConfabulation \nMS-2.5-002 \nDocument the extent to which human domain knowledge is employed to \nimprove GAI system performance, via, e.g., RLHF, \ufb01ne-tuning, retrieval-\naugmented generation, content moderation, business rules. \nHuman-AI Con\ufb01guration \nMS-2.5-003 Review and verify sources and citations in GAI system outputs during pre-\ndeployment risk measurement and ongoing monitoring activities. \nConfabulation \nMS-2.5-004 Track and document instances of anthropomorphization (e.g., human images, \nmentions of human feelings, cyborg imagery or motifs) in GAI system interfaces. Human-AI Con\ufb01guration \nMS-2.5-005 Verify GAI system training data and TEVV data provenance, and that \ufb01ne-tuning", "b9abd627-ee7e-4cb4-b934-f7955d117fe5": "or retrieval-augmented generation data is grounded. \nInformation Integrity \nMS-2.5-006 \nRegularly review security and safety guardrails, especially if the GAI system is \nbeing operated in novel circumstances. This includes reviewing reasons why the \nGAI system was initially assessed as being safe to deploy.  \nInformation Security; Dangerous, \nViolent, or Hateful Content \nAI Actor Tasks: Domain Experts, TEVV", "26741d2e-61fe-428a-ad44-9f36ab22f995": "32 \nMEASURE 2.6: The AI system is evaluated regularly for safety risks \u2013 as identi\ufb01ed in the MAP function. The AI system to be \ndeployed is demonstrated to be safe, its residual negative risk does not exceed the risk tolerance, and it can fail safely, particularly if \nmade to operate beyond its knowledge limits. Safety metrics re\ufb02ect system reliability and robustness, real-time monitoring, and \nresponse times for AI system failures. \nAction ID \nSuggested Action \nGAI Risks \nMS-2.6-001 \nAssess adverse impacts, including health and wellbeing impacts for value chain \nor other AI Actors that are exposed to sexually explicit, o\ufb00ensive, or violent \ninformation during GAI training and maintenance. \nHuman-AI Con\ufb01guration; Obscene,", "f149548c-a4fb-4bfb-9f1f-b3a40284bb32": "Degrading, and/or Abusive \nContent; Value Chain and \nComponent Integration; \nDangerous, Violent, or Hateful \nContent \nMS-2.6-002 \nAssess existence or levels of harmful bias, intellectual property infringement, \ndata privacy violations, obscenity, extremism, violence, or CBRN information in \nsystem training data. \nData Privacy; Intellectual Property; \nObscene, Degrading, and/or \nAbusive Content; Harmful Bias and \nHomogenization; Dangerous, \nViolent, or Hateful Content; CBRN \nInformation or Capabilities \nMS-2.6-003 Re-evaluate safety features of \ufb01ne-tuned models when the negative risk exceeds \norganizational risk tolerance. \nDangerous, Violent, or Hateful \nContent", "f93042e7-98e5-4e82-aff6-83c7148279d9": "Content \nMS-2.6-004 Review GAI system outputs for validity and safety: Review generated code to \nassess risks that may arise from unreliable downstream decision-making. \nValue Chain and Component \nIntegration; Dangerous, Violent, or \nHateful Content \nMS-2.6-005 \nVerify that GAI system architecture can monitor outputs and performance, and \nhandle, recover from, and repair errors when security anomalies, threats and \nimpacts are detected. \nConfabulation; Information \nIntegrity; Information Security \nMS-2.6-006 \nVerify that systems properly handle queries that may give rise to inappropriate, \nmalicious, or illegal usage, including facilitating manipulation, extortion, targeted \nimpersonation, cyber-attacks, and weapons creation.", "0ebc4cec-5f80-4254-99d8-cdf3a203660a": "CBRN Information or Capabilities; \nInformation Security \nMS-2.6-007 Regularly evaluate GAI system vulnerabilities to possible circumvention of safety \nmeasures.  \nCBRN Information or Capabilities; \nInformation Security \nAI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV", "799d6f35-5486-4138-a9b3-3493176ed2c3": "33 \nMEASURE 2.7: AI system security and resilience \u2013 as identi\ufb01ed in the MAP function \u2013 are evaluated and documented. \nAction ID \nSuggested Action \nGAI Risks \nMS-2.7-001 \nApply established security measures to: Assess likelihood and magnitude of \nvulnerabilities and threats such as backdoors, compromised dependencies, data \nbreaches, eavesdropping, man-in-the-middle attacks, reverse engineering, \nautonomous agents, model theft or exposure of model weights, AI inference, \nbypass, extraction, and other baseline security concerns. \nData Privacy; Information Integrity; \nInformation Security; Value Chain \nand Component Integration \nMS-2.7-002 \nBenchmark GAI system security and resilience related to content provenance", "65507ba8-bfa9-4b1f-a7bf-c16015e37ed6": "against industry standards and best practices. Compare GAI system security \nfeatures and content provenance methods against industry state-of-the-art. \nInformation Integrity; Information \nSecurity \nMS-2.7-003 \nConduct user surveys to gather user satisfaction with the AI-generated content \nand user perceptions of content authenticity. Analyze user feedback to identify \nconcerns and/or current literacy levels related to content provenance and \nunderstanding of labels on content. \nHuman-AI Con\ufb01guration; \nInformation Integrity \nMS-2.7-004 \nIdentify metrics that re\ufb02ect the e\ufb00ectiveness of security measures, such as data \nprovenance, the number of unauthorized access attempts, inference, bypass,", "db98fcd2-6682-4549-a5ca-d42f3558622c": "extraction, penetrations, or provenance veri\ufb01cation. \nInformation Integrity; Information \nSecurity \nMS-2.7-005 \nMeasure reliability of content authentication methods, such as watermarking, \ncryptographic signatures, digital \ufb01ngerprints, as well as access controls, \nconformity assessment, and model integrity veri\ufb01cation, which can help support \nthe e\ufb00ective implementation of content provenance techniques. Evaluate the \nrate of false positives and false negatives in content provenance, as well as true \npositives and true negatives for veri\ufb01cation. \nInformation Integrity \nMS-2.7-006 \nMeasure the rate at which recommendations from security checks and incidents \nare implemented. Assess how quickly the AI system can adapt and improve", "4c7a3ea7-e611-4474-96f4-ec8f382135ba": "based on lessons learned from security incidents and feedback. \nInformation Integrity; Information \nSecurity \nMS-2.7-007 \nPerform AI red-teaming to assess resilience against: Abuse to facilitate attacks on \nother systems (e.g., malicious code generation, enhanced phishing content), GAI \nattacks (e.g., prompt injection), ML attacks (e.g., adversarial examples/prompts, \ndata poisoning, membership inference, model extraction, sponge examples). \nInformation Security; Harmful Bias \nand Homogenization; Dangerous, \nViolent, or Hateful Content \nMS-2.7-008 Verify \ufb01ne-tuning does not compromise safety and security controls. \nInformation Integrity; Information \nSecurity; Dangerous, Violent, or \nHateful Content", "70e73003-16d0-4f10-8797-14c8c3da4519": "34 \nMS-2.7-009 Regularly assess and verify that security measures remain e\ufb00ective and have not \nbeen compromised. \nInformation Security \nAI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV \n \nMEASURE 2.8: Risks associated with transparency and accountability \u2013 as identi\ufb01ed in the MAP function \u2013 are examined and \ndocumented. \nAction ID \nSuggested Action \nGAI Risks \nMS-2.8-001 \nCompile statistics on actual policy violations, take-down requests, and intellectual \nproperty infringement for organizational GAI systems: Analyze transparency \nreports across demographic groups, languages groups. \nIntellectual Property; Harmful Bias \nand Homogenization", "018878e7-96cf-401e-8f8b-52f4a4ecbae0": "and Homogenization \nMS-2.8-002 Document the instructions given to data annotators or AI red-teamers. \nHuman-AI Con\ufb01guration \nMS-2.8-003 \nUse digital content transparency solutions to enable the documentation of each \ninstance where content is generated, modi\ufb01ed, or shared to provide a tamper-\nproof history of the content, promote transparency, and enable traceability. \nRobust version control systems can also be applied to track changes across the AI \nlifecycle over time. \nInformation Integrity \nMS-2.8-004 Verify adequacy of GAI system user instructions through user testing. \nHuman-AI Con\ufb01guration \nAI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV", "8c0b1dc6-17b0-45d6-a58c-2bdffae6322e": "35 \nMEASURE 2.9: The AI model is explained, validated, and documented, and AI system output is interpreted within its context \u2013 as \nidenti\ufb01ed in the MAP function \u2013 to inform responsible use and governance. \nAction ID \nSuggested Action \nGAI Risks \nMS-2.9-001 \nApply and document ML explanation results such as: Analysis of embeddings, \nCounterfactual prompts, Gradient-based attributions, Model \ncompression/surrogate models, Occlusion/term reduction. \nConfabulation \nMS-2.9-002 \nDocument GAI model details including: Proposed use and organizational value; \nAssumptions and limitations, Data collection methodologies; Data provenance; \nData quality; Model architecture (e.g., convolutional neural network,"}}