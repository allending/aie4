{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Midterm Notebook"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dependencies"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T21:02:03.848573Z",
     "start_time": "2024-09-23T21:02:02.655715Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nCC2AR-Q0m0x",
    "outputId": "a9936260-6134-4294-f21c-6a40111a57ca"
   },
   "outputs": [],
   "source": [
    "!pip install -qU langchain langchain-core langchain-community langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T21:02:04.484987Z",
     "start_time": "2024-09-23T21:02:03.863057Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -qU qdrant-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T21:02:05.204661Z",
     "start_time": "2024-09-23T21:02:04.492770Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K5qIUrFuENrS",
    "outputId": "61571142-eb50-4eaa-ac68-4c39062a36ad"
   },
   "outputs": [],
   "source": [
    "!pip install -qU tiktoken pymupdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Environment Variables"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T21:02:10.248982Z",
     "start_time": "2024-09-23T21:02:05.210608Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7pKAfycq73wE",
    "outputId": "404522d0-c907-44bc-c8f8-f72084dfbb57"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking\n",
    "\n",
    "We'll use the `RecursiveCharacterTextSplitter` to create our toy example.\n",
    "\n",
    "It will split based on the following rules:\n",
    "\n",
    "- Each chunk has a maximum size of 100 tokens\n",
    "- It will try and split first on the `\\n\\n` character, then on the `\\n`, then on the `<SPACE>` character, and finally it will split on individual tokens.\n",
    "\n",
    "Let's implement it and see the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T21:29:21.474670Z",
     "start_time": "2024-09-23T21:29:19.933522Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "\n",
    "doc1 = PyMuPDFLoader(\"Blueprint-for-an-AI-Bill-of-Rights.pdf\").load()\n",
    "doc2 = PyMuPDFLoader(\"NIST.AI.600-1.pdf\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T01:29:15.832957Z",
     "start_time": "2024-09-02T01:29:15.824365Z"
    },
    "id": "nLW9AfDKfVHn"
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def tiktoken_len(text):\n",
    "    tokens = tiktoken.encoding_for_model(\"gpt-4o\").encode(\n",
    "        text,\n",
    "    )\n",
    "    return len(tokens)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 300,\n",
    "    chunk_overlap = 0,\n",
    "    length_function = tiktoken_len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_chunks1 = text_splitter.split_documents(doc1)\n",
    "len(split_chunks1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_chunks2 = text_splitter.split_documents(doc2)\n",
    "len(split_chunks2)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Qdrant Vector Store for Embeddings"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "qdrant_vectorstore = Qdrant.from_documents(\n",
    "    documents=split_chunks1 + split_chunks2,\n",
    "    embedding=embedding_model,\n",
    "    location=\":memory:\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_retriever = qdrant_vectorstore.as_retriever()"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T01:37:20.002266Z",
     "start_time": "2024-09-02T01:37:18.902838Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FQD5Zwl1tLrZ",
    "outputId": "d42d7488-edca-458b-dca4-1b11f3536cb2"
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector of Size: 1536\n"
     ]
    }
   ],
   "execution_count": 18,
   "source": [
    "query = \"What kind of protections should AI systems provide?\"\n",
    "query_vector = embedding_model.embed_query(query)\n",
    "print(f\"Vector of Size: {len(query_vector)}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### RAG Chain with LCEL"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### General purpose RAG base prompt"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "base_rag_prompt_template = \"\"\"\\\n",
    "Use the provided context to answer the provided user question. Only use the provided context to answer the question. If you do not know the answer, response with \"I don't know\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "base_rag_prompt = ChatPromptTemplate.from_template(base_rag_prompt_template)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Base LLM"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "base_llm = ChatOpenAI(model=\"gpt-4o-mini\", tags=[\"base_llm\"])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Simple RAG Chain Definition"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "retrieval_augmented_qa_chain = (\n",
    "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
    "    # \"question\" : populated by getting the value of the \"question\" key\n",
    "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
    "    {\"context\": itemgetter(\"question\") | qdrant_retriever, \"question\": itemgetter(\"question\")}\n",
    "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
    "    #              by getting the value of the \"context\" key from the previous step\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
    "    #              into the LLM and stored in a key called \"response\"\n",
    "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
    "    | {\"response\": base_rag_prompt | base_llm, \"context\": itemgetter(\"context\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          +---------------------------------+      \n",
      "          | Parallel<context,question>Input |      \n",
      "          +---------------------------------+      \n",
      "                    **            **               \n",
      "                  **                **             \n",
      "                **                    **           \n",
      "         +--------+                     **         \n",
      "         | Lambda |                      *         \n",
      "         +--------+                      *         \n",
      "              *                          *         \n",
      "              *                          *         \n",
      "              *                          *         \n",
      "  +----------------------+          +--------+     \n",
      "  | VectorStoreRetriever |          | Lambda |     \n",
      "  +----------------------+          +--------+     \n",
      "                    **            **               \n",
      "                      **        **                 \n",
      "                        **    **                   \n",
      "          +----------------------------------+     \n",
      "          | Parallel<context,question>Output |     \n",
      "          +----------------------------------+     \n",
      "                            *                      \n",
      "                            *                      \n",
      "                            *                      \n",
      "              +------------------------+           \n",
      "              | Parallel<context>Input |           \n",
      "              +------------------------+           \n",
      "                     ***        ***                \n",
      "                    *              *               \n",
      "                  **                **             \n",
      "           +--------+          +-------------+     \n",
      "           | Lambda |          | Passthrough |     \n",
      "           +--------+          +-------------+     \n",
      "                     ***        ***                \n",
      "                        *      *                   \n",
      "                         **  **                    \n",
      "              +-------------------------+          \n",
      "              | Parallel<context>Output |          \n",
      "              +-------------------------+          \n",
      "                            *                      \n",
      "                            *                      \n",
      "                            *                      \n",
      "          +---------------------------------+      \n",
      "          | Parallel<response,context>Input |      \n",
      "          +---------------------------------+      \n",
      "                   **              ***             \n",
      "                ***                   **           \n",
      "              **                        ***        \n",
      "+--------------------+                     **      \n",
      "| ChatPromptTemplate |                      *      \n",
      "+--------------------+                      *      \n",
      "           *                                *      \n",
      "           *                                *      \n",
      "           *                                *      \n",
      "    +------------+                     +--------+  \n",
      "    | ChatOpenAI |                     | Lambda |  \n",
      "    +------------+*                  **+--------+  \n",
      "                   **              **              \n",
      "                     ***        ***                \n",
      "                        **    **                   \n",
      "          +----------------------------------+     \n",
      "          | Parallel<response,context>Output |     \n",
      "          +----------------------------------+     \n"
     ]
    }
   ],
   "source": [
    "print(retrieval_augmented_qa_chain.get_graph().draw_ascii())"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sample Queries"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = retrieval_augmented_qa_chain.invoke({\"question\" : \"What kind of protections should AI systems provide?\"})\n",
    "response[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = retrieval_augmented_qa_chain.invoke({\"question\" : \"Should people know when an AI system is being used?\"})\n",
    "response[\"response\"].content"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dig into the Context"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "page_content='should be kept up-to-date and people impacted by the system should be notified of significant use case or key \n",
      "functionality changes. You should know how and why an outcome impacting you was determined by an \n",
      "automated system, including when the automated system is not the sole input determining the outcome. \n",
      "Automated systems should provide explanations that are technically valid, meaningful and useful to you and to \n",
      "any operators or others who need to understand the system, and calibrated to the level of risk based on the \n",
      "context. Reporting that includes summary information about these automated systems in plain language and \n",
      "assessments of the clarity and quality of the notice and explanations should be made public whenever possible. \n",
      "6' metadata={'source': 'Blueprint-for-an-AI-Bill-of-Rights.pdf', 'file_path': 'Blueprint-for-an-AI-Bill-of-Rights.pdf', 'page': 5, 'total_pages': 73, 'format': 'PDF 1.6', 'title': 'Blueprint for an AI Bill of Rights', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe Illustrator 26.3 (Macintosh)', 'producer': 'iLovePDF', 'creationDate': \"D:20220920133035-04'00'\", 'modDate': \"D:20221003104118-04'00'\", 'trapped': '', '_id': '69c72ac9690e48e4b446dedbe94af9db', '_collection_name': '2cbda86569ca48ffa29c9fbc566af6e0'}\n",
      "----\n",
      "Context:\n",
      "page_content='justice, and finance, and for data pertaining to youth should put you first. In sensitive domains, your data and \n",
      "related inferences should only be used for necessary functions, and you should be protected by ethical review \n",
      "and use prohibitions. You and your communities should be free from unchecked surveillance; surveillance \n",
      "technologies should be subject to heightened oversight that includes at least pre-deployment assessment of their \n",
      "potential harms and scope limits to protect privacy and civil liberties. Continuous surveillance and monitoring \n",
      "should not be used in education, work, housing, or in other contexts where the use of such surveillance \n",
      "technologies is likely to limit rights, opportunities, or access. Whenever possible, you should have access to \n",
      "reporting that confirms your data decisions have been respected and provides an assessment of the \n",
      "potential impact of surveillance technologies on your rights, opportunities, or access. \n",
      "NOTICE AND EXPLANATION\n",
      "You should know that an automated system is being used and understand how and why it \n",
      "contributes to outcomes that impact you. Designers, developers, and deployers of automated systems \n",
      "should provide generally accessible plain language documentation including clear descriptions of the overall \n",
      "system functioning and the role automation plays, notice that such systems are in use, the individual or organiza­\n",
      "tion responsible for the system, and explanations of outcomes that are clear, timely, and accessible. Such notice' metadata={'source': 'Blueprint-for-an-AI-Bill-of-Rights.pdf', 'file_path': 'Blueprint-for-an-AI-Bill-of-Rights.pdf', 'page': 5, 'total_pages': 73, 'format': 'PDF 1.6', 'title': 'Blueprint for an AI Bill of Rights', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe Illustrator 26.3 (Macintosh)', 'producer': 'iLovePDF', 'creationDate': \"D:20220920133035-04'00'\", 'modDate': \"D:20221003104118-04'00'\", 'trapped': '', '_id': '1d405040b36441069da879411735aa13', '_collection_name': '2cbda86569ca48ffa29c9fbc566af6e0'}\n",
      "----\n",
      "Context:\n",
      "page_content='corresponding applications can help enhance awareness of performance changes and mitigate potential \n",
      "risks and harms from outputs. There are many ways to capture and make use of user feedback – before \n",
      "and after GAI systems and digital content transparency approaches are deployed – to gain insights about \n",
      "authentication eﬃcacy and vulnerabilities, impacts of adversarial threats on techniques, and unintended \n",
      "consequences resulting from the utilization of content provenance approaches on users and \n",
      "communities. Furthermore, organizations can track and document the provenance of datasets to identify \n",
      "instances in which AI-generated data is a potential root cause of performance issues with the GAI \n",
      "system. \n",
      "A.1.8. Incident Disclosure \n",
      "Overview \n",
      "AI incidents can be deﬁned as an “event, circumstance, or series of events where the development, use, \n",
      "or malfunction of one or more AI systems directly or indirectly contributes to one of the following harms: \n",
      "injury or harm to the health of a person or groups of people (including psychological harms and harms to \n",
      "mental health); disruption of the management and operation of critical infrastructure; violations of \n",
      "human rights or a breach of obligations under applicable law intended to protect fundamental, labor, \n",
      "and intellectual property rights; or harm to property, communities, or the environment.” AI incidents can' metadata={'source': 'NIST.AI.600-1.pdf', 'file_path': 'NIST.AI.600-1.pdf', 'page': 55, 'total_pages': 64, 'format': 'PDF 1.6', 'title': 'Artificial Intelligence Risk Management Framework: Generative Artificial Intelligence Profile', 'author': 'National Institute of Standards and Technology', 'subject': '', 'keywords': '', 'creator': 'Acrobat PDFMaker 24 for Word', 'producer': 'Adobe PDF Library 24.2.159', 'creationDate': \"D:20240805141702-04'00'\", 'modDate': \"D:20240805143048-04'00'\", 'trapped': '', '_id': 'f0e8545013fd41e483ccef94aaedfa67', '_collection_name': '2cbda86569ca48ffa29c9fbc566af6e0'}\n",
      "----\n",
      "Context:\n",
      "page_content='Suggested Action \n",
      "GAI Risks \n",
      "MS-2.10-001 \n",
      "Conduct AI red-teaming to assess issues such as: Outputting of training data \n",
      "samples, and subsequent reverse engineering, model extraction, and \n",
      "membership inference risks; Revealing biometric, conﬁdential, copyrighted, \n",
      "licensed, patented, personal, proprietary, sensitive, or trade-marked information; \n",
      "Tracking or revealing location information of users or members of training \n",
      "datasets. \n",
      "Human-AI Conﬁguration; \n",
      "Information Integrity; Intellectual \n",
      "Property \n",
      "MS-2.10-002 \n",
      "Engage directly with end-users and other stakeholders to understand their \n",
      "expectations and concerns regarding content provenance. Use this feedback to \n",
      "guide the design of provenance data-tracking techniques. \n",
      "Human-AI Conﬁguration; \n",
      "Information Integrity \n",
      "MS-2.10-003 Verify deduplication of GAI training data samples, particularly regarding synthetic \n",
      "data. \n",
      "Harmful Bias and Homogenization \n",
      "AI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, End-Users, Operation and Monitoring, TEVV' metadata={'source': 'NIST.AI.600-1.pdf', 'file_path': 'NIST.AI.600-1.pdf', 'page': 38, 'total_pages': 64, 'format': 'PDF 1.6', 'title': 'Artificial Intelligence Risk Management Framework: Generative Artificial Intelligence Profile', 'author': 'National Institute of Standards and Technology', 'subject': '', 'keywords': '', 'creator': 'Acrobat PDFMaker 24 for Word', 'producer': 'Adobe PDF Library 24.2.159', 'creationDate': \"D:20240805141702-04'00'\", 'modDate': \"D:20240805143048-04'00'\", 'trapped': '', '_id': '17949b9f35e14704a545ab6d6df8826c', '_collection_name': '2cbda86569ca48ffa29c9fbc566af6e0'}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for context in response[\"context\"]:\n",
    "  print(\"Context:\")\n",
    "  print(context)\n",
    "  print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
