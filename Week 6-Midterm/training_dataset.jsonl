{"questions": {"0f7ca60e-78a7-4c19-94cd-b98471043def": "What groups are involved in the processes that require cooperation and collaboration?", "96d62b9d-d92b-4d6b-aa65-b4bcd27c1a46": "Why is collaboration among different sectors important in these processes?", "f138c496-711b-4d24-b116-7e852d9e3761": "What did the panelists emphasize regarding the regulation of technology before it is built and instituted?", "532cca04-9f3b-4f2e-b160-fb025efbd538": "What specific aspects of technology regulation were highlighted by the panelists?", "05df20e2-f4e5-4344-b7a8-4239ec0f65e7": "What factors contribute to the increased risk associated with General Artificial Intelligence (GAI) systems compared to other digital technologies?", "af1fa2ea-8182-486f-8911-b0c78707026d": "How can errors in third-party GAI components affect the overall performance of a GAI system?", "27a22958-257d-414b-8c0c-a535808fe157": "What concerns did panelists raise regarding the validity of data-driven approaches in safety strategies?", "f54c33a1-6d93-4d14-93cb-26b49e1467b5": "How might the lack of individualization in automated systems impact individuals and communities, according to the panelists?", "985d2f5c-bf11-4b3a-8a0d-3902f0d00e97": "What are some examples of technologies that can intentionally or unintentionally cause harm to others?", "553b41cd-3b35-4c68-b59f-84f6001bd8ed": "How are companies addressing the potential harms associated with technology development?", "d3fa1bd4-0aa4-4661-9303-8d56ffa15407": "What is the purpose of ballot curing laws in the context of voter signatures?", "2b50a56f-b312-4eb2-b1e6-41777b9ae89c": "How do ballot curing processes differ among states?", "1ae9029d-65c7-45dc-815c-0243c25762db": "What is the primary purpose of the family surveillance algorithm discussed in the ACLU fact sheet?", "7912e90d-b021-4226-b4b9-0c44db96e7e5": "How does the family surveillance algorithm impact the privacy of individuals and families?", "48fa9ed1-0f08-477a-bb26-9b17638a86e5": "What is the importance of training in the governance of technological systems?", "30e5fcdc-6d84-4998-8aef-2826da250e98": "How can third-party audits contribute to the accountability and validity of these systems?", "b3db14d0-8f7f-4d6b-8f66-61438802c0e9": "What are the main findings of Zhang et al (2023) regarding people's perceptions of generative AI compared to human experts?", "ac7793c5-60d7-47f8-a704-90aea802aed7": "What topic does the survey by Zhang et al (2023) address concerning large language models?", "7f78b0fe-cc1d-423b-ace7-dc4179078d4d": "What are the potential consequences of indirect prompt injections on closed production models?", "b9a08058-39c1-4c74-a070-91eae0b12a4f": "How can data poisoning compromise the outputs or operation of a GAI model?", "d5323090-6d6f-446b-ae47-a1d9baa5c081": "What steps should be taken to ensure that automated systems are safe and effective before deployment?", "4dedef7a-a584-455b-857f-343db1a59f92": "Why is it important to involve diverse communities and stakeholders in the development of automated systems?", "fc957c78-6974-4abb-a1fd-7e88803c1659": "What constitutes algorithmic discrimination according to the provided context?", "99df1e94-f2b9-478a-8448-dc33cb266b5f": "Which classifications are protected by law from algorithmic discrimination?", "3aa5df95-e5a0-4286-8e88-4836bfbbcdc0": "What is the purpose of the Family Educational Rights and Privacy Act (FERPA)?", "eec8cc8a-54e1-4194-a888-2034b26916ce": "What year was the Children's Online Privacy Protection Act enacted?", "b7eb08df-39c4-4721-b0e4-9001abdb8ca2": "What is the main focus of the paper by Shevlane et al (2023) regarding model evaluation?", "77b659b4-1b8e-4324-9fd7-c277d59c8474": "How do Shumailov et al (2023) describe the impact of training on generated data on model performance?", "75fc0622-1104-47d9-8af4-dfe76939abaa": "What surveillance technology is mentioned as being used by Amazon and Walmart to combat union activities?", "ed644c24-adc9-42c2-9a5d-34fffc7e2014": "Which organizations have faced enforcement actions by the FTC as referenced in the context?", "975a212f-fef5-4125-8848-f6cc20a8fc93": "What innovative solutions are mentioned for mitigating risks associated with AI systems?", "92282249-58d3-4416-bf25-bcb63cb12cae": "What has the Office of Management and Budget (OMB) called for regarding stakeholder engagement?", "0ee4436b-15a9-4d2d-b316-f07b4d6f86d5": "What are some proposals mentioned for designing algorithmic impact assessments?", "cb86aaae-8577-4b65-b35f-b9a6b1322c60": "Who are the authors of the report titled \"Assembling Accountability: Algorithmic Impact Assessment for the Public Interest\"?", "f16c11fe-118d-48d1-b285-dfc88fe57f49": "What types of research do the National AI Research Institutes support regarding AI algorithms and systems?", "9e2f1fac-e054-4d81-b17f-63f109e07466": "How does the Secure and Trustworthy Cyberspace program contribute to the field of automated systems?", "24487d5e-f936-4aa7-a592-1793df2585f1": "What factors influence the implementation of suggested actions for managing GAI risks according to the AI RMF and its Playbook?", "26718fbd-55f0-4633-a141-d13440a6df51": "Why are not all subcategories of the AI RMF included in the document focused on GAI systems?", "a44625d2-ee3d-4701-b1d2-7e4f53e38644": "What is the purpose of the document titled \"A Technical Companion to the Blueprint for an AI Bill of Rights\"?", "b43cb095-4afa-4d9b-a743-943ab103c7dc": "How does the document transition from principles to practice regarding AI rights?", "387d16f7-e55c-4e8a-8078-227d6611aced": "What measures should be taken to ensure that automated systems do not endanger safety?", "e3fb2593-08d6-4683-948c-a5402f663583": "Why is independent evaluation and reporting important in the design and deployment of automated systems?", "2d6d3cd1-8871-452c-a6de-3107a70eb4ac": "What is the purpose of the executive order mentioned in the context regarding advancing racial equity and support for underserved communities?", "c7ac3186-9be3-4d28-ba99-fe7242a3b8f2": "Where can one find the definition of \"Navigator\" as it relates to HealthCaregov?", "77383788-89b0-491d-b928-e749ad4ce4c7": "What should be performed and made public to confirm these protections?", "6346d44e-82d5-40ca-a8a8-6285c0ce9a36": "Why is it important to make the performance public?", "239c55b0-8728-4013-a2b8-fc829b62dd37": "What policies are suggested to enhance oversight of GAI systems according to the provided context?", "d63d1666-24f9-41b1-9a60-f37f46d46513": "What organizational roles and components should be considered for adjustment across the lifecycle stages of large or complex GAI systems?", "85bdd22f-225b-417e-a1f9-87b31f9dccc0": "What are the suggested actions to manage GAI risks associated with third-party data and AI systems?", "ae2b6484-60b4-4fc9-abcd-9ca42114593d": "Why is it important to document incidents involving third-party GAI data and systems?", "c4b5543a-7d6e-45d7-ab51-666b8b48beaf": "What steps are companies and government agencies taking to protect the public from algorithmic discrimination?", "c6e5a3c3-b702-401a-9583-4668144eff4d": "How can bias testing impact the design and launch of automated systems?", "b7fbacf4-38ea-426d-b6e9-dc77d503d6c9": "What is the focus of the National Science Foundation's initiative mentioned in the context?", "e0edbf9f-1c89-4162-9517-cea42e7e4095": "What concerns are raised by The Leadership Conference Education Fund regarding pretrial \"risk assessment\" instruments?", "eee8920f-fb61-4ea8-a30e-9f601adf6ffa": "What were the consequences of wrongful arrests based on AI for the three men mentioned in the Wired article?", "84a19560-f086-442a-94c3-aa00e97a0058": "How did Amazon's AI recruiting tool demonstrate bias against women, leading to its discontinuation?", "378eae45-1c5a-4e2b-8376-b61712e9375a": "What is the purpose of the Department of Justice's report on violent recidivism tools?", "7e0fe01c-1f05-4d4d-8c0a-cf8e41e3ed7c": "How is the Department of Justice addressing disparities related to violent recidivism?", "4b30af55-8c6c-4709-a790-70646f413c5b": "What happens to the job titles of former Apple employees in employer job databases?", "fee326e9-5fb4-4aef-9937-9df01d8eeb9b": "What organization published a document titled \"Privacy Framework Perspectives and Success Stories\"?", "e20d343c-9547-4073-a5cc-99bdd64acbf5": "What are some examples of provenance methodologies mentioned in the context?", "22339da4-e28f-4563-acd0-82318f4162bb": "What minimum set of criteria is suggested for GAI system incident reporting?", "d4cfdcba-cff9-43f0-9191-817dcd174a94": "What are the key considerations for assigning liability and responsibility for incidents involving third-party data and systems?", "d076ccc2-81f8-4f19-9dbb-4d51d07b7e15": "How should Service Level Agreements (SLAs) be structured to address incident response and support availability in vendor contracts?", "260139a5-3e7d-45d3-a9bb-f434614251aa": "What is the expected release timeframe for the testing and evaluation of AI technologies and systems?", "01722004-d524-41cc-93c7-d8b03e4ae4ef": "In which season is the release of the AI technologies and systems anticipated?", "0748ff61-68f5-41ba-815e-0b191943e4ab": "What mechanisms are in place to verify information sharing and feedback regarding the negative impacts of GAI systems?", "9ca5e319-4c96-4a89-bb4a-b1a20ec2861b": "How do organizational policies ensure the integration of feedback from external individuals and communities concerning AI risks?", "14022269-ea75-4d36-9988-6fd604f5e26a": "What measures should be incorporated to protect intellectual property and trade secrets during legal discovery in sensitive domains?", "3f4bcb61-7f13-4ee6-a3e6-7c564f580348": "How can systems ensure meaningful access to source code and documentation while maintaining confidentiality?", "c8091eba-ef4d-433b-bcf7-ccbe5f9040cd": "What are the key expectations for automated systems as outlined in the context?", "f2bb8b60-0290-444a-a722-7f547269040e": "Why is it important for the fallback and escalation system to provide equitable access to underserved communities?", "98948c3f-d420-4cb2-83cf-a797052f80e6": "What proactive measures should deployers of automated systems take to protect against algorithmic discrimination?", "defe2607-d4b0-43c3-ab4d-c69c20439287": "Why is it important to include independent evaluation and plain language reporting in the design and deployment of automated systems?", "05137c9e-7640-4feb-992f-2e3664f32bbe": "What does the article by Maia Szalavitz discuss regarding the treatment of chronic pain and the response of doctors?", "50453581-c57a-42c8-9db5-c540df9d1083": "How does the lawsuit mentioned in the Metro Times article illustrate the state's approach to the unemployed?", "0aead898-5597-4edb-af6f-cbcdee0810de": "What are the potential risks associated with the emotional entanglement and aversion in the context of GAI systems?", "128a68bf-00f3-4d32-9c24-3e8f09cd28e8": "How might the deployment of GAI systems introduce new security vulnerabilities or impact different groups disproportionately?", "6fe9299b-65a8-4701-b1af-6edfc5e8d296": "What role does the AI Advancement Council play in the ethical use of AI systems within the Department of Energy?", "260f7dd4-2172-4f32-8d72-4f3d5fc824c2": "How have US government agencies implemented frameworks to ensure the ethical development of AI systems?", "cfcd2f97-95d7-4b18-b1d7-dc0cb7e3a753": "What are the potential intellectual property risks associated with GAI systems when using copyrighted works?", "8f07c5bf-469f-4342-bee3-f976483a5a07": "How is the legal status of GAI-generated content that resembles copyrighted material being debated?", "af2a6dbf-2c8b-4b50-ab48-1b1b0bb6b934": "What concerns have been raised regarding the use of Apple AirTags in relation to stalking and privacy?", "0e9554e5-afe3-45c8-8f08-2d4250579e1b": "How do recent studies and reports address the issue of bias in crime prediction software?", "ec06b05f-932c-4f36-886a-f606ef99a7ff": "What is the main theme of Shoshana Zuboff's book \"The Age of Surveillance Capitalism\"?", "d5221de0-22f0-46c9-b8e8-953ac7f97a57": "How might an individual's online presence impact their life insurance options, according to Angela Chen's article?", "0a16e9cf-c47a-403e-bd71-99cab1363cea": "What concerns are raised regarding digital surveillance in the context of reproductive health clinics?", "10dc30eb-a600-41ef-ad4e-fd300108d622": "What actions did the Federal Trade Commission take against Kochava related to data tracking?", "0fcea0d4-97f4-47b6-8ab1-19c5f5c571b2": "What are the main areas where new surveillance technologies are said to disproportionately harm disabled people, according to the report by Lydia X Z Brown and others?", "feda4622-d65f-476a-9967-b45cad2d1353": "Who are the authors of the report titled \"Ableism And Disability Discrimination In New Surveillance Technologies\"?", "44cf5a79-5cbd-4e04-8869-ec62cb1d406e": "What are the main topics discussed in the provided context regarding user privacy and algorithmic surveillance?", "64c02a6a-ae30-47ce-bd1d-9e77ffb8c934": "How do Apple and Google approach user privacy and safety according to the context?", "33275b8b-11d0-4d50-a605-ea200aeadd21": "What should be ensured when a human decision-maker decides to overrule a previous decision?", "f4bf7390-04a2-4f50-bcdc-36f66aa12d41": "How can safeguards be implemented to prevent future errors in decision-making?", "e8091260-c92c-43cc-8b15-f4ddd413a2f2": "Why is it important to measure and limit errors from data entry or other sources in a prediction process?", "8e3a176a-4dcc-4b5b-8512-cc18db8fae54": "What should be documented to justify the use of each data attribute and source in an automated system?", "58c850ab-8879-40ec-840c-1afbbfb65968": "What concerns are raised about the use of surveillance technology in schools to monitor students?", "3252fc4a-3f77-431f-b677-92f55b71b5cb": "How have students responded to cheating-detection companies during the pandemic?", "ad6161da-245e-4e91-8dc0-8a7378bc6f4d": "What is the purpose of the technical companion mentioned in the context?", "ad266a00-749b-40fa-b385-f0c00af2a247": "What does the section \"WHY THIS PRINCIPLE IS IMPORTANT\" aim to provide?", "44377fe1-76e4-4117-9b76-72fb60cfb3f1": "What was the main focus of the event discussed in the context?", "a0bbe061-13de-43ab-812a-1f3b967e4504": "Who served as the moderator for the panel on the healthcare system?", "20b5bca8-a57c-404c-88e7-62c675449ba1": "What are the funding opportunities provided by the National Science Foundation related to artificial intelligence research institutes?", "3f43fea6-7153-4ce4-a026-cdf06b23b90c": "How can one access information about the National Science Foundation's initiatives in Cyber-Physical Systems?", "fe502be2-b7a3-42f7-ab2f-c5b022164d17": "What is the main focus of Tirrell's (2017) work on toxic speech and discursive harm?", "9567e7ee-1238-4168-98ae-11edf4824567": "What challenges related to computational agency are discussed by Tufekci (2015) in the context of algorithmic harms?", "fcee5a9a-ae21-476a-aacf-4ba1724d9ace": "What are some key considerations for assessing the impact of technologies on equality of opportunity?", "8f038bf6-519f-4100-a4cf-b229e801aac9": "Why is community input important in the design and use of technologies according to the panelists?", "25e5731c-73e5-4d33-8d75-fac6b810a91c": "What are the potential implications of automated tenant background screening and facial recognition controls on privacy rights?", "ca446694-1b6d-49b3-a7f9-f61db9add940": "How might existing privacy laws impact students' ability to reinvent themselves in relation to their education-related data?", "fc82102c-9b26-444f-a9a8-537d97a67afc": "How does surveillance of workers impact the boundary between their work and personal lives?", "2dce3bae-03bb-4c6d-8e2f-e37f363a1b2e": "In what ways can data from criminal justice settings affect individuals' access to housing?", "f50c06fd-ecd3-41dd-8418-67e3179c261a": "What are some potential problems that the principle of \"Safe and Effective Systems\" aims to address?", "31ad489a-3696-4fcf-8a82-f2d4051b5652": "How can reliance on technology lead to situations where it has not been proven to work effectively?", "4e3b8ce9-f7aa-4df2-96c8-e2bdc7dad4cb": "What are the potential risks associated with third-party components in GAI value chains?", "ebd69ef9-d1b0-457f-9397-c20a72afbf20": "How has the generation of synthetic NCII and CSAM evolved in terms of its presence on the internet?", "4154d15a-6499-4dff-91eb-575bd18e17b6": "What are the key components that should be monitored in a system's performance according to the context?", "378582b0-a7e6-48af-a418-59816de61d15": "Why is it important to have fallback mechanisms in place for a system?", "992773b4-2991-46ac-9b92-8059f956c5f7": "How does the National Highway Traffic Safety Administration ensure vehicle safety while allowing for innovation in the automotive industry?", "25ef1744-9265-4ee4-8b06-41e5cc3b18a1": "What are some examples of contextually appropriate requirements that are implemented locally for drivers?", "f17af81a-470d-4b94-84a7-7b3ea0ef0a8a": "What are the key priorities outlined in the White House's 2022 Roadmap for Researchers on Information Integrity Research and Development?", "185402b2-a325-406b-b0b2-22cc04de4146": "What findings were reported by the Stanford Cyber Policy Center regarding AI image generation models and their training data?", "dcd91941-ba09-47c7-b5e3-9fdfc022a783": "What is the purpose of establishing a test plan and response policy before developing highly capable models?", "4837d867-7e55-44dd-a579-1b29540a3bcb": "How should the evaluation of GAI capabilities and risks be reflected in the approval thresholds?", "43a3d4e2-8525-4b96-84f5-60368f572518": "Who are the panelists participating in the discussion on social welfare systems and social development programs?", "2cb10044-c665-41c9-acd7-901abf606c49": "What is the role of Michele Evermore in the context of the event described?", "952b6b2b-6cd5-410a-b2ba-8363af36f58f": "What factors should be considered when assessing GAI vendors and tools against incident or vulnerability databases?", "34a7049a-a0d0-4782-94c5-d68d7dd31de4": "How can organizations update their GAI acceptable use policies to effectively address both proprietary and open-source GAI technologies?", "4976207a-7204-43d2-8118-382f7a10532e": "What is the purpose of ISO/IEC Guide 71:2014 as mentioned in the context?", "b6fe5356-47e5-4d44-b0d7-c0d913be6fca": "Who are the authors of the NIST Special Publication 1270 on bias in artificial intelligence?", "046fc834-ddad-424a-aad2-65ad80ff371d": "What are the key components involved in the AI Actor Tasks as mentioned in the context?", "0e840111-bb92-4409-8025-206307af9805": "How should organizations ensure that downstream GAI system impacts are documented according to the provided guidelines?", "66285d26-619d-49a3-87de-2ef51c90c97f": "What dimensions of life should be considered to ensure fair treatment when using automated systems?", "1a92ea19-ea32-47f4-b8ae-8eb5ac844b8d": "How can automated systems impact underserved communities, and what proactive protections can be instituted to support them?", "3002a41a-b82d-4206-94ac-a2f2c3a6fe56": "What information are voters asked to provide to verify the validity of their ballot?", "06fb85c3-a7a5-4785-a580-ab810f6cf834": "Why might voters need to provide a new signature during the ballot verification process?", "001ff0a4-5877-4093-b183-987cbe2abf4d": "What types of organizations submitted responses to the RFI mentioned in the context?", "b5b16f53-163b-4185-8e12-5163124eb0a0": "How many responses were received for the RFI, and where can they be accessed?", "e80b1947-e4e6-4650-8fa5-70ec0c0fe034": "What is the main focus of the 2014 Federal Trade Commission report titled \"Data Brokers A Call for Transparency and Accountability\"?", "762492d6-5a22-435e-86dc-cd361c5dac6a": "According to Nir Kshetri, what potential negative effects does school surveillance of students via laptops have?", "09550520-0191-4e3e-9b22-142500bba2d9": "What should be established to ensure oversight of automated systems throughout their lifespan?", "5a3f596a-6699-412d-992a-defc0809ceae": "Who should be involved in the governance structures and procedures for the development or use of automated systems?", "2394ffaf-eb59-4bdc-b750-cdf78619f5ec": "What is the main focus of the paper titled \"Provable Robust Watermarking for AI Generated Text\" by Zhao and Ananth?", "e3c89cd5-177b-445d-b14a-079a0e00841c": "How does the proposed watermarking technique ensure robustness against potential attacks on AI-generated text?", "a18daa82-00fa-4a44-8cb0-952373f9d5f5": "What organizations are involved in research and education on accessible technology according to the provided context?", "e2366176-bb2a-4b1a-841e-3c11c530668a": "Which initiative focuses on privacy and technology at Georgetown Law?", "01ab90b7-d1be-4d5d-93e2-63554a2d3a40": "What are the potential harms associated with GAI-generated obscene or degrading content?", "9e2ffe59-fe64-4a7f-b90c-b0003fb2f9f1": "How can GAI contribute to the production and access of illegal non-consensual intimate imagery?", "7a6e3946-854c-4517-9978-da4b0db5d94c": "What are the key components that should be included in the ongoing monitoring procedures for automated systems?", "605a5e60-dae0-477c-8682-76882e7e75b6": "Why is it important for automated systems to have recalibration procedures in place?", "fe445912-0231-4cab-bd24-bb215399f0b9": "What key needs did the panelists identify for the future design of critical AI systems?", "8fac1e57-864d-4fa1-981e-a3c6a7fdde0b": "Why is it important to place trust in people rather than technologies according to the panelists?", "8a1efb5f-b2d4-41bd-8eb3-9e488b9c5d18": "What issues are highlighted regarding the crime prediction software mentioned in the context?", "22d8ba5a-bcbd-463c-a488-816866358e6e": "How does the DeepNude app function according to the article by Samantha Cole?", "93d8726e-a6f0-4d45-a6d1-41731ce3e05a": "What are the expectations for data and inferences in sensitive domains according to the provided context?", "5a45e402-f2b3-47ed-96e9-02705cfc87d5": "How should human oversight contribute to the design of automated systems in sensitive domains?", "eca7b312-d8a2-4311-9017-07b0b5e56b93": "What factors should be considered when updating or defining risk tiers for GAI according to the provided context?", "0e571312-f9c7-4752-9002-0405cb2bb0a4": "How do the suggested actions relate to the organization's risk tolerance in the context of information security?", "89a176e3-df57-4792-a648-b2abeca915a4": "What are the key requirements for AI use by the federal government as outlined in the context?", "3904fb02-e9c2-4060-99c6-9e0433ee2d0a": "How does the Blueprint for an AI Bill of Rights relate to the Executive Order mentioned in the context?", "1c914045-a993-40e7-8c30-04baa540d60d": "What are the implications of data discrimination as discussed in the 2016 report by the White House Office of Science and Technology Policy?", "2c023338-54aa-4e76-82ed-758897e7e44b": "How does Ruha Benjamin's \"Race After Technology\" address the concept of the \"New Jim Code\"?", "a69e9d06-2a4f-4752-bc72-15c68d003c6b": "What is the main focus of Andrew Thompson's article regarding Google's Sentiment Analyzer?", "3dc75c43-c19e-48a6-91e3-78f949db44eb": "What is the purpose of the Jigsaw Unintended Bias in Toxicity Classification competition on Kaggle?", "41065a5c-5cfa-437b-9961-7890c386f90a": "What factors should be considered when determining what is timely for an automated system?", "a1007b8e-4966-460e-8479-302da9aefbea": "Which types of systems are classified as time-critical according to the context?", "3587e733-81bc-47c0-920c-7f9c20cb1b73": "What was the purpose of the meetings conducted by OSTP with stakeholders in the private sector and civil society?", "d8bc7a39-d8b5-40f8-bbad-2757524f1a63": "Which organizations participated in the discussions regarding the Blueprint for an AI Bill of Rights?", "9c9e7bc7-4df9-40ff-b9d2-66a57b9a4da4": "What factors should be considered when identifying the intended purposes of an AI system according to MAP 11?", "9d776712-5caf-49b5-a0ee-1deb9c089a40": "How does MAP 11 suggest addressing the potential positive and negative impacts of AI system uses?", "b53d81ba-959e-4f88-9926-de966a1294ac": "What are the characteristics of trustworthy AI that should be integrated into organizational policies and practices?", "353aa795-f3ec-4c5c-9119-984a7c74ff89": "How can organizations establish transparency in documenting the origin and history of training data for GAI applications?", "168e288e-dd6f-49ad-89de-56e87885ca7b": "How do loan prices for refinancing a student loan differ between applicants who attended an HBCU and those who did not?", "f5abd789-a0d9-415d-8682-1105dbd81968": "What discriminatory practices were identified in the hiring tool that affected women applicants?", "67c5c5ab-4f38-45cd-8866-04a158294507": "How many Navigators did the Biden-Harris Administration aim to train and certify in the 2022 plan year to assist uninsured consumers?", "0e5f22ed-073b-4d2b-8d4c-e450dca94f97": "What technologies have businesses integrated into their customer service platforms to enhance efficiency and support?", "4c451868-283b-4e49-a4c8-09a506238432": "What are the five principles outlined in the Blueprint for an AI Bill of Rights?", "3604df64-bbff-4c12-b418-de489d5dab0c": "How can communities and governments implement the practices suggested in the technical companion to protect the rights of the American public?", "f3167d71-f4cf-49d1-af3a-7422fd2c0594": "What criteria should be used to establish the relevancy of data for automated systems?", "5e702a71-fc4e-49cf-abde-d6a716943b5b": "Why is it important for data to be of high quality and tailored to the specific task at hand?", "a438f42a-3086-42f3-8a49-42abaf5d34b3": "What is the purpose of verifying data or benchmarks used in risk measurement according to the provided context?", "ac97e320-c03e-4454-aa37-fb32904f2552": "How does the context address the representation of diverse user populations in structured GAI public feedback exercises?", "2e2bc17d-3103-4950-92b5-ba10d3c7ee18": "What are the key components that should be included in contracts and service level agreements (SLAs) for GAI systems?", "e88181b4-4432-480d-95ba-a7dde648b2b1": "How can organizations measure the success of their content provenance management efforts with third parties?", "ed39ecc2-b783-4a52-949e-5b0e842bceda": "What policies and procedures should be established for the continuous monitoring of third-party GAI systems in deployment?", "232b6d9d-c5b9-4b30-aa2f-ad7cd6d9164e": "How can organizations address GAI data redundancy, including model weights and other system artifacts?", "249929a6-58b5-459f-8c52-9628e3b7b63b": "What characteristics of trustworthiness does the NIST framework aim to address in AI products and services?", "b88290d6-a49f-4240-b57c-11459a59677b": "How is the NIST framework being developed to ensure a collaborative and transparent process?", "fd451664-5428-4dc8-b3e4-936e4b31b41a": "What are some of the specific areas where technology is being used to improve social welfare, as mentioned by the panelists?", "bbeb58da-3994-4c78-b6f7-65ce5fa3c465": "What concerns did the panelists raise regarding the impact of technology on individuals interacting with social welfare systems?", "9a3e32fe-5879-4da4-a0e9-9232c4a628b0": "What did various panelists emphasize regarding the voices of those subjected to medical technologies?", "6dfb1435-6402-45b1-ad69-6a245e4ba3ad": "Who were the stakeholders that medical care providers were accountable to?", "f8ecddf8-ad53-4908-a522-22235dcc866d": "What is the purpose of the NIST AI Risk Management Framework?", "d329f4d2-7b4b-4c8a-82d2-59e294d3b928": "Which organizations are mentioned as examples of effective stakeholder engagement in the context?", "95d5dc10-8724-443d-969e-b8d33f7a17a3": "What are the potential subcategories that could be added later?", "1531e01c-8dae-4edb-b08c-e361586fbb6b": "Why are certain subcategories not addressed in the current context?", "bd9cac00-116f-4d0f-b0e7-dce1119b9b76": "What role do healthcare navigators play in helping individuals access health coverage options?", "f9ea52e2-6d0c-43b0-81b7-bcbb7d07f127": "How can laws and policies be designed to support the principles of human alternatives, consideration, and fallback in practice?", "03a3eab1-7023-489a-8983-ca7fb742a940": "What is the main focus of the article by Ziad Obermeyer and colleagues published in Science in October 2019?", "a98f6f04-a113-457a-8068-896fee5529b8": "What type of safeguards does the Data & Trust Alliance discuss in their January 2022 overview?", "ad8e8fbd-741b-45dc-96c4-79c64a818cdc": "What are the specific tasks and methods that the AI system will support according to MAP 21?", "ba774841-6a7f-4e2e-bb65-8d45925e75f0": "What are the suggested actions to ensure information integrity and data privacy within the GAI system?", "21ae7cf2-34e1-4f53-bbb8-f786457f6901": "What issues does the principle aim to address regarding automated sentiment analyzers?", "684d0489-4dce-40da-973e-35452c6efba8": "How did the automated sentiment analyzer demonstrate bias against certain groups, according to the context?", "353ae25e-224f-455d-872e-c3fa012038f5": "What mechanisms should be created to protect whistleblowers who report violations of laws or risks to public safety?", "5288c627-b89e-4d7e-b9f3-9c9fbf7d34b3": "Under what circumstances can an organization be held accountable for causing harm related to CBRN information or capabilities?", "6e786805-092e-433c-aae8-9a1c6eed5961": "What are the key features that should be included in systems designed for high-risk scenarios according to the context?", "8feb5d6e-6e09-4f53-b1ea-901ecd3dfedf": "What types of statistics should be reported regarding the use of human alternatives in the system?", "20868ef2-0c59-4ac4-9282-6a07200a2a8d": "What disparities are observed in the risk assessment of Black students compared to their white peers regarding the likelihood of dropping out?", "5f8bc318-78db-4d5b-946e-288d67e057cb": "How does the risk assessment tool for predicting recidivism demonstrate bias in its predictions for different racial groups?", "868e67fe-727b-4267-884c-fc0cc7caa09d": "What are the key topics covered in the technical companion to the Blueprint for an AI Bill of Rights?", "e01879b4-183b-4c67-9514-a5b2bd07c77e": "How does the document address algorithmic discrimination protections?", "b705d103-9346-452f-ac3c-4354efb64d2b": "What are some suggested ways to mitigate the harms caused by data collection systems in communities?", "0f752dfb-e06c-40d7-8ab3-d3b400341151": "How can technology be utilized to assist individuals in receiving benefits according to the panelists?", "a4c8c8b3-27fd-439c-9f38-30a3ed3ee746": "What are the potential risks associated with human involvement in the use of automated systems?", "c19c1cc5-de5f-48eb-9356-cd81cdffef72": "How can governance structures help mitigate bias in human-based systems?", "66494484-94fa-43eb-9748-8e0211cd7bf1": "What is the purpose of the White House Office of Science and Technology Policy's initiative mentioned in the context?", "06395dbf-9875-4064-9b6b-dc0b3aa52922": "When was the Notice of Request for Information (RFI) on Public and Private Sector Uses of Biometric Technologies issued?", "182d614d-8dc8-4a63-a16f-960bfd228523": "What topics were explored in the panel discussion on Equal Opportunities and Civil Justice?", "afe0c956-44fb-4001-88d5-8a6fdafc20da": "Who served as the moderator for the event, and what is her role?", "5a94ac37-8166-4f0e-a923-8303dac16a3e": "What requirements have some state legislatures placed on the use of pretrial risk assessments?", "fdb2b4f2-7ba4-46b0-8692-86101e9380ec": "What does Idaho Code Section 19-1910 mandate regarding bias in pretrial risk assessments?", "dbc10ada-4086-4c76-9ffd-64515325728f": "What were the main topics discussed in the panel on Artificial Intelligence and Democratic Values?", "3cb7983b-7989-4697-b853-154e17adfc6d": "Who were the key speakers at the event examining the challenges and opportunities in AI design?", "bfdf7e0e-d15b-46e1-8ca5-d85f99577d5c": "What are some benefits of AI-enabled systems as discussed by the panelists?", "fa458c20-5467-4157-9fa2-cd037edc0a74": "How can lessons from urban planning inform the integration of technology in communities?", "980233ab-89a8-497d-a459-44ddce47dfe9": "What are the key oversight functions that need to be established for the GAI lifecycle according to the context?", "07677f12-28c7-41d5-acce-5dce94167091": "How should organizational teams communicate about the risks and potential impacts of the AI technology they work with?", "e742054e-0139-4116-b968-50675a3377db": "What is the purpose of the National Artificial Intelligence Initiative Office's public input request regarding biometric technologies?", "38090ee8-c020-4091-911e-3b3d4e930252": "Who are the authors of the synopsis of responses to the OSTP\u2019s request for information on biometric technologies, and when was it published?", "7da3e9e2-6d33-4371-8cca-3d6dadff1ce7": "What issue was identified with the algorithm used to deploy police in neighborhoods?", "ff636ab9-b9bb-42fe-8d94-a72e6577e31d": "How did the feedback loop affect the accuracy of crime predictions made by the algorithm?", "7d643c6f-c7d0-4961-b09a-cb382eeab677": "What issues arose from the implementation of the proprietary model designed to predict sepsis in hospitalized patients?", "7b25bd79-e13c-43bf-9a05-f28b4b9bdbf5": "How has the response to racist messages on social media affected the speech of Black individuals who criticize those messages?", "16f005ea-0a56-4b4e-8ac8-04c5fdcdb1b8": "What is the purpose of the effort mentioned in the context to create a bill of rights for an automated society?", "05c813c3-1fad-40f6-9e89-410deb049c59": "Which US Department's report from July 1973 discusses the rights of citizens in relation to automated personal data systems?", "4be30042-f927-467d-928e-703fe5a8a6d3": "What organizations are involved in the field of algorithmic auditing and risk consulting according to the provided context?", "5aa01b90-fced-4a9e-87fc-d30a4ca0e5b9": "Which university is mentioned in the context as being associated with the Citris Policy Lab and Labor Center?", "de9c2ee4-d68c-42b9-a459-7fcbc717adf8": "What type of information is required to be open to public inspection in relation to risk assessment?", "62697d18-bf94-44a0-bcb8-98a77333f367": "How do assertions of trade secrets affect discovery in a criminal matter?", "f5296a0a-e949-4cb5-9583-dcb0b84a7810": "What measures are federal government agencies taking to prevent bias in automated systems?", "c9ce896a-f400-46ba-b6bc-5771ed6f30f6": "How are non-profits and companies contributing to the identification and mitigation of algorithmic discrimination?", "dbdc0890-c9dc-4070-adba-f4cb26049d48": "What is the main topic discussed in the New York Times article from October 7, 2020?", "62ddead4-cefc-4030-ace5-7a790df8123d": "How does the USA Today article from May 2, 2021, highlight the issue of digital divide in relation to unemployment benefits?", "fb9e22af-687c-4029-b992-44c95effb1ff": "What is the significance of the ACLU of New York's publication regarding the temporary ban on facial recognition in schools?", "887c4816-5de2-4c15-8062-a35a72395621": "When was the amendment to the Education Law enacted by the New York State Assembly?", "7014face-0845-45c8-beda-4df0ae436a3f": "What are the potential risks associated with data reuse in sensitive domains such as criminal justice and finance?", "aa0cdd24-3358-4bd3-b60c-e1c5a1671274": "Why is extra oversight necessary for the reuse of sensitive domain data?", "4f10bd37-7af5-456e-be90-6f6cfd33ae16": "What is the main focus of the document titled \"Flows of Personal Data, Annex Part Two\" published on June 20, 2013?", "8a62c41a-5405-4c6f-8b17-0f12effff319": "What issues are raised in Jessica Guynn's article regarding Facebook and discussions about racism?", "929bb11b-28ad-466c-b6b6-15e6ab5da67e": "What measures should be implemented to mitigate identified risks associated with the system?", "fa80aea2-d643-4f4d-89d1-78fa10825bf9": "How can aggregated datasets be utilized to replace individual-level sensitive data?", "661e735a-d6a7-4f82-b065-850f7700005a": "What are the suggested actions for addressing GAI risks associated with third-party entities?", "6bf08eb6-9c94-4e0d-a497-29e42eb72f95": "How should document interactions with GAI systems be handled prior to interactive activities involving significant risks?", "dc4b0766-3bff-4e90-a38b-14f90c123001": "What are the expectations for automated systems in sensitive domains according to the provided context?", "e41fc621-9f8d-480b-973f-73551f6bd90f": "Why is it important to implement human oversight and safeguards for automated systems in areas like criminal justice and education?", "43ef8173-bfe5-4c58-9e39-abb227107104": "What types of systems are mentioned that impact the safety of communities?", "cbf99439-fa2f-4557-8c51-9b1f163727cc": "How do systems related to access to benefits or services assist decision-makers?", "a5f04537-355c-472a-bfcb-0a2c74df3a6f": "What are the nine principles outlined in Executive Order 13960 for federal agencies using AI?", "ae770724-5d6c-477d-a930-8d4d2acd7029": "How can laws and policies help implement the principles of safe and effective systems in real-life scenarios?", "c707357e-b8df-43c5-8bd1-86ad9c9e3d16": "What is the purpose of documenting the AI system's knowledge limits and how its output may be utilized by humans?", "71dddf88-37e4-4d5b-a434-4a71d88ac1aa": "How does the suggested action MP-22-001 relate to the concepts of information integrity and value chain integration?", "e9f912ae-a635-4ff2-bdac-5db06be39d65": "What issues are highlighted regarding the tool designed to assist low-risk federal prisoners in obtaining early release?", "2537f072-2b3a-48ce-b02a-622d3cb9e46c": "What efforts is the Justice Department making to address racial bias in prison release decisions?", "227c46de-3282-4f05-b2eb-c3e35ac4026c": "What organizations are involved in promoting civil rights and technology policy according to the provided context?", "0bbc56dc-9cb3-4c1b-82b7-5ece8c458380": "Which entities listed in the context focus on privacy and technology issues?", "3bbda291-cedc-405f-8d74-4dd51035a807": "Why is it important to have human consideration before making high-risk decisions involving automated systems?", "d67d9b48-86f5-4649-9633-add75575441e": "What should not be assumed about validation testing performed in one location or use case?", "263888bc-6c5b-4c2d-9c74-022e430b8c32": "What are the existing practices that protect the American public from potential harms related to automated systems?", "abda5e5e-668d-41c1-98a0-a393327ca225": "How could expanded protections enhance confidence in the use of automated systems?", "617558e3-627a-4bbf-8a13-3e6d25cef463": "What does it mean to garnish wages?", "fa52b8a5-eb19-494a-b68f-e2da9e7f54ee": "How does withholding tax returns affect an individual's finances?", "2da8a740-e120-4c66-a6ef-f72114a9a802": "What is the main focus of AB 701 as discussed in the Zaller Law Group California Employment Law Report?", "4b4622a2-3006-41ef-8399-9dc5c2a3f8cb": "How does the National Institute of Standards and Technology contribute to the understanding of explainability in artificial intelligence?", "61487855-7b7d-4740-b7aa-395746e2b5d2": "What are the key characteristics of AI risks and trustworthiness as outlined in Chapter 3 of the AI Risk Management Framework by the National Institute of Standards and Technology?", "4275b89e-3a7e-4a6a-9f56-f824334f58c3": "How does Chapter 6 of the AI Risk Management Framework define AI RMF profiles and their significance in managing AI risks?", "26b4c7c7-dc67-4e4d-8d8d-dff55e9abe44": "What is the main focus of the study conducted by Wu et al (2024) regarding large language models (LLMs)?", "92c2a379-3568-42c4-8bee-49a4205b6063": "What concerns are raised in the Bloomberg article by Yin et al (2024) about OpenAI's GPT in the context of hiring practices?", "be28a0c2-846f-4707-877f-e7135ff70f65": "What is the main focus of the article by Darshali A Vyas et al regarding race correction in clinical algorithms?", "57b5c032-efe0-462c-976b-21c696fcae00": "Where can the definitions of 'equity' and 'underserved communities' be found according to the provided context?", "875616ae-273a-4e7a-a313-10ebea0419cf": "What protocols are suggested to ensure GAI systems can be deactivated when necessary?", "0ac26bc2-a123-4a71-9948-38fafdd48dcc": "What factors should be considered when decommissioning GAI systems?", "69ac2751-0e75-4cbc-812c-b68cb690774b": "What should be included in the assessment of risks according to the consultation process?", "0fe6b401-f093-43f7-bbb5-66889006bdbd": "What actions should be taken if an automated system is found to have unintended safety violations?", "a2fce441-0cd1-4224-b09d-05cd16512c44": "What issues are highlighted regarding automated test proctoring software and its impact on disabled students?", "2f77a449-7aa0-4af3-a494-a9ec1d3b56d8": "Who are the authors of the study that discusses racial bias in an algorithm used for managing population health?", "1dc97abb-6090-4ecf-b57a-35a30fb9a28c": "What are the suggested actions to prevent GAI systems from generating content that violates the law?", "733b1d44-96ed-4157-8110-5c79abc02f20": "How do the established policies and procedures relate to the organizational risk priorities in the risk management process?", "84df0f9b-5053-4c04-9267-3bac77361771": "What roles do the panelists hold at their respective universities?", "a8f77b95-eaa4-4c62-9b28-60ec90356726": "What was the main topic of discussion among the panelists?", "bdd907d3-90bc-4b5c-b2f8-22a14e2e4eea": "What are the suggested actions for managing GAI risks in relation to legal and regulatory requirements?", "7d6a4a7f-529e-4eeb-bc5f-dfed19a4836f": "How do AI Actor Tasks vary between AI development and AI deployment in the context of GAI risk management?", "379409a7-11a5-46f8-a922-f01822752245": "What aspects should be considered when assessing the meeting of goals in the context provided?", "5038d784-f939-44ff-8421-d957b6a2ef5d": "How should the reporting of data and governance regarding access to technology be presented?", "f825e730-70d6-45e7-a991-d84b70dedbdc": "What are the key aspects to review and document regarding data used in the AI life cycle according to MP-23-002?", "983fa531-c273-4f2e-8412-31414dfa2427": "What techniques should be deployed to verify the accuracy of information generated by GAI systems as outlined in MP-23-003?", "0431f0a4-1c06-4193-b56e-8f1954b1bf6a": "What is the focus of the National Institute of Standards and Technology's AI Risk Management Framework, as mentioned in Appendix B?", "01bb100e-f860-400e-a49e-bf3326ff3b88": "Where can one find the AI RMF Playbook published by the National Institute of Standards and Technology?", "732298cc-a7cd-4afd-aaa0-156689318281": "What is the focus of the National Science Foundation's program mentioned in the context?", "49171449-883d-4c0c-bf2e-bd800c4b8a73": "How does automatic signature verification software potentially impact US voters according to the article by Kyle Wiggers?", "b2bf3d18-362b-4c00-8fc3-7a3aa226d22f": "What are the key components involved in the value chain and component integration related to information integrity?", "f7041767-28f1-4cbc-be37-2d9215a3f908": "How does governance and oversight play a role in the tasks of AI actors?", "2d426057-d7ae-460b-819e-c2a8e32c316e": "What percentage of racy results did Google cut for searches like 'Latina teenager' in March 2022?", "084682cc-e738-4536-b480-4ff210f8ebc1": "Who is the author of the book \"Algorithms of Oppression\" and what is its main focus?", "56014d00-cca7-467c-890e-d1cea73d3e2e": "What aspects of performance testing are included in the evaluation process?", "b62d5388-f2a9-4dc8-a5f1-f65237eab5e5": "How should the reporting of performance testing results be formatted for accessibility?", "51bda860-1005-4957-85c3-5c3494db2268": "What concerns do students, professors, and education experts have regarding the use of race as a predictor of student success in major universities?", "2a49441b-382a-4d78-8610-ab81b9b92095": "How might the use of race as a predictor impact Black students in the fields of math and science?", "e1e4f53a-b337-4f26-ac49-7cab55868102": "What is the purpose of implementing a use-case based supplier risk assessment framework according to GV-61-005?", "37246c5b-bfa3-4e88-b39f-363a2745b787": "What actions are recommended in GV-61-006 regarding contracts with third-party entities?", "f7715b04-2bf7-4733-bbb9-177cf53ac0ac": "What is the purpose of ongoing monitoring and periodic review in the risk management process for GAI systems?", "23cb44ce-136d-47f6-bf20-20a4c72c8819": "What are the suggested actions related to defining organizational responsibilities and establishing policies for GAI system incident response?", "db491d38-6e46-48a0-ae93-1f58468ec535": "What are the potential impacts on victims of non-consensual intimate images, regardless of the authenticity of the images?", "b27eaebd-974a-4c14-be3c-c30042612cc3": "How did the AI-powered cameras in delivery vans affect the eligibility of drivers for bonuses?", "b3529031-625c-4528-984b-1b225d0ebf9f": "What are the key expectations for automated systems to ensure they are safe and effective?", "7aaecc09-c051-484f-8f59-03288be6693a": "How should automated systems avoid the use of inappropriate or irrelevant data?", "77440e07-7a72-4e6b-80bc-454888f3684d": "What are some examples of speech-related systems mentioned in the context?", "b9c9a65e-f5b7-41e7-b6b7-15485cdf441f": "How do surveillance algorithms impact privacy in public spaces?", "356bb6a8-9094-4e50-a284-8d6ff3a9b659": "What are the key considerations related to scientific integrity and TEVV that need to be documented according to MAP 23?", "971a0a03-e3a7-48e5-a914-0763d20e61e4": "How can the accuracy, quality, reliability, and authenticity of GAI output be assessed?", "9f7af070-2a14-421b-a2ea-01b90e59a12e": "What are the key tasks involved in AI Actor roles?", "ee8f89f4-1125-415b-b45f-ecce7120ef2c": "Who are the primary stakeholders in the AI Actor framework?", "5fcc3605-d518-42b2-afad-7c3d5307c668": "What are the potential consequences of data privacy breaches involving biometric or health information?", "5b9edce2-2386-43da-a7fa-eb9d4e1dc866": "How can the environmental impacts of training or operating GAI models affect ecosystems?", "b7b191f8-d54e-407c-833d-a59910bc2fc3": "What is the focus of the National Institute of Standards and Technology's 2022 publication regarding artificial intelligence?", "1d5717ff-856c-483f-bb45-e9bfa86af9c6": "How do pervasive label errors in test sets affect machine learning benchmarks according to Northcutt et al (2021)?", "35020e63-ee1d-44c0-9cec-aaff1bc83dc2": "What are the main findings of the report \"The Public Health Crisis Hidden in Amazon Warehouses\" by Human Impact Partners and WWRC?", "700a27d0-fd9d-44db-b1e6-b1f6a1321ae3": "How are surveillance programs affecting contract lawyers according to Drew Harwell's article in The Washington Post?", "004bc31d-e125-47af-9b8d-935ebdb245d3": "What is the role of the Information Technology and Innovation Foundation in relation to the Information Technology Industry Council?", "d8ec5e9d-6254-4753-9e32-6d9cf4644335": "Who are some of the individuals associated with the Innocence Project mentioned in the context?", "0fdabd43-29e0-4431-97d1-26703e5ced15": "What is the purpose of the email address ai-equity@ostpeopgov created by OSTP?", "912370ef-6945-4672-b64e-35e0dd936bcb": "What information was OSTP seeking through the Request For Information (RFI) regarding biometric technologies?", "d555f200-a1bd-41d7-bb08-c55c709ef10b": "What does it mean for a decision to be made on a fully or partially autonomous basis?", "520f5c33-c60e-4952-b4b0-81448a82d187": "In what situations might there be a determination to revoke benefits?", "786fad00-f7ff-4ecc-800e-5164c6f2c8c8": "What are some of the risks associated with using AI in high-stakes settings as discussed by the panelists?", "08b5b0df-0afc-42e8-ad8c-53b66f749264": "How do the panelists address the issue of public trust in relation to AI technologies?", "954d1448-4e8b-4376-b29f-4f60731c0a80": "What concerns were raised by panelists regarding the delivery of healthcare through technology?", "98a79e92-2a8c-490b-9106-6a2131d839bf": "How do racial biases in medicine impact the effectiveness of technology-enhanced care, according to the panelists?", "e0d51396-2dbc-4605-93b3-0b84d55ef15c": "What are the key priorities in information integrity research and development?", "fd06b7f6-0454-4494-91ec-ebd057e3e76b": "How does information integrity impact research and development processes?", "9d229864-4c98-46d1-bf94-5f82a4027b93": "What types of information should be included in the reporting for systems in use?", "49eea1a9-360d-421b-9f53-bd4b133441cb": "Why is it important to report on training and governance procedures for technologies used in sensitive domains?", "3e5bb9db-2f15-4257-91c7-10771c71ac85": "How can GAI systems contribute to the unintentional production of misinformation?", "cd88aab0-6ccd-4d9b-947b-8d1ab3101801": "In what ways might GAI systems facilitate the deliberate dissemination of disinformation by malicious actors?", "72cb5b32-d4ed-44f7-be99-04f2427297e3": "What actions has the Consumer Financial Protection Bureau taken regarding black-box credit models?", "8c9879a8-b85b-4b26-82cf-2c4781491103": "What information does the Federal Trade Commission provide about using consumer reports for credit decisions?", "458f2be6-4458-4a3d-a4e4-46cbdb34208d": "What technologies were discussed by the panelists in relation to the criminal justice system?", "c54d037d-03f5-44b4-b17f-5773115ce5f4": "What was the main emphasis of the panelists regarding community safety and strategies?", "6c25d095-8f4e-460d-bfdc-1c00de18e98a": "What challenges does the automated moderation system face in distinguishing between counter speech and hateful messages?", "06d23801-c0ea-436d-a3c4-9c0ae74a89ea": "What measures has the device manufacturer implemented to protect individuals from unwanted tracking, and what limitations do these measures have?", "beed923b-9632-465b-8945-6188e7417627": "What measures should be taken to combat automation bias in automated systems?", "f0b72c15-a5d5-4868-ba7b-f0841bef1f59": "Why is it important for individuals interacting with automated systems to receive regular training and assessment?", "51693b37-f0fb-4003-bc19-82044430a50e": "What organizations are involved in the Project On Government Oversight?", "32d118c0-43d3-41d8-b7ea-5f731a11aa69": "Who is associated with the Science, Technology, and Public Policy Program at the University of Michigan Ann Arbor?", "26a57c8a-15a5-41bd-b361-5a3063a9039c": "What are the key components that interdisciplinary teams should reflect according to MAP 12?", "9752d5bd-37b5-41b2-979e-ff6bf01cfef3": "How does the establishment of interdisciplinary teams contribute to addressing GAI risks?", "82580fad-cc16-41dc-a454-0cd340cb542f": "What are the criteria for the kinds of queries that GAI applications should refuse to respond to according to the acceptable use policies?", "aa722549-21c4-4a23-aa9c-791d3f502887": "How can user feedback mechanisms for GAI systems be established to include thorough instructions and recourse options?", "63f6abc9-62fc-45e7-a660-0cc6c0b13d91": "What was the main issue highlighted in Scott Ikeda's article regarding the data broker's exposure of social media profiles?", "f67be9ce-c3f1-4287-b92a-b32b27f32a59": "What prompted backlash regarding facial recognition technology in public housing, as discussed by Lola Fadulu?", "3bf60769-6455-4fe4-984f-dcba696b2361": "What role do strong transparency requirements in smart city projects play in reshaping power dynamics for marginalized communities?", "9aae4761-e502-4163-9bc4-688f16fc6f6b": "How do panelists suggest that technical and governance interventions can protect against the harms of emerging technologies?", "417b6bdf-4fbb-4063-8f7f-8e2701992674": "What are the potential impacts of AI-enabled \"nudification\" technology on individuals, particularly women?", "16e59462-cdac-41e7-bc1f-268f6157185f": "How does the principle of \"safe and effective systems\" aim to address the issues related to image-based abuse?", "cc2eab1d-4bd2-4ea8-b85f-848435a62b78": "What types of technologies are included in health and health insurance systems?", "ad14de61-54ab-4819-8135-27811f223694": "How do financial system algorithms determine credit scores and loan allocations?", "3fd54119-7334-419d-93b9-81a81943cb96": "What are the primary considerations derived from the GAI PWG consultation process?", "2181f3db-4508-464a-bff3-47a13aa0f2eb": "Who contributed to the analysis and development of the primary considerations for GAI?", "97eb2b86-5cb1-4067-8b3e-238ffe524dbe": "What organizational policies are suggested to foster a critical thinking and safety-first mindset in AI system design and deployment?", "f08c3dee-07ea-4aca-a552-23551165216a": "How can organizations address the risks associated with a lack of explainability and transparency in GAI systems?", "8a89c0ec-05ad-42a6-80ec-5731b87da313": "What is the role of Carl Holshouser at TechNet?", "da91d205-0f53-48d4-aaa0-4652475a5669": "Who is the National Campaign Director for the Partnership for Working Families?", "d9f719ba-8a1f-4a79-9681-f89d004f5737": "What are the special requirements that adversaries are often subject to regarding classified information and protected data?", "e95df5e6-5ba1-4a69-9a59-00edeaadfc0b": "How can the implementation of the Blueprint for an AI Bill of Rights inform national security and defense activities?", "f933d896-f53d-48c2-90d8-294ea06404ab": "What themes were explored in the panel discussions regarding automated systems and democratic values?", "93a6e5b2-6563-4bad-b36f-76417d1b7957": "How did the panel on Consumer Rights and Protections address the challenges faced by individual consumers in an AI-enabled ecosystem?", "3faa9db4-95ac-41a5-992e-80b799e94d1e": "What are the key elements that should be maintained in records of changes to content made by third parties according to GV-61-008?", "44d6504c-a7ed-46de-8487-836032e6c09f": "What updates are suggested for due diligence processes in GV-61-009 regarding GAI acquisition and procurement vendor assessments?", "00b93ab4-597d-4aaf-8adb-24e047da7432": "What are the main themes discussed in the paper \"Algorithmic monoculture and social welfare\" by Kleinberg et al?", "2d001394-e5e1-437b-99f9-18ff2f904852": "How do the findings in \"GPT detectors are biased against non-native English writers\" by Liang et al contribute to the understanding of AI biases?", "73012a6f-b05e-409f-b7a8-3e723dcfef4a": "What should be the level of responsibility for establishing governance procedures within the organization?", "4f471ed3-bf87-4055-bc52-d3ede6c01552": "Why is it important to conduct an independent ethics review before deployment in certain cases?", "9be7480e-bc18-4330-b7a6-192eb8d3d094": "What is the significance of existing human performance in relation to the algorithm's pre-deployment standards?", "7466e7c9-8d04-43cd-8727-806c048d70e1": "How should potential risks of the automated system be addressed before deployment?", "ec6465db-3f03-4ee6-8cde-36da907acf6f": "What is the main focus of Mike Hughes' article regarding the interaction between robots and humans?", "b8940ee1-5f9a-41f9-a976-85795854574f": "What topic do Rachel Orey and Owen Bacskai address in their blog post from November 4, 2020?", "d6a01d7c-873d-489c-8980-fc16c62b3f98": "What are the key components of Information Integrity in relation to Information Security?", "166fb241-6f91-4d1a-8948-339f4f56d962": "How does Intellectual Property relate to the concepts of Information Integrity and Information Security?", "ec28b524-df88-473c-bcba-bc62e415e0ad": "What are the primary goals of field testing in relation to AI-generated information?", "58a86d0a-e7fb-4536-bc96-117d497cfe9e": "How does AI red-teaming contribute to identifying flaws in an AI system?", "08f6c04e-6be1-44d2-8d2b-266cceaa2bea": "What processes are defined, assessed, and documented to ensure operator and practitioner proficiency with AI system performance and trustworthiness?", "2bb117c3-a4cc-4704-a90c-dea986f1fc4e": "How can existing training programs be adapted to enhance understanding of digital content transparency in relation to GAI risks?", "87f1a12a-7437-47d9-9dc5-fb9cbc55599b": "What considerations should be taken into account for government applications that involve law enforcement or national security?", "96913c42-c028-498d-8ce3-f55043c341a4": "Why is it important to document concerns raised during consultations regarding automated system development?", "a52c8c8f-6d0d-41ab-aa89-321a392b8b80": "What factors should be considered when assessing the validity and accessibility of an explanation?", "a9771743-0615-495b-ba9a-d4360bb74a2b": "How should individualized profile information be presented to ensure clarity and machine-readability?", "305a54e7-47f5-464f-a20e-8aa5577d2032": "What factors should be considered when calculating error ranges for explanations in the reporting system?", "6d30af9e-5158-4291-8433-2ced6c8042a7": "What elements should be included in the summary reporting to ensure accountability and clarity?", "fb5749e2-bea1-4ed9-a502-706a4b9bc3b9": "What are the potential negative consequences of the creation and spread of NCII on individuals, particularly women and sexual minorities?", "2294513c-d261-4c6c-bd49-df9f27255742": "How might the inclusion of CSAM and NCII in training datasets for GAI models impact efforts to address these issues?", "baa4870b-f3a5-48ed-8cf9-9f92726e4105": "What are the main concerns addressed in the paper by Staab et al (2023) regarding privacy and large language models?", "ed94b388-a541-4681-b726-394322950c20": "How do Stanford et al (2023) investigate the representation of opinions in language models?", "f596d7fd-0757-4241-b41d-32d393b7cf1a": "What are some examples of participatory engagement methods that organizations can use to involve external stakeholders in product development?", "d474d256-c67a-4127-9f02-d14eeb3ddffa": "How does field testing differ from participatory engagement methods in terms of structure and purpose?", "6c38a794-61ab-4649-a3a6-edce03d8acc0": "What are biological design tools mentioned in the context?", "d0669463-cb91-458a-a746-f16e12625302": "Where can the document related to biological design tools be accessed?", "f4d9dfe4-c111-4d37-b709-9f45bf4849c4": "What steps should be taken to mitigate or eliminate disparities in automated systems?", "9ef8f338-7f27-437b-bad6-9ba96f8327c3": "Under what circumstances might the use of an automated system be reconsidered?", "ef603791-797d-4ede-961a-3e88890b0590": "What is the focus of the article by Karen Hao regarding AI ethics?", "161fadd9-9d76-49e8-9bcc-96323e62c156": "What type of companies are highlighted in Disha Sinha's article about ethical AI?", "90baba5e-a92d-492a-9609-cf95cb942c79": "What organizations are associated with the Digital Therapeutics Alliance?", "99b96a64-cc84-4a85-bff0-125a23188807": "Which university is linked to the Center for Human Rights and Global Justice?", "eff8c255-0e86-4d8d-9e33-c9051eab2260": "What is the importance of involving end-users and practitioners in the prototyping and testing activities of GAI systems?", "2d18dbc8-2c70-48c3-ad45-9e35afb823ed": "How can systems be implemented to monitor and track the outcomes of human-GAI configurations for future improvements?", "9da1eebe-bd9c-4c2a-88ae-afe9f9f832ab": "Why is early-stage consultation emphasized in the development of automated systems?", "4db9bf4b-8967-4add-b1ce-df46bacc26ae": "How should outreach to relevant stakeholders differ based on the specific automated system and development phase?", "eacf1e17-a149-4ff4-ab67-33ca8708eda2": "What are the expectations for automated systems intended to serve as a blueprint for?", "5214d914-1f0a-4b9c-95f8-d68a34380192": "How do the expectations for automated systems address unmet needs for change?", "fa030f8b-43ad-4eb4-8021-c1d1bf17bd2e": "How can innovation be encouraged while ensuring the safety of individuals?", "55483612-9daa-4013-9d63-35487cf2245b": "What measures can be taken to protect people from harm in the process of fostering innovation?", "ba16a05d-c693-4c57-8f68-caf13976352a": "What are the key characteristics that define high-integrity information?", "9108a1be-0851-4551-8abf-f48c57745831": "How does high-integrity information distinguish between fact, fiction, opinion, and inference?", "76187161-7bf9-473f-bdad-52943f58630a": "What are some purposes that feedback activities can serve in organizations?", "51c1162e-c451-467c-ab38-d04d925ecc7a": "What best practices should organizations follow when implementing feedback activities?", "b1d55148-137d-4244-8383-336754a0e9ac": "What types of entities should be given access to the system and associated data for evaluations?", "c9aa2c01-3093-4b77-9909-7b1164ef09bd": "What mechanisms should be included to ensure independent access for evaluators of the system?", "eb90834f-0717-4562-8c96-84c576041e08": "What are the suggested actions for addressing privacy risks associated with AI-generated content?", "a1388208-65ec-45f4-8d15-40eed225e57b": "How should organizations respond to potential intellectual property infringement claims according to the provided context?", "6d160348-a777-4aa3-a897-ec1e0936c1a0": "What are some examples of \"sensitive domains\" that require enhanced data protections?", "6a916ce0-e95e-4242-8dcf-6a0a1c9f9654": "Why are activities in sensitive domains considered to potentially cause material harms?", "9bf60638-6f9a-490c-860d-d0f869078488": "What is the purpose of the National Artificial Intelligence Initiative Office as mentioned in the context?", "b4e90fbc-bbf9-4f4e-9be4-80c8c414ed98": "What are \"traffic calming\" measures and what benefits have been described by the US Department of Transportation?", "b28d2b18-9546-492a-a77d-97d079e9675e": "What is the purpose of the Executive Order on Advancing Racial Equity and Support for Underserved Communities Through the Federal Government?", "857d547f-f6e4-4cf1-8273-1535a51dc077": "What was President Biden's response to the Supreme Court decision to overturn Roe v Wade?", "6d471bbe-5906-4f18-92cc-cadfab11febe": "How do inaccuracies in labels affect the stability of benchmarks in GAI model selection?", "616bf44d-3c5c-4199-8f47-21fa9891a24c": "What are the suggested actions to manage risks unique to or exacerbated by GAI?", "2911f142-5a22-4310-8c84-811d74956c2c": "What types of information should be included in GAI system inventory entries according to the context provided?", "927042dd-6a23-4e8e-925a-30b18f418e8c": "What are some examples of external information sharing resources mentioned in the context for reporting known issues?", "59e551e5-956e-4217-adae-e9728a4b092a": "What factors should be considered when tailoring the extent of explanation provided by a system based on risk level?", "2c797751-76c2-452a-bb2b-5d046a626e13": "Why is it important for the explanation provided by a system to accurately reflect the influences that led to a decision?", "5727e49b-f824-4ee1-8717-c69ace3d181a": "What processes are suggested for identifying emergent GAI system risks according to MEASURE 32?", "cac4b91a-ef89-4329-bda0-de1306184e94": "How are feedback processes for end users and impacted communities integrated into AI system evaluation metrics as outlined in MEASURE 33?", "b71ac209-d228-4bc7-9ccd-baf21df11483": "What are some of the concerning uses of AI systems in education mentioned by the panelists?", "b8315e29-7762-426f-8d10-aaef49f38d9a": "How do the panelists describe the impact of technology on access to equal opportunities in housing?", "122b07a9-9fa9-45ad-a73b-9aec4cb5c08a": "What are the key ethical principles developed by the US Intelligence Community for the use of artificial intelligence in national security?", "a68160d3-0567-4343-a40f-7d89f0aecb0a": "How does the National Science Foundation contribute to the development of automated systems that align with ethical principles in AI?", "6c0f3fe9-3d59-4bff-a72c-ac9594b178de": "What types of systems are mentioned in the context that have the potential to lead to algorithmic discrimination?", "47d8c023-4e9b-4c7d-8fd5-666e04deeff3": "How do education-related systems utilize algorithms in relation to student monitoring and resource access?", "0ea62a7c-c6ac-4dbb-a1a2-c6b86253c26b": "What are the key elements that panelists believe are necessary for fostering responsible innovation in companies?", "c4106a36-e5ee-47ca-a40e-51026ab777cb": "How does the event address the impact of technology on public safety and democratic values within the criminal justice system?", "e79daf3f-c86a-45de-a8ad-ff4161513537": "Who is the Senior Policy Advisor for Data and Democracy at the White House Office of Science and Technology Policy?", "83fcaf62-6991-4387-a7d3-187b74487e42": "What role does Jennifer Clark hold at the Knowlton School of Engineering, Ohio State University?", "714ed52e-e058-4224-9dfe-00dabe17db10": "What are the main concerns addressed in the paper by Qu, Y et al (2023) regarding text-to-image models?", "c618d475-dc14-4be2-a23d-1c48370862ee": "How does the study by Rafat, K et al (2023) propose to mitigate the carbon footprint in deep learning model compression?", "6611077f-eedc-4bb6-a96a-1d4d786ab0c3": "What is the purpose of the US Department of Energy's Artificial Intelligence Advancement Council?", "41e73b94-9f1e-46ca-bb92-56e225c88ca2": "What document outlines the US Department of Defense's Responsible Artificial Intelligence Strategy and Implementation Pathway?", "d10a9bd4-e4b5-4a51-8b28-26cd73189db4": "What are the key characteristics of trustworthy AI mentioned in the context?", "06e1aa92-d446-420c-885c-893376904274": "How does the energy consumption of training a single transformer LLM compare to carbon emissions from flights?", "af10c236-ccc0-4eab-b631-dc58a43fbd43": "What action did the Biden-Harris Administration take regarding health care navigators ahead of the HealthCaregov open enrollment period?", "66006e24-b009-4b20-b673-657f77dd250f": "What are the sources mentioned that discuss the state of customer care in 2022?", "089e485b-34ae-4a3b-897e-04fba7415116": "What is the focus of Andrew D Selbst's article in the Harvard Journal of Law & Technology?", "f85c37cb-b434-4bbc-93d9-db1ebed6ca5c": "What initiative did the Department of Justice announce on October 22, 2021, to address consumer harms?", "f5dce8ee-2be9-493c-bc14-c5b579e81d6f": "What are the key principles that systems should follow regarding user experience and design decisions related to privacy?", "5e08a1e5-1255-4e4e-b07b-aac1b71a7541": "How should consent requests be structured to ensure they are meaningful and understandable for users?", "36f2cad8-3003-46c7-bd8b-e63232bdd010": "What are the key concerns related to data privacy and intellectual property law in the context of AI actors?", "e9f1d0e2-ef65-4867-8e57-79ea0c329423": "How does the OECD define AI actors and what roles do they play in the AI system lifecycle?", "b0b492f2-87d5-4804-b84a-2d4180354466": "What types of services are mentioned in the context?", "8a6cd034-4f47-43fa-b296-386579efba27": "How does the context describe the nature of information provided about goods and services?", "f6d6e8c1-7663-4640-9f07-deeb8b7b8e74": "What types of housing-related systems are mentioned in the context?", "9aaedae3-7d67-4247-aeb5-7b34b9304ac9": "How do employment-related systems influence terms and conditions of employment?", "945a7ce4-91fd-4bb1-b3f9-51c9eff03961": "What policies and practices should be implemented to define the use, storage, and protection of third-party intellectual property and training data?", "495097bd-f455-477f-90ec-87aec5446543": "What steps should be taken to re-evaluate risks when adapting GAI models to new domains?", "d7518a3f-1733-477b-a336-39510d569853": "What factors should be assessed to determine the expected and acceptable GAI system context of use in collaboration with socio-cultural and other domain experts?", "130a2170-3e80-4a93-8fe4-8c96367e34e7": "What elements should be included in risk measurement plans to address identified risks related to harmful bias and homogenization?", "b839d9de-29dc-44bc-8cc9-cd5a84f76f5f": "What are some of the extraordinary benefits brought about by automated systems mentioned in the context?", "93cd906b-b7ca-4ff8-950f-c864a6ffe9ca": "How can the use of data and algorithms impact global industries according to the provided context?", "2ad6d02e-d6a5-4c24-8b34-a123d193fd5a": "What are the main predictors of non-consensual dissemination of intimate images according to Karasavva et al (2021)?", "ac52fd98-ad98-4508-a21b-6a0f6d816f3c": "How does Khan et al (2024) describe the value chain analysis of generative AI?", "7bd39d7a-241d-4703-8cea-bbfca7733fc8": "What key components are included in the regularly-updated reports regarding the system's integration into the organization's business processes?", "7d9eb089-4c9b-4bc5-8dc7-cc2330e0ed55": "How is data used in the system described in the reports, including its processing, potential issues, and relevancy justifications?", "3778ab16-dd62-4119-a14b-6c5926550c44": "What are the key considerations for establishing policies related to data collection and retention as mentioned in the context?", "bc7dc686-b036-4398-a9b0-a3ccf302f926": "How should training data curation policies be documented according to applicable laws and policies?", "656019f7-8de4-4cdd-8168-205382847f30": "What are the characteristics of trustworthy AI mentioned in the context?", "4d3a20d9-d9c0-4a35-8d72-e3ad07cd8146": "How can human perspectives and experiences impact interactions with GAI systems?", "c317a02b-226a-4d85-b702-7498342d0e00": "What factors should be considered when testing technology to ensure it works effectively in its real-world context?", "10deb2db-b3ec-492f-bc9f-d900c4959dcf": "Why is it important to compare system performance with existing human-driven procedures after testing?", "0ebe9bf9-c57c-4b46-92d9-533f6417b023": "What are the implications of collecting information on individuals without their consent or legal authority?", "8110ffb1-0ce6-46a8-abfd-74223dee61f5": "In what situations might surveilling individuals be considered acceptable or legal?", "3935dde0-383c-431b-9750-fd27c40ecc70": "What are the differences in energy and carbon intensity between generative and discriminative tasks in LLM inference?", "b9de3306-ba8b-40de-9a47-6d56aedfca24": "What methods can be used to reduce the environmental impacts of trained models during inference?", "cb35b789-148c-4c72-91c3-c820e95910c6": "What are the key components that should be included in incident response plans for third-party GAI technologies?", "20db5e88-2ccc-49b0-8cc8-e502be3ac630": "How should organizations ensure that their incident response plans for third-party GAI technologies are regularly updated and improved?", "ccd77b49-dd6d-42a0-bd75-752367bf3fda": "What are some examples of automated systems that can produce inequitable outcomes according to the context?", "9a7fa9b1-de78-49d7-85c2-98d75667a3e6": "How can data that fails to account for systemic biases impact decision-making in areas such as law enforcement and healthcare?", "56cee28d-8f3e-4388-a961-0ed6feb4eb55": "What considerations should be made to ensure requests are accessible to users with disabilities?", "13fd240c-c5d1-470f-a63e-49db4b3534b8": "Why should user experience design avoid using \"dark patterns\"?", "4c8a0c94-616e-4874-bb18-18dfaae5579f": "What steps should be taken if a proxy is identified during proactive testing of an algorithm?", "8f2b2c91-010d-4e0c-8ae7-8419478483e4": "How can organizations ensure that a proxy feature does not contribute to algorithmic discrimination?", "50f5c5bc-3a7c-4e59-9899-6160dd8a0cd0": "What are the key expectations for automated systems as outlined in the context?", "9a1cf5df-24ee-445f-8059-0d7be65bac75": "Why is it important for automated systems to be tested for algorithmic discrimination before being sold or used?", "fa083022-7f0c-42ab-8b54-6aab42e4190c": "What types of sensitive data are mentioned in the context that could expose individuals to meaningful harm?", "c50f9c2a-167d-4ba2-854b-3cb9a17bee44": "Why is data generated by or about individuals who are not yet legal adults considered sensitive?", "9ab3d54c-0f0e-4db5-96b0-58213489ec2b": "What is the focus of the article from the Canadian Centre for Cyber Security regarding generative artificial intelligence?", "c267ed1c-25b9-4001-9c7d-ce762c25efb4": "What are the main findings discussed in the paper by Carlini et al (2023) on quantifying memorization across neural language models?", "91d3fb6e-d6ad-4d1d-9c91-ea68c34efb70": "What is the primary goal of NIST in relation to artificial intelligence?", "71c8629e-2135-4d21-90f7-eb86c3115b2c": "How long has NIST been conducting work on AI?", "308ad885-574a-49bb-a36a-e368b01bda7c": "What are the conditions under which sensitive data can be used for non-necessary functions?", "91c3ad0b-2f84-4c9a-9739-937f3660c353": "How should consent for non-necessary functions be obtained according to the provided context?", "11d22e1f-5ca0-49fd-9476-285764bbc724": "What is the purpose of conducting a thorough ethical review when using sensitive data in decision-making processes?", "3fb526fc-94d9-4752-b1c3-ef29446e338c": "Under what circumstances might an ethical review determine that sensitive data should not be used or shared, even with consent?", "15ac65b5-cd14-4b8e-a054-9aa3f8d01671": "What is the focus of the paper by Padmakumar et al (2024) regarding language models and content diversity?", "a6cb139e-3465-4cb9-a7b7-056e2b9ca4e2": "What are the main topics covered in the survey by Park et al (2024) on AI deception?", "d9b33503-daaa-45f1-9182-a32d1618bf32": "What is the address of the National Institute of Standards and Technology (NIST) mentioned in the context?", "61288b27-9f80-4307-82bd-ea61f8f92693": "Where can additional information about NIST AI publications be found?", "56333e99-2b70-4956-8876-50d3166cafac": "How do societal norms influence the classification of sensitive data over time?", "0ccd4664-8637-4810-9268-3f510d46f723": "In what ways can the context surrounding sensitive data impact its perception and handling?", "d9e47b65-2160-4c25-990c-d97d48b9f3bc": "What is the purpose of the AI Bill of Rights mentioned in the context?", "e12a5b2d-10db-4000-985e-746a0e8ac848": "When was the Blueprint for an AI Bill of Rights published?", "cc75ef46-6e66-43cd-af22-977eee389821": "What does the Biometric Information Privacy Act in Illinois require from private entities regarding biometric information?", "d99a10e2-0bc0-4648-a976-823ccb212764": "How can the principles of protecting rights and access be implemented in real-life scenarios according to the provided context?", "3d687266-478f-4d0d-bce9-e4c19f28d1e8": "What issues does the principle of human alternatives aim to address in the context of unemployment benefits systems?", "ffe8cef9-bb4e-40cb-ba13-a5954823616a": "How did the fraud detection system for unemployment insurance distribution negatively impact individuals with discrepancies in their files?", "5ae68c19-ce9d-4e17-85c7-aaa8f21d3430": "What methods can be used to assess the general awareness of end users and impacted communities regarding feedback channels for AI systems?", "6719067e-5248-4170-9256-c3838f6354a6": "How can the trustworthiness of AI systems be measured throughout their lifecycle according to the provided context?", "a6398c65-3d0a-4157-b42e-d9739cd5c8c3": "What are some appropriate responses to identified privacy risks according to the context?", "4a612055-ba4b-414f-b5ba-6dac5895439c": "Why is it not acceptable to transfer privacy risks to users through notice or consent requests?", "6731ed13-2847-44c5-b083-314efffeccc6": "What are the novel methods and technologies being evaluated for measuring GAI-related risks?", "248048f3-dbcc-45e8-93d9-e1b97b3019e8": "How do the models ensure valid, reliable, and factually accurate outputs while assessing risks in content provenance and offensive cyber?", "5a0c24cc-7817-46f7-90fa-f789cebe53a8": "What are some known past incidents and failure modes associated with GAI systems?", "1391bb83-c561-4a28-b3db-14befca4e8e8": "How can organizations identify and document foreseeable illegal uses of GAI systems that exceed their risk tolerances?", "96769580-6e3c-4146-a5ea-9a1ecd31f393": "What are the key components that should be included in the policies and procedures for risk measurement?", "a4d84aa7-cfaa-4c02-8b3f-32dfa8dbcc0c": "How can structured public feedback exercises, such as AI red-teaming, enhance the risk measurement approaches?", "b64252cd-b8d8-49bf-a8ed-e14bfa1495e2": "What factors should be considered when determining the objective of disclosure in relation to GAI systems?", "2c0dc893-4c31-40c2-a859-d5991a6fcd0d": "How can adversarial role-playing exercises help in identifying unforeseen failure modes in GAI systems?", "1be3b222-6179-4eb6-856a-34cfeb9e6936": "What legal relief can an individual seek if a federal agency does not comply with the Privacy Act\u2019s requirements?", "35b652df-c78f-402a-8c7c-e7f98b39b37b": "How does NIST\u2019s Privacy Framework assist organizations in managing privacy risks?", "c3043bc4-6858-48ff-ba2d-82c2b8f1100e": "What procedures should be established to engage teams for GAI system incident response according to GV-21-002?", "eaf9d28f-4861-4d70-bd8a-495d8c0a786f": "How can organizations verify that AI Actors conducting GAI incident response tasks possess the necessary skills and training as outlined in GV-21-003?", "a302b788-f0f0-457b-ab4f-8a8051d4c851": "What are the two main categories of risks associated with advanced AI as mentioned in the context?", "a031b2a2-3ba0-44a6-8914-df82985a20c0": "Can you list some examples of technical/model risks identified in the context?", "bb7d29d0-612a-4b2e-99bc-52f256eac44d": "What mechanisms should automated systems provide to allow users to opt out in favor of a human alternative?", "95271837-9565-4fd8-99be-c19d1b865958": "Why is human oversight and training important in the context of automated systems used in sensitive domains?", "3a1e9480-9bbf-4c18-baa1-32d96af2151b": "What is the significance of the number 73 in the given context?", "f1fd0080-6ef2-4e09-8be1-7f63f9850e3f": "How does the number 73 relate to other numbers or concepts mentioned in the context?", "a208b877-6a39-4ff3-8c91-26ad2f7c1797": "What are the key considerations for organizations when applying governance principles to generative AI models?", "6294c3d9-8509-4c03-b6ab-99fdf4b6c569": "How might organizations choose to revise their existing risk tiering for generative AI systems?", "b6e5fa4f-a8fa-47ff-b8cc-30d6a6dfd93e": "What are the key concerns and risks associated with the deployment of automated systems?", "8409739c-5f4a-418b-8678-f1923e88580e": "How can ongoing monitoring contribute to the identification and mitigation of unsafe outcomes in automated systems?", "672f8105-add9-473e-802e-6910437cdf51": "What are some best practices for ensuring privacy in a consented use case?", "e99e2bed-bbc8-4104-af98-55e187963eab": "How can privacy-enhancing technologies contribute to system security protocols?", "1e338f74-3c26-40ac-90ab-7c33de3bf1d0": "How does alignment to organizational values influence auditing and assessment processes?", "c1f1ced1-ed2d-4957-8830-5ab690ced3a4": "What role does data provenance play in change-management controls?", "f7bb5c35-a0db-40db-b458-e74166a89309": "What options do individuals have if they encounter problems with automated systems?", "d2e42cc8-4017-49b5-841b-cdf11f84089d": "Under what circumstances might a human alternative be required instead of an automated system?", "c34af4dc-1fae-49b1-8b07-cd4075e75e4c": "What are some of the sensitive domains where automated systems are used in the criminal justice system?", "6b6fdf49-d5b7-49fc-94b0-bff6e35e11cb": "Why is it important to have extensive human oversight in the use of automated systems in sensitive domains?", "aab12fbe-97ff-47a9-8f77-20ccb98d81b3": "What groups of individuals are specifically mentioned as being adversely affected by persistent poverty or inequality in the context provided?", "25759a5a-c795-43ef-82cf-fd3d185673ef": "What types of rights and opportunities are encompassed within the framework described in the context?", "71527165-7333-463a-946f-6e22855eef94": "What are the potential risks associated with confabulated content when using GAI in decision-making applications?", "48cd4170-c424-4fbc-990a-5467b1764538": "How might GAI outputs mislead users into trusting incorrect information?", "51bb4f4e-f47b-4c66-a397-5be5381ace48": "What is the purpose of the technical companion mentioned in the context?", "dab7cbce-efbe-4fd7-9301-84e5ae53f67f": "How do the principles outlined in the framework assist in the technological design process?", "56dc2516-0002-4d0a-adbf-1199188cb74a": "What guidelines should be followed when requesting consent from users regarding their data and metadata?", "8a84ca85-944b-4be4-b97e-cc7630ba9be4": "How should consent requests be structured to ensure users understand the scope and purpose of their consent?", "44dde9b8-4b95-4813-9ca3-15654cc7d921": "What was the purpose of the panel discussions co-hosted by OSTP and various organizations regarding the AI Bill of Rights?", "375fbfa5-008e-43e1-80c3-481dd0e9730d": "Which organizations collaborated with OSTP to inform the Blueprint for an AI Bill of Rights?", "d54947c9-8307-4c7d-ba6f-5533ffe21af9": "What is the purpose of the AI Risk Management Framework developed by the National Institute of Standards and Technology?", "95ee3e7d-a8d8-4a60-9e78-2d68878b8cfe": "When was the US Department of Energy's Artificial Intelligence Advancement Council established?", "729f5870-b11a-4365-8989-f515002fa829": "What are the potential risks associated with third-party GAI integrations mentioned in the context?", "75edceaf-9502-4f92-b0cf-a841b040182a": "How can organizations manage the risks related to the collection and use of third-party data for model inputs?", "5a34551c-8bad-48ae-a2c9-60e9eeaf942a": "What is the purpose of maintaining a document retention policy for test, evaluation, validation, and verification (TEVV) in relation to GAI?", "46741257-8814-46ae-a83c-3c3aa11d6087": "What mechanisms are suggested to inventory AI systems according to organizational risk priorities?", "a1b26141-c8df-47fc-99aa-c832311b22b3": "What are the intended recipients of the reports generated by the automated system according to the context?", "d3a8425c-09ef-4ee5-acc0-e985099208c9": "Why might certain information not be made public, as mentioned in the context?", "a2141cd6-31ea-4d56-a6eb-7825c04cfc4e": "What measures should be taken to ensure that data pertaining to youth is used ethically and with necessary protections?", "93fcf7b5-1a8f-4304-aae5-e513ff0655a3": "Why is it important to have heightened oversight for surveillance technologies, particularly in sensitive domains involving youth?", "ac9f4683-9abb-4b67-9cce-3d58efcbcfee": "What are some reasons people may prefer not to use an automated system according to the context provided?", "ddec3f83-c0e0-46e2-bca5-7cbb6bdd2c03": "What challenges do individuals face when seeking alternatives to automated systems as mentioned in the context?", "5d8c8ee8-4d26-4682-8cd6-4b0bd16fd613": "What issues arise when automated systems are used to evaluate employee performance and make termination decisions?", "dc6fb1a8-dbb5-4969-92a3-5ea50240c921": "How did a software error impact a patient's access to pain medication in a hospital setting?", "3eee8e7e-25c9-4a80-ae3b-5a8a67530786": "How do government agencies enhance and expand surveillance capabilities through technology?", "91d004f8-6290-48ec-9aa1-ff0bf7b503e4": "What challenges do members of the American public face regarding access to their personal data?", "fe260adb-ea2f-4fa8-8a78-049064b00beb": "What factors can affect the accuracy of automated signature matching systems in the voting process?", "3b7fd31d-42dc-4985-ad02-ff6ac833700b": "Why is a human curing process important in the context of mail-in voting?", "0ff1c6fc-f6eb-4e07-a76c-594238041b36": "What are some risks to privacy associated with GAI systems as mentioned in the context?", "57fb06a3-2cd5-426d-9ed2-be57428f4a67": "How does the lack of disclosure regarding data sources impact user awareness of personally identifiable information (PII) in GAI training?", "c7637342-0d73-4674-a703-4a61d31f2ee3": "How can organizations maximize the utility of provenance data in their risk management efforts?", "499cddfa-6249-47f0-aaf9-d763514d9722": "What role does direct input from end users play in enhancing content provenance compared to automated error collection systems?", "deffafd4-36f9-4eba-a8f8-ebf586a30c78": "What are some challenges associated with estimating GAI risks according to the provided context?", "b048baf2-ebab-4425-919a-d42bb1bb37ce": "Why are speculative risks related to advanced GAI systems not considered in the document?", "63ee738d-c834-4c5e-87ed-d280e251b648": "What are the key components of the digital content transparency solutions mentioned in the context?", "bf0d281d-e84b-4c04-9184-538c7ea2d34a": "How can robust version control systems contribute to the AI lifecycle according to the provided context?", "bbb2db35-bf23-4c84-8ea8-6ce14e46d106": "What factors determine the level of human consideration and fallback required for automated systems?", "43c380be-38e1-4753-a6b5-a68781d21dc2": "Why is it important for automated systems with high-stakes decision-making to have greater oversight of human consideration mechanisms?", "a011d33b-0471-4e52-a9a4-30b4894d93de": "What are the current limitations in reporting and documenting AI incidents?", "e5aa8331-5997-4145-914b-a7a58e22746a": "How do publicly available databases decide which AI incidents to track?", "c801d50a-a565-4e69-ae74-15d1bd25588b": "What is the focus of the model cards framework discussed in the context?", "c82a449a-568f-4f6f-97c2-78e7e0fa2330": "Who are the authors of the paper \"Model Cards for Model Reporting\"?", "b4f0e682-6ecf-483b-940f-6def580edd55": "What are the suggested actions for managing AI risks that do not surpass organizational risk tolerance?", "35bc819b-20d6-4ff4-9c2d-3561208179f2": "How should organizations respond to GAI risks that exceed their risk tolerance according to the context provided?", "22a9627a-0fb0-4972-a1de-0365e2800996": "What challenges do parents face when a child welfare investigation is initiated based on an algorithm without their knowledge?", "039a799e-593e-4420-a405-2da7572ed195": "How does the lack of notice regarding data collection impact a parent's ability to contest a child maltreatment risk assessment decision?", "1a739202-16cd-4c20-b8e5-6659c3d7d4e4": "What are the potential harms associated with AI incidents as defined in the context?", "3dd92ae7-c64d-4eff-acfb-616010afebc7": "How can AI incidents manifest in terms of their impact on individuals or groups?", "e95c1ea3-f55f-4a8f-ba5a-465adbaa805c": "What are the different categories of ecosystem or societal risks mentioned in the context?", "08b616b7-20d9-478c-9d8d-bd11f367d2ed": "How are some risks described in the context as being cross-cutting between the categories?", "dabb41eb-37f4-4edf-a608-d47b49205b3f": "What is the purpose of the expectations for automated systems as mentioned in the context?", "c6ee5c15-f5b5-4035-b4f9-719c36a78245": "Why is independent evaluation important for automated systems, particularly in the public sector?", "8681e320-7137-4114-a24b-24a3405fb2b9": "What will future revisions of the profile include regarding AI RMF subcategories and risks?", "daf2e8f0-f0e5-4f8b-b563-d0a8cebe9629": "Where will the glossary of terms related to GAI risk management be hosted?", "ad0eb872-f5f2-4b86-bda3-962ee89af7c8": "What is the definition of algorithmic discrimination as outlined in the context?", "bfdda532-1d7b-4781-afbe-2a0c43f77220": "Which classifications are protected by law against algorithmic discrimination?", "11ce0ccd-3b5a-4308-be37-812b238b4449": "What are the expectations for automated systems regarding the handling of sensitive data?", "077f5d7c-a8f6-4d3b-a147-9f5ece276b08": "Why might consent for sensitive data need to be acquired from a guardian and/or child?", "5e81d0f4-c40a-4f11-957b-577221cf120c": "What types of data are considered sensitive according to the context provided?", "3be256d3-d533-47db-9dd4-bdafe59b5f88": "How can sensitive data potentially expose individuals to meaningful risks?", "3a215422-10a5-499a-9988-694c5db5035c": "What is defined as an \"automated system\" in the provided context?", "9a69c417-928e-43a9-abf5-f217a1e49d44": "How does the context differentiate between automated systems and passive computing infrastructure?", "6d42bf4f-1edc-4db9-bf6c-93e1b42ecf2a": "What are some considerations that may affect the appropriateness of notice in law enforcement contexts?", "20fdf738-8c29-462c-b1d1-7bc3c0cb5d9f": "How does Executive Order 13960 relate to the use of automated systems in federal departments and agencies?", "f1c13d85-e215-4cc0-b93a-e7dcd84b7105": "What are the potential consequences of overly homogenized outputs in foundation models?", "c7e59ed4-55af-4f6c-9fc2-8177f0fc1ad8": "How can model collapse affect the robustness of a new model's outputs?", "9560f9e5-6670-45a3-8da6-a31f463dc58d": "What are the five principles identified by the White House Office of Science and Technology Policy to guide the design and use of automated systems?", "9690ca23-bac5-4319-8a85-74f2dea67e9b": "How does the Blueprint for an AI Bill of Rights aim to protect the American public in the context of artificial intelligence?", "ab19af0e-2a67-42f0-b1d0-c71eec70f050": "What processes should be established for post-deployment monitoring of GAI systems to address potential risks?", "d4f3a8ae-5be3-4efb-aa54-00472e0a33e9": "How can sentiment analysis be utilized to assess user sentiment towards GAI content performance?", "aa9f4bfa-b630-4c6d-a6dd-f3e56e510669": "What should be regularly reviewed to ensure the safety of a GAI system operating in novel circumstances?", "9560f275-f052-410c-92bd-1a94236ce6ad": "Who are the designated AI Actor Tasks mentioned in the context?", "97caf6fb-54d6-43ec-a509-ba1363f9d698": "What are the key aspects of information security for GAI models and systems?", "488becf7-54a5-4153-b02b-324087267b4e": "Why is it important to maintain the integrity and confidentiality of GAI code, training data, and model weights?", "793ff485-6ea7-4ad2-9528-65c0bf041fec": "What are the core principles for managing information about individuals that have been incorporated into data privacy laws and policies globally?", "b4d1c2ec-d999-4023-8c63-76fe6f00f9a2": "How does the Blueprint for an AI Bill of Rights relate to the Fair Information Practice Principles (FIPPs)?", "cac4e2fa-fa97-43d1-b2e5-12d433f321a5": "What are the key tasks involved in AI Actor management according to the provided context?", "d1b34049-f238-4a7e-bb0c-0cfb548abbfc": "How are AI risks and benefits from third-party resources monitored and controlled?", "d3335d75-2d5a-40aa-b0ed-bbf27a6c747a": "What are the privacy implications of using biometric identification technologies in New York schools?", "7bf1e819-3fde-4580-a5ea-92a704138f1c": "What federal law requires employers to report costs associated with surveilling employees during a labor dispute?", "30269bc0-2c64-455d-8593-d8f893fc4df3": "What are the potential risks associated with the non-transparent integration of upstream third-party components in the context of GAI?", "50c62687-0afa-44b9-a1fd-b40757549647": "How might GAI facilitate access to CBRN weapons or related knowledge for malicious actors?", "6e0d80ee-842a-4cd0-b712-47d48481979b": "What is the main focus of the paper by Boyarskaya et al (2020) regarding AI system development and deployment?", "2183dd8b-6bd7-4b68-88cc-563ee832f3cc": "According to the article by Burgess (2024), what is identified as a significant security flaw in generative AI?", "590cdd7b-1634-4d19-9fb4-a2ae6e11a307": "What steps should be taken to assess the intellectual property and privacy risks associated with the use of training data?", "c324526d-e094-4306-8cb2-6e2312c43356": "How can the likelihood and magnitude of impacts from AI systems be evaluated based on past uses and external feedback?", "66ac5796-d5d3-4303-8c9b-cfafddbd8810": "What are the ethical and social risks associated with language models as discussed by Weidinger et al (2021)?", "80e1ca04-256f-4e3e-bcba-212144f989bf": "How does the research by West (2023) highlight the risks that AI poses specifically to women?", "811a80de-b8b0-40c9-af47-a1446c68dc4a": "What methods did the White House Office of Science and Technology Policy (OSTP) use to gather input from the public on algorithmic and data-driven harms?", "824170fb-7ff6-4531-a319-d9a29b1aaa63": "Who were the various stakeholders involved in the yearlong process led by the OSTP to address algorithmic and data-driven issues?", "8a581d4a-0f07-45e0-a1a0-367b3d3078c6": "What is the purpose of performing and making public disparity testing results and mitigation information?", "de9928e3-fac6-48aa-90c7-c16c4b74c0b7": "Why is it important to confirm protections related to disparity testing?", "6053208c-e7b8-4395-84d8-12dcf21adab7": "What are the responsibilities of AI Actors in evaluating GAI system performance and addressing reported issues?", "ad777204-4ac2-42d9-9029-a4be3bf49789": "How are measurable activities for continual improvements integrated into AI system updates according to the context provided?", "b0285db8-5763-4327-bdbf-be133814aaae": "What are the risks associated with directly using demographic information in automated system design?", "a2ca3e93-793a-4a0c-8b02-63e8a34c5b5c": "How can proxies contribute to algorithmic discrimination in decision-making processes?", "561c0cf8-a3dd-44b4-9679-984f3790d3fe": "How do sociodemographic variables influence the algorithm's output in relation to a patient's race or ethnicity?", "ecf01b7f-1eb4-48fe-b320-81f327c062cf": "What are the potential consequences of using algorithms that adjust for race or ethnicity in healthcare?", "42a4f4b0-bfba-4cfe-a6d8-f1f95bfd2fec": "What are the potential impacts of surveillance technologies on individual rights and opportunities?", "187c8383-1e8f-40a5-aa00-07b8e948dc50": "Why is it important for designers and developers of automated systems to provide accessible documentation?", "6c767f4a-5834-4427-ac07-51a1ced67771": "What are the key components involved in the Human-AI Configuration as it relates to GAI functions?", "baabc0fc-a123-496c-877e-d6201aee81aa": "How are roles and responsibilities for managing AI risks communicated within an organization according to GOVERN 21?", "1b80d2eb-cfd5-4442-9ff7-fa905bd419fc": "What types of harmful content should be analyzed during the due diligence process for GAI output?", "1e5a3799-ba5f-4881-b4a8-ac4b65bc26ca": "How does the due diligence process address potential misinformation related to CBRN information or capabilities?", "b06d7587-17d8-4670-9a5a-7006fd02141c": "What measures should be taken to ensure individuals subject to monitoring are informed about the use of their data?", "4e30e6f1-492f-4886-9096-52ea609d95bf": "How can surveillance systems be designed to protect civil liberties and democratic rights during their implementation?", "40dcad7b-a44c-4728-8df6-bde4416a2552": "What proactive measures should designers and developers take to protect individuals from algorithmic discrimination?", "578330a9-8c5c-4413-8ea2-7721e3168a29": "Why is it important to conduct equity assessments during the design of automated systems?", "d4eb2c7e-08ce-4de4-8187-2bf8fc097531": "What is the problem referred to as data memorization in the context of GAI models?", "a0722c5f-319b-4b10-8ae2-70b0f1f2df06": "How can GAI models potentially infer sensitive information that was not included in their training data?", "9007b3d0-d32e-4431-8a1f-ccddacc956db": "What processes should be implemented for analyzing generated content performance and trustworthiness characteristics?", "e94aa728-daac-4c90-81bc-5cd241c0fd6c": "How can real-time monitoring help identify deviations from desired content standards?", "aa1a0081-f7b3-425d-93c1-98a3d2aeccb1": "What are the limitations of current pre-deployment testing approaches for GAI applications as mentioned in the context?", "ce02657d-7c17-479a-b6a0-ef9138efa4a2": "How do organizations utilize pre-deployment testing practices to assess the performance and risks of GAI systems?", "94b9eef6-9fcd-44a9-98b8-5d6062b534fc": "What are the different forms in which notices and explanations should be made available to meet accessibility expectations for the American public?", "2854f950-63c1-40b4-91b9-63e32f3977ac": "How should explanations be tailored to serve different purposes, such as informational use or allowing for recourse?", "86c090f2-69f6-4f9f-aa4e-666a17e09214": "What tools are suggested for analyzing content provenance and detecting data anomalies?", "ed4c49fd-e5f4-409f-b8e3-7cf394d8bd91": "How can evaluation metrics be disaggregated to identify discrepancies in content provenance mechanisms across diverse populations?", "91ce403f-b4e5-426c-9d7f-d69fa16299e1": "What are the key considerations for automated systems used in sensitive domains according to the context?", "1757c62b-c5e3-43c5-b651-a2b3fb74cdb8": "Why is it important to provide meaningful access for oversight in automated systems?", "4aad5967-68a7-43a0-b7e3-7b6a3ae38580": "What is the primary goal of the Defense Advanced Research Projects Agency's program on Explainable Artificial Intelligence?", "e612ace4-4672-4f30-9638-eef693523924": "How does the National Science Foundation's program on Fairness in Artificial Intelligence relate to explainable AI?", "3b7c9217-1430-4132-a186-334a27f5f96a": "What types of harmful content should be assessed in system training data according to the context provided?", "4b09d600-32f0-48d4-bdb1-79fca60a61c1": "When should safety features of fine-tuned models be re-evaluated based on the context?", "ba090ba4-1d4c-4e65-a49f-1038b01fb6cc": "What role do representative AI Actors play in the lifecycle mentioned in the context?", "0ac31c0a-ef66-475f-a438-b1d0d6154024": "What is the significance of Figure 3 in relation to the AI RMF?", "fa95ca75-ce77-499f-ba7f-6087b4e030a3": "What are some practical technical and sociotechnical approaches mentioned for protecting rights, opportunities, and access in the context of an AI Bill of Rights?", "facc56f2-a2f2-4199-96f4-27e94d1e0d00": "How can the guiding principles of the AI Bill of Rights be translated into real-life laws, policies, and practices?", "d9a45b03-0811-4081-ad54-1bb6b7906485": "What are the potential risks associated with \"jailbreaking\" GAI systems in terms of user interactions?", "e88c2c19-1b01-4b2c-922a-be5b0a8ca8bd": "How might negative responses from chatbots impact users who are experiencing distress?", "8f28bf2c-7135-41dd-b761-3666add3ac42": "What measures should entities take to ensure the accuracy and completeness of their data?", "08f0ea96-3dd8-428c-bd34-9baace4bc21e": "How should access to sensitive data be managed according to the provided context?", "a454087d-3254-4a33-a88a-940dfa0aacd4": "What are some ways the TSA is making flying easier for transgender people according to the ACLU article?", "b0cd94ce-1a3c-417c-af7a-528faef54158": "Where can one find information about the TSA's policies for transgender, non-binary, and gender nonconforming passengers?", "8915492a-26c0-443b-a065-f78972585f21": "What measures can be taken to protect identifiable information (PII) in AI applications?", "b0c1731c-1692-443e-813c-953917dcdac6": "How can techniques like anonymization and differential privacy help minimize risks in AI-generated content?", "fe507a13-f73e-4720-b7cc-e05e92733a03": "What is the primary focus of the framework mentioned in the context regarding automated system development and use?", "2524b46f-dc41-42ff-ac6b-f8aadff9677c": "Does the framework take a position on legislative and regulatory proposals at various government levels?", "c115e84e-28c8-4306-b07f-e4ecffc1988b": "How can corresponding applications enhance awareness of performance changes in GAI systems?", "c5d664cc-31c6-482b-90e2-1b680ce2a94a": "What role does user feedback play in assessing the efficacy and vulnerabilities of GAI systems?", "6e69799f-4b6f-49a0-859f-cc8f3822f526": "What are some examples of immediate risks associated with the misuse of AI systems?", "75cdc265-38c9-4767-8b5e-2af493d44cbd": "How do the characteristics of a GAI model influence the presence and type of risks it may pose?", "0850484b-d693-490d-849e-340c674d47d2": "What is the purpose of the information provided in the context?", "b1dd2d9d-2bc4-4506-a68f-6dd03b73a91f": "Does the context suggest any endorsement or recommendation by a US Government agency?", "03802873-d7f3-4aba-83d8-bb34299acc72": "What are some examples of how automated systems impact people's lives according to the context?", "07e90b29-c913-4a0d-995c-236ac6dde596": "Why is it important for individuals to understand the role of automated systems in decision-making processes?", "fb0a3530-8e29-4053-aaed-7e1c805d19f7": "What foundational American principles has President Biden affirmed as a cornerstone of his Administration?", "29d60fff-cdb9-481e-8e19-7a9eb158a871": "What actions did President Biden take on his first day in office to address inequity and advance civil rights?", "7b373969-0869-4753-8f49-1130e698bf22": "What are the built-in protections that should be in place to safeguard individuals from abusive data practices?", "3975d869-8ee3-40d2-b50c-b30b992a52a5": "How should designers and developers ensure that data collection aligns with reasonable expectations?", "13f6dcfb-b287-4388-a01b-b7b324e78064": "What are the main themes discussed in Duhigg's article about how companies learn consumer secrets?", "89e78744-1a50-4fed-a43e-a01440dff205": "How do the findings in Elsayed et al's research relate to the influence of altered images on human perception?", "f31c0308-6237-4be1-b692-1e555350d6cb": "What are some reasons why certain GAI risks cannot be measured quantitatively?", "e5121b5d-ea6c-489a-837f-d6fd264039e9": "Who are the internal experts mentioned in MEASURE 13, and what role do they play in the assessment of GAI risks?", "e48a859c-4473-448d-9bfa-6dac9953f4c1": "What are the unique risks associated with the development and use of GAI that organizations need to identify and manage?", "79092675-9644-4531-9cdd-ccc849f67b9f": "How are the identified risks related to Trustworthy AI Characteristics in the AI RMF?", "f996eda2-f980-4cd5-93bf-ec6886cf731e": "What are some potential consequences of erroneous outputs from AI systems on decision-making?", "80f5ff42-b5c9-41d6-8ebd-50c03b146179": "How can human-AI configuration lead to inappropriate anthropomorphizing of GAI systems?", "93b7ddaa-c5e3-45ba-8b4a-712a31e5b80e": "What procedures are in place for the review and maintenance of policies regarding newly encountered uses of the GAI system?", "6c581332-ed07-4eb8-beb4-5ed2e664a391": "How are response and recovery plans verified to ensure they include necessary details for communication with downstream GAI system Actors?", "fc0d8a9d-b98c-4a11-949b-6b61a2353e3c": "What challenges arise in establishing a baseline scenario when assessing harm caused by disparities between groups in AI behaviors?", "1b3de213-82b6-4dc5-83c8-517ae262cdcb": "How does the presence of an AI system influence the determination of harm in situations where biased behavior is observed?", "bf2784d6-b500-4547-b3e3-686d53755a9d": "What are the expectations for automated systems in relation to data privacy and surveillance?", "34605653-cd3b-4622-b348-3d09da5c9e7e": "Why is heightened oversight important for surveillance or monitoring systems?", "4c5a9606-3e7b-44a3-a59d-fec04295bb4c": "What should be included in the notice provided to individuals impacted by an automated system regarding their right to opt-out?", "8c46a334-7984-4ed5-8544-14318036aeef": "How can the effectiveness of the notice and instructions for opting out be evaluated?", "a6599822-5c70-431c-9250-38a1c38ba28d": "What are some examples of settings where future sector-specific guidance for automated systems may be necessary?", "c8b0c22d-9f31-4b2f-a03c-954f10d56f28": "How does the Blueprint for an AI Bill of Rights address the balance between law enforcement information protection and other principles?", "f32ff14f-96df-4dd0-bf0f-640971290bb5": "What initiative has the Department of Justice launched to combat discrimination in mortgage lending?", "33020145-d44d-4f52-89f7-b9b9a9de1740": "How is the federal government addressing the issue of redlining in communities of color?", "f4f0b003-2c7d-40d3-93f4-a0957245e5fd": "What processes are suggested to mitigate risks associated with unexplainable GAI systems?", "98af905a-7720-4910-9767-a6c4d31e3203": "How should the adaptation of pre-trained models for specific generative tasks be documented?", "ef7bf3fe-fe7b-412e-b931-39d1ddde8388": "What steps should be taken to monitor and document instances where human operators override the GAI's decisions?", "db59b972-a01b-4b08-a0c5-7800d7bc0e0d": "How can the results of structured public feedback exercises be verified and incorporated into the decision-making process for AI deployment?", "deaceffa-0db6-40d9-a05a-176847e3d306": "What roles do data providers and system funders play in this category?", "d1e7da0c-6e92-4f2b-9cb5-82a18784d75f": "How are products related to the context of data providers and system funders?", "067fb92d-368b-4156-8fd5-b455613a7df7": "What practical ways were proposed to reduce bias in healthcare treatment for patients with similar illnesses?", "dca53166-da24-4db8-adf1-e79d599d7f0f": "What is the purpose of the Algorithmic Bias Safeguards for the Workforce initiative?", "f3b12aa2-63c4-49c5-8ed8-6c85a2f1a878": "What are the expectations for automated systems intended to serve as a blueprint for?", "c9a7c111-2b4d-4b59-b09a-5c847eda9fab": "Why should derived data be viewed as potentially high-risk inputs in automated systems?", "4cacd155-b23f-45e9-b301-bf2f1c4afdb6": "What factors should be considered when determining the applicability of suggested actions to AI actors?", "141e65af-cd35-4c7a-9981-379efd1b6bc7": "How are Action IDs structured in relation to AI RMF functions and subcategories?", "34d918a9-e2b4-4b4d-bbe8-1538eb777a4b": "What are the key expectations for automated systems as outlined in the context?", "68485945-37a6-4382-b75b-981f07aa8221": "Why is it important for automated systems to provide clear and understandable explanations of their decisions?", "92ed4f14-26b4-429e-9c21-70da64912501": "What are the main themes discussed in Chandra et al (2023) regarding Chinese influence operations?", "dee0b60c-0d85-4096-9415-a723f7ca149c": "How do Ciriello et al (2024) address the ethical tensions associated with human-AI companionship in their inquiry into Replika?", "14a52970-4e49-4abb-b4a6-cd21eb2b076e": "What methods are suggested for seeking feedback from affected communities regarding GAI system outputs?", "4a1b4636-ca48-4e0d-b156-9382f7be133d": "How can the quality and integrity of data used in training GAI systems be evaluated?", "ed237ad9-46b0-4d64-b316-47775c598a0d": "What are some of the significant negative impacts associated with the design, development, and deployment of GAI systems?", "90684a4e-5d8b-4c04-94b8-bcdeb72ba8d9": "How can a plan be devised to halt the development or deployment of a GAI system that poses unacceptable negative risks?", "45092704-1ff1-4b1f-8bd1-480637c49e0a": "What methodologies are suggested for evaluating potential biases and stereotypes in AI-generated content?", "4b8c2d33-0d0f-4488-b446-5d74bf2939c1": "How might AI-generated content impact different social, economic, and cultural groups according to the context provided?", "e1bc5dec-0525-46aa-bd92-44f71e76368c": "What are some implications of using third-party GAI models and systems for an organization?", "ec86734e-003b-4bb0-ab2d-a15c874ca711": "How do existing governance protocols need to be adapted for GAI contexts?", "66e4770a-e6eb-4e4a-b7f2-314a3bbc615b": "What is the title of the article by Mick Dumke and Frank Main published in the Chicago Sun Times on May 18, 2017?", "82ea0853-c631-472b-b865-2ed77fcad5c7": "When did the Biometric Information Privacy Act become effective in Illinois?", "9ce45542-ab27-4c78-979b-981d36ac3c21": "What are the short, mid, and long-term impacts of AI in cybersecurity as discussed by De Angelo (2024)?", "d6075fee-9472-46fb-a581-65aadb2544b7": "How do chatbots relate to mental health and the safety of generative AI according to De Freitas et al (2023)?", "1bbd5dc5-d41e-406e-bb40-1eb5b9d754c7": "What are some of the specific contexts in which laws guiding the collection and use of personal data exist in the United States?", "ad6f8c33-a11d-430f-ac07-b0c3020ef7e0": "Why is there a need for additional protections regarding personal data in an increasingly automated society?", "32095d18-23c9-4baa-8c49-35dbcee5ebaa": "What does \"equity\" mean in the context of treatment for individuals from underserved communities?", "9c91aaef-7c78-42ba-9b71-8a2a3e833500": "Which groups are specifically mentioned as having been denied fair and just treatment in the context provided?", "717c4598-0a41-40e2-a0ca-2a05494630f9": "What is the purpose of the AI Risk Management Framework (AI RMF 10) for Generative AI?", "112a0ed5-8c67-419d-b081-eacc8aee5282": "How does the AI RMF aim to improve organizations' ability to incorporate trustworthiness considerations?", "21912c63-55ee-4d52-9e33-5b31407c29d6": "What measures should be taken before using data collected for specific goals in a different context?", "7d862deb-a668-452f-8ce5-0968068b2b59": "Why is it important to establish clear timelines for data retention?", "0718475f-5cee-4829-a6cf-32e5581ecf46": "What are the recommended practices for obtaining user consent for data collection according to the context provided?", "afab3f40-d769-42b3-9a02-48ddcad92d5b": "How should systems be designed to ensure user choice is clear and not obfuscated?", "e88fea9e-1c99-4895-b657-7f302c3b8149": "What is the purpose of Executive Order 13960 regarding the use of artificial intelligence in the federal government?", "e139d38f-e74b-4aca-9cf7-ca16eb63d1a6": "How does the Blueprint for an AI Bill of Rights relate to the principles outlined in Executive Order 13985?", "a4ad5f05-6b2d-4e52-b4c7-07f3ceeb3023": "What are the key tasks involved in AI deployment according to the context?", "4aea276a-b3cb-467d-a013-3c58a562abf1": "Who are the stakeholders mentioned in the context that are involved in AI impact assessment?", "afa6fb9f-22fe-4c72-aeec-eb5cd385e6ed": "What types of rights and opportunities should be protected in relation to automated systems according to the framework?", "eba65977-58b8-48af-a443-ab04c3c26286": "How does the framework address the potential impact of automated systems on civil rights and liberties?", "d10f4697-498d-40b0-b642-bfe0fc7b55d8": "What is the purpose of retaining the option to dial zero in automated call centers?", "1fe15653-a6d0-450b-92f7-d3ef49b9da47": "How do human alternatives serve as a check on automated systems in identity controls?", "95be6474-41d5-4597-aba8-1665468ca8f1": "What are the key expectations that automated systems should meet regarding the collection and use of personal data?", "ea563177-8920-4b03-ac51-337ff4a8c58a": "How should privacy risks be assessed during the development life cycle of automated systems?", "0d4cfd2b-0441-4e25-9571-8bf0d5c3f95b": "What is the significance of the number 43 in the context of the research?", "d49d2f48-ab82-4170-ad36-38b1591b962b": "How does the research relate to the broader field it is part of?", "5d54af50-08e9-494e-8273-e322e9aefe1a": "What should be done if equity standards are no longer met and cannot be mitigated?", "e7f239d2-569e-4c9f-acd7-cbfd1d5d2708": "How do prior mechanisms contribute to better adherence to equity standards?", "24602a76-696e-4371-9f0a-14dd43246645": "What is the focus of the document titled \"Property Appraisal and Valuation Equity\" published in March 2022?", "a63b17e9-59b1-48e7-aaa5-686d8db0ab98": "What are the main topics addressed in the EEOC guidance regarding the use of software and algorithms in assessing job applicants and employees?", "aad07b57-5721-4065-95ed-338dab8c31f5": "What are the key expectations for automated systems regarding data privacy?", "4e5d0aa8-363c-41c9-b93f-86c5889c47ed": "Why are traditional terms of service considered inadequate for protecting privacy?", "27e3f506-4eca-4347-b257-fa78ac1c3aef": "What role does provenance data tracking play in distinguishing between human-generated and AI-generated content?", "2ed6da6e-a2af-409f-94a3-cb150b87111c": "How can digital transparency mechanisms improve public trust in AI systems?", "b537a00a-178e-458f-9148-20b375ee1136": "What should the documentation of the system include to ensure it is understandable to the public?", "a9bfb2fe-e919-4b46-a067-413d44934161": "How should the notices regarding the use of automated systems be presented to users?", "c9a1472a-0d25-4101-98cf-be09ece44c7b": "What role did the international community play in shaping the Blueprint for an AI Bill of Rights?", "bd5dab36-b7ec-4ee6-b733-f5e0721fe98f": "What are the core messages regarding the potential of AI technologies as discussed in the context?", "4d56e4e0-d4ce-4c81-beda-0b478831a70e": "What methods are suggested for quantifying harms related to generated content exhibiting harmful bias?", "042e053c-e52f-4ae6-989a-0ccb72304d7b": "Which general fairness metrics are recommended for evaluating ML pipelines or business processes that utilize GAI?", "9da59a71-fc38-4d44-b8bb-d63099b500d5": "What are the main techniques used in provenance data tracking for GAI systems?", "9cf6599c-beaf-4d73-89d0-cacb42e77ddd": "How does provenance data tracking assist AI Actors throughout the lifecycle of digital content?", "aafc2864-b147-43c3-8d9a-3f6583cb9761": "What are some examples of structured public feedback methods mentioned in the context?", "b7972ac6-b9df-4bb7-a7c2-d4b2331374b7": "How might gaps between benchmarks and real-world use of GAI systems be affected by prompt sensitivity?", "0d8a8f21-9d23-4ef0-aac0-50155e49ac55": "What steps should be taken to adapt processes based on findings from incidents involving inappropriate or harmful content?", "b30de182-206f-4438-b8d4-647920e77954": "How can visualizations be utilized to help non-technical stakeholders understand the functionality of GAI systems?", "441f2a5a-1b7b-4e3a-af91-452b3061baea": "What are the legal and regulatory requirements for reporting GAI incidents mentioned in the context?", "6d295c91-8ef2-4a60-a61e-0006be0cee6c": "Which organizations' reporting requirements are referenced in relation to HIPAA and autonomous vehicle crashes?", "c27d36f0-9645-4ce7-aea7-ea84649b9112": "What are some of the challenges posed to democracy by technology and automated systems, as mentioned in the foreword?", "996fe255-ce39-43f7-ad44-288e42c72134": "How have algorithms in hiring and credit decisions been shown to impact existing inequities, according to the context?", "8b869c2a-7b4e-47e9-bfce-e894bfbe9548": "What measures should entities take to ensure independent evaluation of their data policies?", "11a8f5d6-da42-4822-8f42-9e0bda171a2e": "How should entities respond to public inquiries about the data collected or stored about individuals?", "bc5e6261-06eb-4aae-a32a-80c17084685b": "What impact does the use of automated systems have on individuals' rights and access to services like Medicaid-funded home health-care assistance?", "f716d2f7-f08a-43c7-8456-9fbd3fa6eceb": "How can transparency in the use of algorithms improve public trust in the decision-making processes related to eligibility for assistance programs?", "fbf5fa11-a725-4416-a4aa-3d8a253cb99e": "What type of reporting should you have access to in order to confirm that your data decisions have been respected?", "8d02f47d-c2e2-4f14-984f-c6fe3f3a572d": "How can surveillance technologies potentially impact your rights, opportunities, or access?", "e571b4aa-f274-42de-934d-18cab9ba459d": "What methods are suggested for assessing the impact of AI-generated content according to the provided context?", "3ec4b7de-4534-4ea7-a7f1-95446ac1966a": "How can structured feedback mechanisms contribute to the detection of shifts in quality or alignment with community values in AI-generated content?", "9462862a-524f-4ec4-a466-ac3a9d853d93": "What factors should be reviewed during the research and development or acquisition of technology to identify potential discrimination?", "445da68b-62fe-4788-ae6f-de7b95f42bed": "Which groups are emphasized as underserved communities in the context of assessing equity related to technology introduction?", "1696d067-68b4-492e-8c0d-5f8e97cf688e": "What are the key risks associated with unreliable downstream decision-making in GAI systems as outlined in the context?", "850b2aa0-e04c-4b61-a539-60fd96cc2417": "How should GAI system architecture be designed to monitor outputs and recover from security anomalies?", "512af064-2574-45bc-9988-cdbf2adf7b54": "What are the main purposes of AI RMF profiles in managing AI risks for organizations?", "4dd0e7f5-47c5-4f4d-89d6-35513d7934ae": "How does the cross-sectoral profile of GAI assist in addressing risks across different use cases or sectors?", "061e92cb-0315-4ee4-abbe-471ea8de0924": "What are some of the problems that the principle of data privacy seeks to address and protect against?", "f3e4d990-69e1-42e7-b0f5-87f408d48a4d": "How does data privacy serve as a foundational principle for achieving other principles in the framework?", "f613c86b-af8f-4ce4-8f10-10a323a8ac38": "What are the emerging areas of study related to the deception of humans by LLMs?", "70c7008b-62de-41cd-99eb-f7c1379b1dcb": "What characteristics define trustworthy AI in the context of managing harmful bias and ensuring safety?", "e7c544ba-d0e5-41cf-9973-9d3f68320936": "What are the main findings of the study by Wang, X et al (2023) regarding energy and carbon considerations in fine-tuning BERT?", "7a444949-3784-4e86-9d60-76147fe850c6": "How does the dataset \"Do-Not-Answer\" contribute to evaluating safeguards in large language models (LLMs) according to Wang, Y et al (2023)?", "ad2f3ce7-ff43-4b6d-a9b7-8be870356a20": "What is the purpose of the 15 Winogender Schemas in natural language processing?", "b7297088-2948-4d58-84a3-f21525a45f44": "How do the 15 Winogender Schemas differ from each other?", "fc5fa57a-1d5e-4661-b6c7-7e56d000634e": "What responsibilities do individuals or organizations have regarding the notification of significant changes in automated systems?", "59ed8c0a-6803-46b9-8f0d-ca91dcbb17c9": "How should automated systems ensure that the explanations of outcomes are meaningful and useful to the impacted individuals?", "21a864ea-e446-457a-9cbf-fa4ba9cf4012": "What measures should be taken to ensure that notices and explanations about the automated system are accessible to users with disabilities?", "7fbc1d52-7bd4-422d-9c2a-02ecaed5ae42": "How can user testing be utilized to assess the effectiveness of notices and explanations provided to those impacted by the technology?", "1de0b29f-a11c-42c5-8622-961425244709": "What measures are suggested to assess the proportion of synthetic to non-synthetic training data in AI model training?", "5317043f-ec08-4e3f-b5d8-bffd4fe64c06": "How should the environmental impact and sustainability of AI model training and management activities be documented according to the provided context?", "2524319a-7a71-43e7-919a-5d618e29ea68": "What are some of the principles proposed for the ethical use of AI and automated systems?", "af6ab579-e6c4-4914-af08-7a7bfc448bd8": "How are companies and researchers addressing the challenges posed by new and emerging technologies in relation to legislation?", "269fbe37-fd07-4bef-9f2d-bdcecd1e6d36": "What are some potential risks associated with the domain where previous assumptions about security and safety may no longer hold?", "957f1104-8811-4d46-b6af-8a90d50b43bc": "How can approaches be leveraged to detect the presence of PII or sensitive data in various forms of generated output?", "58d010d3-af16-4736-87f7-b83b56dd1419": "What are the suggested actions for evaluating fairness and bias in GAI systems as outlined in the context?", "8eb85195-2331-4f04-9b6e-e0efff2e577f": "How should benchmarks be applied to quantify systemic bias and what considerations should be documented according to the provided context?", "7fa271b1-90be-401b-916f-f9ef4bfa2e3e": "What are the main concerns discussed in Luccioni et al (2023) regarding the cost of AI deployment?", "63afa79c-57c0-414c-94cb-6ffee2062c44": "How does the research by Mouton et al (2024) address the operational risks associated with AI in the context of large-scale biological attacks?", "5bf35ff2-e9e4-40f3-9e97-715f06bb65e0": "What types of attacks are assessed during AI red-teaming according to the context provided?", "af60013e-38cc-490e-bc74-e7c5d439e5e0": "How does fine-tuning relate to safety and security controls in the context of information integrity?", "f32165a4-efa5-41a2-a65d-d5f0de917a84": "What are the potential risks associated with providing instructions and material that may elicit harmful model behaviors in AI red-teaming exercises?", "a014b4a4-51a3-451b-9cab-1f8094a7dee1": "How can AI red-teaming exercises benefit from the involvement of large groups of participants?", "6470b0a5-e3ff-4652-9764-1f95d0f0eb5c": "What are the key considerations for human involvement in automated systems used in sensitive domains?", "e00e8f7e-45ef-44a2-a703-643cea119224": "Why is it important to provide meaningful access for oversight in automated systems?", "df585d41-5806-40ae-9dc3-4410acacb9fa": "What procedures are in place for ongoing risk identification and management related to sensitive data?", "3a10b960-37d9-4e60-983f-051c431cb4c5": "How should reporting be formatted to ensure it is clear and machine-readable?", "cc7cc11f-447c-4918-a647-03573175e57e": "What types of automated systems are considered in scope for impacting individuals' or communities' rights and opportunities?", "a209d751-4453-4402-8607-79f03cf15a8d": "How are \"communities\" defined in the context of the provided framework?", "4ac3b948-6f86-4b0e-bf4a-848242469fe1": "What are some potential mental health harms associated with the use of surveillance technologies in schools and workplaces?", "b3049077-be8a-4ae2-92c5-c4bc89dc864f": "How can inaccurate and faulty data affect individuals' opportunities, such as qualifying for loans or employment?", "4a85ff19-57a9-4108-bc90-38eea2d02bdf": "What is the purpose of the framework mentioned in the context?", "d9b7f9c0-c092-4307-8359-35c1b683f921": "How does the Blueprint for an AI Bill of Rights relate to existing laws and policies?", "7aac8b81-d0a6-4216-bb56-2ca1c74e5200": "What is the purpose of the Blueprint for an AI Bill of Rights in relation to government and private sector practices?", "2277c8e3-aaeb-42ca-b9b0-7142b2db3920": "How does the Technical Companion aim to influence the development of technical standards and practices?", "4d9fb74a-61b0-42e0-bc93-178c3bb4ce18": "What criteria should automated systems meet to ensure their explanations are technically valid and meaningful?", "8b45e1b4-dd65-4558-9cd5-1be7076f0681": "Why is it important for reporting on automated systems to be made public, particularly regarding clarity and quality of explanations?", "1bf7ed90-e52f-48bb-a37b-471444f51082": "What are the key responsibilities of AI system operators in identifying GAI incidents across the AI lifecycle?", "0f4148d8-a445-4597-9018-10a433791429": "Why is documentation and review of third-party inputs and plugins important for AI Actors in the context of incident disclosure?", "d9b99410-dddd-47be-9e3a-b9fcfdb174e0": "What are the potential consequences of disinformation and misinformation facilitated by generative AI on public trust?", "8e9cbd49-1894-4fc2-af2d-c105c124faf7": "How can generative AI models contribute to the creation of deepfakes and synthetic audiovisual content?", "5f39174f-404c-421d-8b07-822e7dfd896a": "What procedures should be established for escalating GAI system incidents to the organizational risk management authority?", "000f9284-29d1-4406-b8b7-4ebed5d88206": "How often should the specific criteria for deactivating GAI systems be reviewed in relation to risk tolerances and appetites?", "749af9cf-0261-4210-8386-73ebe7d73ec7": "What mechanisms should be provided to the public to ensure appropriate and meaningful consent regarding their data?", "7ebe645d-c2a1-4cf8-8294-39783e150b21": "Under what conditions should consent be re-acquired when using data collected from individuals?", "e417a9c2-fa64-4f72-a578-691bdb44ab42": "What types of identity-related information should be limited to avoid algorithmic discrimination in surveillance systems?", "71e97510-def0-41a1-b9e8-81348f5f753d": "In what settings should continuous surveillance and monitoring systems not be used according to the provided context?", "e77cfca3-3e32-4d60-aa9e-2b3c09a0863c": "What procedures are suggested for responding to and recovering from previously unknown risks in GAI development?", "94cde78b-0315-41a5-9e02-a1ab8afdae92": "How can GAI development enhance techniques while ensuring data privacy and preventing harmful bias?", "bd5502d8-97f7-407c-8cea-715d50c96b8b": "What is the primary purpose of AI red-teaming in the context of AI model development?", "d9ae537f-225f-4c85-aa01-6bdde2a1ee08": "How does the diversity of an AI red team impact the quality of its outputs?", "39899c65-44b3-4b4e-b754-53de3d096fac": "What methods can be implemented to evaluate the decisions made by GAI systems for interpretability and explainability?", "78b0bbc2-1736-4a45-8354-ac2102279837": "How can vulnerabilities in GAI systems be identified to prevent misuse and unintended outputs?", "98873820-06ba-4ec6-b304-6f82d1589091": "What is the title of the paper by Acemoglu published in 2024 regarding AI and macroeconomics?", "9f9a5070-bfc7-4aa2-951c-aa4d9acd4a21": "What topic does the 2024 survey by Atherton focus on in relation to deepfakes?", "dfebf95a-65bc-4438-95bf-1e34443d7f6c": "What are the key components involved in the algorithmic impact assessment process as described in the context?", "2ea70b3b-d21a-4780-82c2-e8902768da4c": "Why is it important for the reporting of algorithmic impact assessments to be clear and machine-readable?", "c81525b2-4b11-4899-98b7-a7845e77cd1b": "How do LLMs compare to traditional search engines in providing assistance for biological threat creation and attack planning?", "08e2d040-758d-443c-972c-38d0e00ce3e6": "What factors are necessary for the physical synthesis, development, production, and use of chemical or biological agents?", "6e60b11a-3043-4de6-8121-ab36959d0377": "What are the three categories of bias in artificial intelligence identified in the special publication?", "30067a3e-d415-48fb-83fb-e3dce76ac5b8": "What are the three broad challenges for mitigating bias in AI mentioned in the context?", "ac9c690b-3a8d-4878-acb2-0654ac6cb053": "What measures are taken to ensure that the app remains functional if users deny or revoke permissions?", "44f9659c-1a03-4b69-9d0c-2bc05316708a": "How does the app clarify the use-context of permissions to users?", "3e5accc5-3fdf-40bc-a324-f0068329acd2": "What does the context indicate about the enforceability of defenses against the United States and its entities?", "e9370df0-43ae-40fe-82bc-11b319e1ebdf": "How does the document relate to the concept of sovereign immunity?", "f9c636c7-429f-433b-8012-ed75397a85bb": "What techniques can be employed to mitigate representational biases in AI-generated content?", "28583001-9db6-48fb-b995-9319defa0f8f": "How can real-time monitoring systems ensure the effectiveness of content provenance protocols?", "b81a7847-d493-46f9-97ec-0f352064a1a9": "What measures can be taken to balance individual privacy with evaluation data access needs in the context of automated systems?", "005b3743-2ca5-4539-afce-22e829c78dab": "What key components should be included in an algorithmic impact assessment according to the provided context?", "6d94599a-f2db-4a3f-ae8e-d897c80b15f1": "What types of entities are required to provide public reports regarding data security lapses or breaches related to sensitive data?", "6502d1c8-fd8c-458a-9a49-e608bbc424be": "What information should be included in the public reports concerning the ethical pre-reviews undertaken by those developing technologies in sensitive domains?", "f76e3244-0855-4b1f-b76c-7c395d7fcccd": "What are the implications of human subject experimentation in the context of organizational compliance bodies?", "d7a13428-d56a-4056-b42f-0d158418b139": "Why is it important to maintain data quality in sensitive domains, particularly in relation to decision-making?", "5abde1cf-9576-4791-b8c8-3bcebd95e3fe": "What is the definition of \"dual-use foundation models\" as per EO 14110?", "fd571694-a553-4abb-acf4-976e7397496f": "What directive does Section 41(a)(i)(A) of EO 14110 give to the Secretary of Commerce regarding generative AI?", "444c5c4e-e9d8-482b-88d4-a489a19f5241": "What concerns have parents and education experts raised regarding the collection of sensitive data about students?", "8b3ffa18-7813-46d1-837b-8b9fb13ee687": "How can the transfer of employee data to third party job verification services impact future employment opportunities?", "610f5449-2b20-4a99-ac91-e59b0656d031": "What commitment is included in the Action Plan to Advance Property Appraisal and Valuation Equity regarding Automated Valuation Models?", "a6241056-ebb5-467d-b297-a329896fd0c7": "How can the use of AI and automated systems by employers lead to discrimination against job applicants and employees with disabilities?", "11d817b4-0a14-43e0-b67f-4bae32e99283": "What measures should be determined to identify new impacts from the GAI system according to Action ID MP-52-001?", "81cf6251-f279-4e11-b278-c7d27aac2970": "What is the purpose of planning regular engagements with AI Actors as suggested in Action ID MP-52-002?", "600b1568-c99e-4c2e-b9df-8c29ae1111d3": "What concerns did the National Disabled Law Students Association raise regarding remote proctoring AI systems and individuals with disabilities?", "2f3d2bc3-86f3-4b0c-bb0d-b7979a26e7a6": "How did the algorithm designed to identify patients with high healthcare needs treat Black patients compared to white patients?", "6bb2c64c-c50a-4d76-8af7-56c0a596e670": "What are some examples of critical resources or services mentioned in the context that should be accessible to individuals?", "5014be90-6134-4e50-9435-2bc4e49ca490": "How do the five principles of the Blueprint for an AI Bill of Rights function as backstops against potential harms?", "ae20035c-aace-47d5-8d1a-bbcad61294ee": "What are the suggested actions for documenting the AI model details according to MEASURE 29?", "38b29b0b-261c-406f-ac14-e1615ba59e84": "How should the output of the AI system be interpreted to ensure responsible use and governance?", "c6aaeb50-fc98-4af6-b4df-9ac7e752bea5": "What mechanisms are suggested to sustain the value of deployed AI systems according to the context provided?", "0d071c65-cd9b-4b16-a0bf-54411ae9795a": "How should GAI system outputs be evaluated in relation to organizational risk tolerance and guidelines?", "e8f9a4c6-8302-480a-819b-8e0115deded6": "What factors should be considered when assessing the demographics of groups in disparity assessments for automated systems?", "eec5a3fb-aaa2-4fd4-9084-8d740cf4402c": "Why is it important to use a broad set of measures in both pre-deployment testing and in-context deployment of automated systems?", "96ce4c93-676c-40c0-b910-8d0a56b5b031": "What should automated systems undergo before deployment to ensure their safety and effectiveness?", "b2860df7-ad59-467f-862f-e4892c776b7e": "How should automated systems be designed in relation to the safety of individuals and communities?", "b32a838c-2a15-45dd-a8b2-c2f172a9f6e6": "What are some applications and contexts of use for GAI systems mentioned in the context?", "1b642d13-a28a-483b-be05-5dc80068cc26": "How can organizations manage the risks associated with AI applications according to the provided context?", "e5190bbf-1cb6-48c2-ae8d-5fdb57124488": "What are the potential risks associated with eased access to CBRN information or capabilities?", "6417c74f-6e10-4f5b-8053-6fbe574c7358": "How does confabulation contribute to the spread of misinformation among users?", "f865f5df-bfb1-49c2-bda7-215f4d20d90b": "What is automation bias and how does it relate to the perception of GAI content quality?", "04643b5a-3270-445c-b78b-90d38541650c": "What are some of the trustworthy AI characteristics mentioned in the context?", "f6ff90d8-f04c-42a3-bedf-a0b99697957d": "What are some examples of domains considered sensitive in the context of health, family planning, and personal finance?", "75a813dc-4ba1-4cfd-bf15-2d63bfcd0d8d": "How does the definition of \"surveillance technology\" relate to the monitoring and collection of data concerning individuals?", "430ee8f0-4a85-4242-8174-f8174f2cfc1d": "What types of groups are suggested to be defined for gathering structured public feedback in the context of GAI technology?", "6a26d8b9-20ae-4024-a7dc-9189fae68696": "What actions are recommended for engaging in evaluations and assessments related to GAI risks?", "c343cd0a-608c-4b05-84a9-d4a061f7f019": "What types of data are considered sensitive when generated by individuals who are not yet legal adults?", "388c6006-2055-4b5d-bc89-fa48ae623ba0": "What are some examples of sensitive domains that require enhanced data protections?", "33d306d3-a528-4528-8cd5-43ba60163839": "What are the implications of surveillance technologies on the rights and opportunities of underserved communities?", "3c76e65b-246e-4a8d-afdb-2e91b488569a": "How does the definition of \"underserved communities\" relate to the impact of government and commercial surveillance?", "4f2aaa7a-7556-49c6-88a9-829093603584": "What are the necessary functions for which data and inferences in sensitive domains can be used?", "23ad22c3-693c-4c7e-a0ab-980657f5fca5": "What measures should be taken to ensure that surveillance technologies do not infringe on privacy and civil liberties?", "9fa12471-add9-480b-a140-3cae57530a34": "What types of metadata can be included in provenance tracking for GAI content?", "36ea99ac-9f78-4db4-b3bd-c2a268d20ce7": "How can provenance data tracking techniques assist in assessing the authenticity and integrity of digital content?", "350a1822-87af-47eb-97f3-06c05950ab63": "What are the ongoing assessments mentioned in the context aimed at monitoring regarding GAI tools?", "5515be41-e20c-41b0-b2d1-fe9ab4304bfe": "What characteristics define trustworthy AI as described in the context?", "afc6c1fb-6962-49d6-86a8-d2934475bc20": "What are the potential benefits of combining GAI-led red-teaming with human teams in AI risk assessment?", "96309fb2-8fe8-4333-9aba-3421bc01310b": "How might GAI technologies impact the challenges associated with content provenance, particularly in relation to deepfake content?", "c6097f74-b0f6-4b46-b853-4e26f8b303a3": "What groups are identified as being adversely affected by persistent poverty or inequality in the context provided?", "732ca28f-5556-4501-ad3d-6401f4cab353": "Why is it important for the data used in system development or assessment to be representative of local communities?", "fe499e35-8c01-48d8-916e-e6baa327c380": "What is the purpose of the expectations for automated systems as mentioned in the context?", "6fd42231-7236-4c2e-9866-4507c130a92e": "In what types of settings is extensive oversight expected for automated systems, according to the risk assessment?", "6df0dcb9-213f-49ce-86e0-072947f59a25": "What types of reports must the Department of Labor Office of Labor-Management Standards and employers' consultants file regarding their activities?", "74d98cb1-65c6-49a9-b1b8-07eb49929a80": "How do well-designed privacy choices on smartphones contribute to meaningful privacy and data agency for users?", "8ada4ff1-199e-4226-bb95-babc1b57bb17": "What are some examples of sensitive information that can be categorized as sensitive PII?", "3397c162-1952-40cc-8884-ad34e60a75a2": "How do lowered barriers for offensive cyber capabilities impact the ease of hacking and exploitation of vulnerabilities?", "4156166d-f251-49e7-93b9-439d1cd8bd84": "What are the different levels at which risks may exist in the context of GAI models and systems?", "bf29bc9b-402e-4877-8efb-359a0c6db3c9": "How can human behavior contribute to the risks associated with GAI models?", "307e90f5-a744-4452-b956-cc678e18d2cd": "What measures should be taken to review training data for CBRN information and intellectual property?", "86b733bf-0ed6-4490-81c9-dc4f6d85e491": "How can organizations prevent or respond to outputs that reproduce particular training data, such as plagiarized or trademarked content?", "02217bfe-d5f2-40e2-915b-4ef3c09c3252": "What is the importance of domain expertise and socio-cultural awareness in AI red-teaming?", "b30dfa42-f7fd-4074-9f73-7032abff349c": "How should AI red-teaming results be analyzed before being integrated into organizational governance?", "58559d9a-3ec2-40f7-ace7-2336d2c7b205": "What are the main concerns addressed in the paper by Greshake et al (2023) regarding LLM-integrated applications?", "38ef40cc-5352-405e-b8eb-aa9241477bf6": "How does Hagan (2024) propose to establish quality standards for AI responses to legal problems?", "6c64d0ff-7d98-4b28-9949-cd00c2eed68e": "What are the key tasks associated with AI actors in the context of CBRN information and capabilities?", "f65e1396-55f6-4fcb-ba4e-e767afae959f": "How often should GAI system vulnerabilities be evaluated to ensure safety measures are not circumvented?", "94a42faf-2ba5-4ec7-8748-39a3116a4d53": "What are the differences between narrow and broad application scopes in the context of external use?", "45eba1b1-9baf-4d7d-b7a1-d08f23535f37": "How do data privacy and intellectual property concerns relate to the use of various data sources such as grounding and retrieval-augmented generation?", "31d5f00b-c730-4a62-9bba-625b972a2a99": "What measures should be taken to ensure privacy protections when collecting demographic data for disparity assessment?", "94ec81f7-37aa-428b-b6b7-066353feec83": "What actions should be documented if an automated system leads to different treatment of identified groups?", "491ae79f-2926-45e7-b18d-d67053b38552": "What is the title of the publication related to Artificial Intelligence Risk Management by NIST?", "e011d282-cefb-43f5-8ab0-ea6442308303": "Where can the NIST AI 600-1 publication be accessed for free?", "a50cfe25-c693-43cc-b17c-3840d6b7a160": "What are some of the key elements included in the framework developed by non-profit organizations and companies for transparency in machine learning systems?", "e85be9e8-a000-4db8-af5f-9486dd6dcf9e": "How are major technology companies attempting to improve communication with the public regarding their automated technologies?", "1f390439-3dd3-4ee7-948e-06e94d829624": "What is algorithmic discrimination and how does it affect individuals based on protected classifications?", "02022286-ecf1-4c44-9ada-ec5950cab661": "What are some examples of classifications that are protected by law against algorithmic discrimination?", "95fac599-6b25-468a-9228-68939694684c": "What criteria are used to evaluate the safety risks of the AI system as mentioned in the context?", "d6dea6e8-5af9-4b5d-90b2-1f7dfc7c399d": "How does the AI system ensure it can fail safely when operating beyond its knowledge limits?", "c7366164-f8dd-4bf1-93ea-3885bc1a6808": "What are the expectations for automated systems regarding data access and correction for individuals?", "067879b6-28dd-48d3-b66a-7a02ab23130d": "How should entities handle consent withdrawal and data deletion according to the outlined expectations?", "810cc726-606e-4327-b787-083e29d37f48": "What are the potential forms of latent systemic bias that can arise in GAI systems due to the characteristics of the training data?", "a19bf3ba-ac6b-4f79-9ebb-09f471ee378e": "How might the digital divide affect the representativeness of demographic groups in GAI system training data?", "1864bd3d-a0e7-4e05-8d70-61fcd630efaf": "How do school audio surveillance systems identify potential \"stress indicators\" among students?", "8f65424d-1858-4821-b637-ff00e7f97807": "What concerns are raised regarding the use of online proctoring systems in relation to students with disabilities?", "a5849622-f8c9-4ef4-b456-c07c0cd6b789": "What is the focus of the section titled \"Overview of Risks Unique to or Exacerbated by GAI\"?", "cea64ad3-a16c-4010-bcfa-e944477f3312": "Where can one find the suggested actions to manage GAI risks in the document?", "73825310-9b67-4ca5-a11e-bd3d6059048a": "Who are the intended recipients of the reports generated by the automated system according to the expectations about reporting?", "3039170b-ab00-4fab-9c24-01f9efaea2b2": "Why are the reporting expectations considered important for transparency?", "0a751c70-b6ba-46d2-a06a-d3634c899308": "What practical tips does the technical assistance provide to employers for complying with the ADA?", "84788036-cee0-420a-859d-cb1c76227fac": "How did the healthcare algorithm's reliance on past medical care costs impact Black patients' access to healthcare?", "ed3efb94-fb87-4b0f-a4c3-de44b25db9a5": "What are the main themes discussed in the paper \"Algorithmic Pluralism: A Structural Approach To Equal Opportunity\" by Jain et al (2023)?", "882a6a65-5819-41e9-af95-7369028915b0": "How do people typically respond to AI failures according to the study by Jones-Jang et al (2022)?", "847c955d-4967-4cb4-b887-e386df7e7a73": "What are the criteria for automated systems to be covered by the Blueprint for an AI Bill of Rights?", "eb97baaf-8d09-4845-9096-8fb6246b35e7": "How do the examples of automated systems relate to civil rights, civil liberties, or privacy?", "519fc7a5-5312-430d-a352-88c9e629582c": "What are the key risks associated with the value chain of GAI systems that need to be tested?", "b0d564c8-7cb6-4d8b-a17c-43705d1f3515": "How should organizations reassess risk measurements after fine-tuning third-party GAI models?", "10c1772d-d5f4-44bb-9ecd-865f3c6044b2": "What techniques are suggested to assess and manage statistical biases related to GAI content provenance?", "fd959889-7bea-4d4b-b9da-c2de4a4dda5a": "How should content provenance data be documented to ensure it interacts with privacy and security effectively?", "af8fa2e6-2375-4be2-aabd-11cd9580b7f8": "What is the purpose of reporting summary information about automated systems in plain language?", "3df35550-0416-4fa4-836e-157cfc138073": "How should the level of risk be determined for operators or others who need to understand the system?", "6f2ac104-7ba2-4f62-9adc-46ea4bdfec81": "What methods can be used to compare GAI system security features against industry state-of-the-art practices?", "7b5f26bc-94d0-4a2a-b843-9ae3b81d81f0": "How can user surveys be utilized to assess satisfaction with AI-generated content and perceptions of its authenticity?", "f20a40d4-16bb-4a06-9d07-b39cd01afac9": "What methods are suggested for employing human domain knowledge to enhance GAI system performance?", "e9cfb3f1-3eeb-42f7-aa22-c2c53b475122": "How should instances of anthropomorphization in GAI system interfaces be tracked and documented?", "63ce4b31-6a30-44d1-ab24-a0fa64a4b790": "What are the potential risks associated with \"algorithmic monocultures\" in decision-making settings?", "bba5f22c-3fe8-4450-8fb3-9e996e42818b": "How has the impact of Generative AI (GAI) on the labor market been studied compared to traditional AI?", "4973be89-d89f-4e04-8890-a8840c276123": "What are the key tasks involved in the Human-AI Configuration and Value Chain integration?", "416cf4aa-9895-4318-9499-bdb752172e17": "How are the most significant AI risks selected for measurement during the MAP function?", "c94162d0-9e34-49a3-82c2-614fa6fd3e2b": "What are some key practices mentioned for ensuring data protection and retention in the context of GAI use?", "1f6f576e-ebc2-47df-87cc-3a763daf72fd": "How can establishing acceptable use policies for GAI in human-AI teaming settings help mitigate risks?", "165cabfe-d697-4bea-ac2d-db1f7efb7b89": "What measures should be taken to ensure that data collection conforms to reasonable expectations?", "5e3864fc-20f0-4964-843d-4f2d6a08b98f": "How should designers and developers respect user decisions regarding the use and deletion of their data?", "38934b1c-3153-4383-9d13-79f641cc3271": "What are the key factors that a predictive policing system analyzes to identify individuals at risk of gun violence?", "83b31149-78ca-48ad-a421-13f455dc1a5c": "Why is it important for both police and the public to understand the reasoning behind the determinations made by a predictive policing system?", "17c1eaeb-8a02-4304-9c3e-9ee9232a3fbd": "What specific goals should be identified for data collection in a surveillance pre-deployment assessment?", "a170a38a-f0bd-4a5c-89d8-0d0999b20f5e": "Why is it important to have an independent party assess the impact of surveillance or data collection on rights and opportunities?", "bf7e4330-67aa-4c0c-b320-8dbf6dbc3711": "What are the main concerns discussed in Satariano et al (2023) regarding the impact of deepfake technology?", "31afab54-9270-49c3-9bc7-bb98f3a22d38": "How do Schaul et al (2024) describe the role of certain websites in shaping the intelligence of AI like ChatGPT?", "857595d8-8f73-48f5-97b7-4497db7f3121": "What are some potential negative impacts of inaccurate inferences made from disparate sources of information?", "da4b4aa1-da76-41b2-89b1-ae6ccb1faefc": "How can predictive inferences based on PII or protected attributes lead to adverse decisions for individuals or groups?", "a44f58f1-9b9d-4239-b636-44f5a9e5c11a": "What are the existing regulatory safety requirements mentioned in the context for medical devices?", "4e595de1-caba-41fe-a046-a040bf7ab60f": "Why might exceptions to the principles described in the Blueprint for an AI Bill of Rights be necessary?", "cb812d0e-d86e-4628-87e2-2ec104e62b32": "What aspects of the training process for the pre-trained model are highlighted in the context, including hyperparameters and duration?", "5b769470-f2da-450d-8ca9-ce1fb3f0466f": "How does the system integrate user feedback to address problematic content according to the provided context?", "3e42dbb8-5c1c-4406-8976-36547580f04b": "What are the key considerations for ensuring accessibility in the design, development, and deployment of automated systems?", "74366bf3-23c5-44d9-9909-ad60e9d6c0e5": "How should organizations address accessibility barriers in automated systems after deployment?", "ebae6b5b-5715-4e92-af7d-f873b23aee58": "What are some examples of content types where creative generation of non-factual content can be a desired behavior?", "f8563ed2-de0d-4bc8-b726-30e55501a07b": "What issue do legal confabulations present in current state-of-the-art LLMs?", "13365d5b-4aac-4281-afb0-b4499217165e": "What are the Access Board\u2019s Section 508 regulations focused on in the context of technology design processes?", "34d901db-047b-469a-93d1-aef28ed58472": "Which organizations have issued standards related to accessibility criteria besides the Access Board?", "861cdb16-559f-4f5a-9b46-27ad9e846d80": "What types of data and metadata are included in the reports provided to users?", "c4b4beb5-bc50-4fc0-8e5a-8d85511b0678": "What measures are taken to ensure user privacy when identity verification is required?", "e0622975-699e-4e3b-aeba-bcbe9fa1c268": "What role does notice and explanations play in the context of automated systems affecting individuals' lives?", "79236b46-6748-4a30-a82b-e7c674568551": "Why is it important for the American public to be informed about the use of automated systems?", "3bd3efc5-a542-4a68-a216-b4879fd89c6c": "What is the purpose of creating measurement error models for pre-deployment metrics in the context of TEVV?", "1ef71476-55af-44d9-9fcf-14263974690e": "How can domain expertise be utilized when modeling complex societal constructs such as hateful content?", "b9badc0d-8ccb-448a-a966-41ab05c005ad": "What is the purpose of the Blueprint for an AI Bill of Rights published by the White House Office of Science and Technology Policy?", "230fb635-9548-4672-b797-1b575ff48db8": "When was the process to develop a bill of rights for an AI-powered world announced by the OSTP?", "43b40c0d-9c6c-4fcb-985c-6e8cdd4dc8f5": "What should be the criteria for triggering a human alternative in the attainment process when automated systems are involved?", "5fa5c49e-86b6-4b56-ab7b-2008504e664a": "How should the opt-out process be designed to ensure it is timely and not unreasonably burdensome for individuals?", "73d2b114-db7f-4786-827a-22e91e87cc24": "What is the title of the report published by the Federal Trade Commission in May 2014 regarding data brokers?", "d2e732ca-f3b9-41c2-837e-b129a1da3c87": "Who are the authors of the report on social media surveillance by the US Government published by the Brennan Center for Justice?", "6e834a06-38e0-4ab5-a8bb-4c330c8b8849": "What approaches can be used to assess algorithmic discrimination in automated systems?", "a0d654fb-227a-4891-aaac-3163ad42b8fe": "How often should riskier and higher-impact systems be monitored for algorithmic discrimination?", "b234b55d-b69d-476a-a6b6-798bfb917036": "What are the implications of the principles described in the white paper for US government negotiations?", "ab52af4e-58ee-40c1-8390-a0e086b3a602": "How do the principles in the white paper relate to existing statutes and regulations enforced by Federal agencies?", "5960f654-a577-4068-929d-6f0bf3b893ec": "What measures should be taken to ensure that algorithmic discrimination does not occur based on community membership in real-world contexts?", "55afe1aa-509f-43b4-bacf-24fa7d1117fb": "Under what circumstances is surveillance considered acceptable, and what guidelines should be followed to ensure it is limited and proportionate?", "32c3fbee-70f7-4fdd-b12e-5798ff0e8c96": "What should be made public whenever possible regarding effectiveness?", "cf120356-4331-4a32-bcf1-59997b9f3cf4": "What is the significance of considering human alternatives in the context provided?", "755d6c81-4e63-429c-966e-4566e3ac7bd0": "What are the potential consequences of using unobservable targets in automated systems?", "1cfe4880-b551-4ba6-9318-023c415eaf25": "Why is ongoing monitoring and mitigation important for addressing algorithmic discrimination?", "bbf89691-521e-4ef4-b704-f006409c5e0b": "What are the suggested actions for measuring AI system performance or assurance criteria according to MEASURE 23?", "d6bc63b1-0104-4768-bbc3-77d09544e320": "How should claims of model capabilities be evaluated as per the guidelines outlined in the context?", "6b58f561-3584-40bf-82b1-e526461f6bb5": "What are some potential sources of harmful bias in Generative AI (GAI) systems?", "d8aa1526-aef3-48c6-b3b5-53868a0d59f0": "How can disparities in model performance across different subgroups contribute to discriminatory decision-making?", "0036ef04-4e58-41ec-95f1-97eaa4d03952": "What are some examples of how data privacy issues can arise in the context of insurance and data brokerage?", "0e2dc1a7-b6a4-4d23-915a-10fd8ba7d7c0": "How might the installation of facial recognition systems by public housing authorities impact individual privacy?", "3ee7390b-713e-442f-8e9e-c748f2509898": "What policies and procedures should be established to record and track GAI system reported errors?", "fd5cd8db-2d0c-45d0-ba81-afab4fb7bbbd": "How can organizations ensure the integrity of information when tracking near-misses and negative impacts?", "f8feaf50-5e49-4ca7-bbd2-fa220ee41cd6": "What methods did the White House Office of Science and Technology Policy use to gather input from the public on algorithmic and data-driven harms?", "eb66d742-6c1b-4dc0-9047-9b7660d1310c": "Who were the primary participants involved in the year-long process led by the White House Office of Science and Technology Policy?", "478c9a2a-1d78-4631-9624-71c48fa4a9d9": "What rights do applicants have when their application for credit is denied according to the CFPB?", "486c26b4-1176-42d0-81a8-ab2792a665f3": "What does the California law require regarding notice and explanation for warehouse employees?", "3d73fb6c-18d9-4037-934a-5dab4c5fd00d": "What methods are suggested for measuring the prevalence of denigration in generated content during deployment?", "fd3136a2-1d66-4596-b1da-bfe00c32fdaa": "How can direct engagement with potentially impacted communities help identify the classes of individuals or groups affected by GAI systems?", "bf8f397e-3fa2-404f-8e61-07fde6ea4fcb": "What are some potential risks associated with text-to-image models in terms of promoting dangerous messages?", "25ee3d67-d288-4b56-8310-ba22a663478f": "How do current systems attempt to restrict harmful content generated by GAI, and what limitations do they face?", "763bf30d-db02-41ff-8fb9-2c4cebc08bdb": "What are the potential consequences for individuals who choose to opt out of an automated system?", "8985243f-eedf-4259-a2f2-80991a6a4e81": "In what situations might a human alternative to an automated system be legally required?", "c77b9ea8-28d9-444d-b8e6-e27141ca11a3": "What are some examples of sectors or situations where notice and explanation requirements are already in place?", "e02f4d31-abb6-4969-9a35-1256007a07f8": "How are innovative companies and researchers addressing the challenge of creating explanatory systems for the public?", "653aac08-c3f5-445a-865f-370d762f3b4d": "What are the risks associated with the use of Generative AI (GAI) as defined in the document?", "a6af37fa-fb89-4e4a-96d3-b5bb23a37177": "How does the document suggest organizations manage the risks related to large language models (LLMs) and cloud-based services?", "77eea05d-e8ca-48d1-89a2-e97a5de5eec5": "What type of medical device is mentioned in the context that collects data for diagnosing sleep apnea?", "99339f1c-1f71-48a1-9801-98990bd5e233": "How did a department store company use predictive analytics in relation to consumer data, and what was the consequence for a teenage girl?", "548cc5b4-a78d-4f27-a266-68ad5c5fe75b": "What challenges arise from the opaque and complex decision-making processes of automated systems?", "cd576c5a-9e90-4744-bb16-fb1b6d9035c6": "Why is it important to provide clear and valid explanations for decisions made by automated systems?", "81514d81-d0f9-4894-850c-98ce264ecf0c": "What are some of the key differences in oversight requirements between generative AI (GAI) and non-generative AI tools?", "d4e76dfc-69d7-49b6-89d7-46dc5d7f14ce": "How might the varied outputs and user interfaces of AI technology influence the interaction of different AI Actors with GAI systems?", "069346dc-2702-47ac-b1fa-e63ceee007ea": "What are some of the mental health problems mentioned in the context that are being bred by certain societal issues?", "277149b9-e4c7-47c6-9443-d700150e842a": "How are some companies addressing concerns related to consumer privacy according to the context?", "6d8942b6-7c11-44d6-a758-fba9f519402f": "What steps should be included in the communication plans for deactivating a GAI system?", "ea50abc2-7dab-4dc7-a5df-81e725761de3": "What are the potential risks associated with the performance of AI systems that may lead to their deactivation?", "43434e05-f092-4112-874d-48eee034d2f5": "How can the selection of a watermarking model impact computational complexity in AI systems?", "0827d342-b494-4447-bc47-805f99c3708f": "What are some organizational risk management efforts for enhancing content provenance in GAI systems?", "942580d1-fb7b-4fab-b194-e8f94f97b25f": "What role do organizational boards or committees play in the deployment of GAI applications according to the provided context?", "74fa6ef9-81f2-47ba-8633-d92ba835eeda": "How should human moderation systems be utilized in relation to generated content and AI model performance?", "ac382de5-e963-4bfa-9b5c-df62bd916530": "What are the key components involved in third-party transparency and risk management for GAI systems?", "c30d0097-78f9-4446-a954-1614f3c9ae1c": "How do robust test, evaluation, validation, and verification (TEVV) processes contribute to pre-deployment measurement efforts for GAI systems?", "551b762e-4680-421b-9369-b7dc0f4b14c6": "What contributions did the NIST Generative AI Public Working Group make to the report on trustworthy development and use of AI?", "060b34d3-fe93-48b2-89ea-65ad890bed00": "Who are some of the individuals acknowledged for their helpful comments and contributions in the report?", "b3ff1c60-3768-47ab-b20a-d842f27f9e8f": "What does the term \"confabulation\" refer to in the context of GAI systems?", "a872ff46-6d23-462d-89d1-26137a2c28bb": "How do confabulations relate to the design of generative models like LLMs?", "d08c07b2-2399-4460-979d-60ef2bf84170": "What aspects of human governance processes should be assessed and made public according to the context?", "a14f23c7-a428-4756-89ab-bc878ec812f8": "Where can definitions for key terms related to The Blueprint for an AI Bill of Rights be found?", "ef1d8fd5-d2d9-4f6e-9507-acbbf2ce511b": "What are the two criteria used in the framework to determine which systems are in scope for the AI Bill of Rights?", "437768ec-9ba8-481d-926f-e800cd1df5c3": "How does the framework address the potential harms of AI systems in relation to the American public's rights and access to resources?", "8869cf94-03e3-4166-aadf-727bd60e8b31": "What factors can influence the likelihood and magnitude of risks in a given context?", "eb586687-25c6-4aa1-b8a4-c211a3d17c85": "How do GAI risks differ from traditional software risks?", "a6335481-7ed7-424c-af30-9b1c05acba60": "What is the main focus of the paper by Kalai et al (2024) regarding calibrated language models?", "f3f3acb3-66b7-4f0f-83f4-cb3a00575eac": "Where can the paper \"Calibrated Language Models Must Hallucinate\" by Kalai et al be accessed?", "dec930a3-4a52-4dd7-8c40-c584e80cd4f9": "What types of organizations can take concrete steps to uphold the values mentioned in the context?", "cc8eb8ef-80bc-4419-80b9-2c4c0e800b3f": "How does the Blueprint for an AI Bill of Rights assist in informing policy decisions where existing laws or policies are lacking?", "72433b8b-1aef-4dbe-a4e4-c5771965c57f": "What is the primary purpose of the Policy, Organization, and Priorities Act of 1976 as it relates to the Executive Office of the President?", "15425181-5e35-420f-b576-84602307fa54": "How does the Office of Science and Technology Policy (OSTP) assist the Office of Management and Budget (OMB) regarding Federal research and development?", "8a1dee58-1c97-43cf-a2b2-cb723b106c3b": "What steps have been taken to address the issue of sexualized content in search results for \"Black girls,\" \"Asian girls,\" and \"Latina girls\"?", "bcd56f3b-e57a-4e66-ae4a-255256a26c94": "How do advertisement delivery systems contribute to reinforcing racial and gender stereotypes in job advertisements?", "ec059047-1084-43ee-b0ca-b790f9a63f85": "What are the two types of prompt injection attacks mentioned in the context?", "6f325aeb-f5a7-4154-b238-6e98f5f03d61": "How might conventional cybersecurity practices need to adapt in response to the challenges posed by GAI systems?", "2fc84559-a4c0-4a15-acdb-8467471aa439": "What is the importance of involving representative AI Actors in structured human feedback exercises?", "526eaab7-8b79-4adf-8e91-c8a5c413411b": "Why is it necessary to verify that those conducting structured human feedback exercises are not involved in system development tasks for the same GAI model?", "14e6599f-fbba-483f-a1b0-9aeb3be3d38c": "What are the capabilities and limitations of GAI systems in relation to digital content transparency for AI actors and the public?", "f8c9a5ab-8157-49d8-a992-f567207b3eda": "How can structured feedback about content provenance be effectively recorded and integrated from various stakeholders, including operators and impacted communities?", "02fc96b2-8e70-4d73-ab71-d32de8b8aa60": "What are the potential risks associated with increased attack surfaces for targeted cyberattacks?", "63d6c057-4093-4e1b-ad63-814f66e4b145": "How might the easing of production or replication of copyrighted content impact intellectual property rights?", "24e9270d-329d-4d85-8b6a-d5fd7bbe12ce": "What processes are followed and documented for tracking, responding to, and recovering from incidents and errors in AI systems?", "57db431d-f943-4bd7-a517-528a7cfbe1c8": "How are incidents communicated to relevant AI Actors and affected communities according to the guidelines?", "93db1398-3b91-4443-97ea-59285b92d625": "What are the legal requirements that govern government surveillance and data search and seizure in the US?", "11258c5a-d0f6-458c-b0eb-0dfea56e0f28": "How do Constitutional and statutory requirements ensure human and judicial review in criminal investigative matters?", "f240ab76-9352-40ad-914d-e9f0fc77008a": "What are the potential risks associated with membership inference in the context of biometric and personal information?", "1c7b2708-16e1-4516-8e70-49f4bc2445e1": "How can feedback from end-users and stakeholders be utilized to improve the design of provenance data-tracking techniques?", "f2e2f690-1f74-4215-abfe-4ce2189ccbee": "What are the key considerations for collecting data from individuals in the context of machine learning model training and testing?", "f8ee13ce-de22-4486-afd9-9981fbeaebbd": "How can user experience research contribute to ensuring that data collection practices align with individuals' expectations and desires?", "4f9e5858-e192-42b5-aeb1-ead4734620ec": "What are the potential benefits of using generative AI models in social media campaigns?", "1e4dc283-1cd3-4ccf-b04e-d1d6d46a0616": "What are the two primary information security risks associated with GAI-based systems?", "5bded1b1-f8b6-42eb-87c7-ee7707dbfd07": "How do current text-to-image models contribute to the underrepresentation of women and racial minorities in professional roles?", "53748806-5803-41cf-8d2d-41f04fbc0cab": "What challenges do image generator models face in producing non-stereotyped content despite specific prompts?", "d9ab6799-40d9-4ebf-a90e-e8ce6c516392": "What are some examples of sensitive domains that require enhanced data protections?", "18f57e1c-be4f-4443-b553-0bf12d3bfe45": "Why is it difficult for individuals to opt out of sensitive domains such as health and employment?", "5f647aff-dba4-4a06-8a9f-a5d0ff5ae062": "What are some real-life examples of how data privacy principles can be implemented through laws and policies?", "65955264-6a20-4528-a054-5e86603866a8": "How does the Privacy Act of 1974 illustrate the principle of limiting the scope of data retention?", "d8f6746a-4e57-437a-a605-3b3bb8e0d76e": "What is the importance of having a human fallback system in automated systems, especially for the American public?", "4a55b659-8800-4c0e-bc5a-fee5c7d365c7": "How does the context suggest that immediate human consideration is necessary in time-critical systems?", "09ff3795-c6f0-4673-acba-315f0996e697": "What measures are organizations taking to demonstrate compliance with applicable laws or regulations regarding privacy risks?", "5d7172e7-a02e-49b3-9f1c-6e0eaf4d7fab": "What prompted the state-wide biometrics moratorium in response to the school board's surveillance of public school students?", "86514d23-b3a3-4aa1-b2db-f401c1d421ee": "What are the anticipated environmental impacts that should be documented during model development, maintenance, and deployment in product design decisions?", "e4a435fa-569c-4324-8bc8-ffab34821f18": "How can the trade-offs between resources used at inference time and those required at training time be verified when measuring environmental impacts?", "cccd1498-8af8-48f2-824c-617dae955a76": "What is the purpose of utilizing a testing environment like NIST Dioptra in evaluating GAI trustworthy characteristics?", "c2adfede-b901-4f59-b5f4-d276540393c3": "What are the risks associated with extrapolating GAI system performance from narrow and anecdotal assessments?", "09f01393-367a-493c-82e8-083d525a9dc0": "What criteria must federal agencies meet to retain data about an individual under the Privacy Act?", "744a8ea0-bf94-4c2b-9b2d-4edc60a4ceb2": "What rights do individuals have regarding their personal information stored in federal systems of records according to the Privacy Act?", "8fb00557-bf63-4c30-831e-3d109f5f1996": "What information should designers, developers, and deployers of automated systems provide to ensure transparency for users?", "46334081-aeeb-4c0f-a76d-7d0f118412c8": "Why is it important for individuals impacted by automated systems to be notified of significant use case or key functionality changes?", "99e88de6-a7d7-4774-94bf-a0f0c66e9338": "What is the purpose of regularly assessing and verifying security measures according to MS-27-009?", "b93739db-81d6-462a-b18a-99ab6b2e92c5": "What types of risks are examined and documented under MEASURE 28 in relation to transparency and accountability?", "731726ed-1384-4885-9872-7cc5c4b62586": "What are the expectations that automated systems should meet when handling sensitive data and metadata?", "b9aae9cf-981b-4cde-92cd-2988a4ab9e5d": "Why is it important for the American public to have assurances regarding the protection and use of data in sensitive domains?", "a67947f8-0a66-4290-9b63-816d75a5369c": "What are the potential risks associated with confabulations in statistical predictions, particularly in healthcare?", "449dc11c-9e07-4f3f-bb08-55b10e8c9cf8": "How can the confident nature of a response contribute to the spread of false information in open-ended prompts?", "d41c817f-ddb7-46ed-b547-258138a885c7": "What measures should be taken to protect the public from algorithmic discrimination during the development of automated systems?", "3f0648d3-8021-4c3b-b6c3-384ae596525c": "Why is it important to conduct proactive equity assessments in the design phase of technology?", "ebf12bdc-8e81-4099-9120-51637db79ef7": "How do GAI systems contribute to the advancement of offensive cyber capabilities?", "5a47b49f-d495-45e1-8abb-8110a86ea3f2": "What vulnerabilities are GAI systems susceptible to that could impact cybersecurity?", "15713dbb-b100-4bed-aed2-12b4d7cb1307": "What methods can be used to measure the reliability of content authentication techniques such as watermarking and cryptographic signatures?", "a80e6b76-9ab4-49ad-b3f4-a59e17162f92": "How can the rate of false positives and false negatives in content provenance be evaluated?", "8f5a0f44-808c-4f9f-abc4-9f82434f42e4": "What are the key barriers for malicious actors in the misuse of chemical or biological agents as discussed in the context?", "fc49f5bb-3886-4279-8ece-883be24b7b10": "How might chemical and biological design tools (BDTs) enhance design capabilities in chemistry and biology compared to text-based LLMs?", "cc57a43a-8002-40db-8d30-c4870889855d": "What are the main components included in the Blueprint for an AI Bill of Rights?", "1270243a-b658-4e7a-b9ad-ff5a2e39738e": "How was the Blueprint for an AI Bill of Rights developed?", "c9d0e42d-91c7-4d3e-9bad-ab2bb141df2a": "How does the local police department utilize videos from the community in relation to facial recognition software?", "f944fb43-a92e-46c2-ae48-117d7d14a5f7": "In what ways do companies use surveillance software to monitor employee discussions about union activity?", "9838d201-e798-4bde-89ad-c76634d4ee6f": "What are the implications of withdrawing data access consent on user data and metadata?", "66b43651-d86b-49f6-99a7-d8db5a2710e6": "What capabilities should entities establish to support individuals in managing consent and access in automated systems?", "a1579016-b897-496a-b12c-f3f3f5fd9243": "What steps should be taken to enhance transparency and accountability in the GAI system according to MG-41-005?", "cdd58363-c9cd-4b4f-9764-c37260c4cafd": "How can organizations track dataset modifications to ensure the provenance of data as outlined in MG-41-006?", "a1132e72-2b71-4491-b77c-cac660935be7": "What are the established security measures suggested for assessing vulnerabilities and threats in AI systems according to Measure 27?", "782bcc8c-943a-459b-8ef5-9db998b461ab": "How does Measure 27 propose to benchmark GAI system security and resilience in relation to content provenance?", "c16c793f-5e60-4cd0-b943-c2b3e9a4a47f": "What practices should be applied to ensure content provenance in GAI systems to mitigate risks associated with synthetic data generation?", "9277e3ee-6b61-48dd-83c1-efbbcc4351fd": "How can potential harms related to misinformation, deepfakes, and tampered content be identified and ranked in the context of GAI?", "214a76e3-cdb0-46b9-9185-443186938a3c": "What is the purpose of the Blueprint for an AI Bill of Rights as outlined by the White House Office of Science and Technology Policy?", "5582ad26-6f6b-44a9-b5d5-fd848da9a700": "Is the Blueprint for an AI Bill of Rights considered binding guidance for the public or Federal agencies?", "b9b7f9b9-8d46-4cdd-a413-8094f3a93c6f": "What are the key tasks involved in the AI Actor's responsibilities related to information security?", "56bb7fcd-fca9-43e2-aaba-f4aa4b68898c": "How does the AI Impact Assessment contribute to understanding vulnerabilities in AI systems?", "19484be7-46ad-4bbd-85af-13c18c0b8b78": "What is the title of the publication released by NIST in July 2024 regarding artificial intelligence?", "57993c1a-e8c0-45f0-afab-8737c76373fc": "Who is the Secretary of the US Department of Commerce mentioned in the context?", "b79f7499-8b49-4c67-8393-2172e7606c7f": "What were the reasons individuals were denied benefits in the system?", "0b4b43e6-10b5-403b-9536-ba479dbe9e12": "How did the lack of an explanation for the system's criteria impact the correction of errors?", "816d80a1-0772-485a-b1ae-f1a7384e1407": "What are some potential issues with using intelligence tests and professional licensing exams to assess GAI system validity and reliability?", "a673faee-29db-4860-aba5-d7635415fa02": "How do measurement gaps between laboratory settings and real-world conditions affect the assessment of GAI impacts?", "bc491efb-0ab2-4733-a9e3-7f2085082402": "What are the federal laws that require lenders to notify consumers about certain credit decisions?", "5964db43-850c-4ca2-8da5-cb2ebbd9df07": "What information must be included in an \"adverse action\" notice provided to consumers who are denied credit?", "25fc7d12-5dd1-4331-beeb-3a0abe234dc8": "What mechanisms are included in the post-deployment AI system monitoring plans for evaluating input from users and other relevant AI Actors?", "2d79f1ad-ca53-4aaa-9f6d-fba2e9241abf": "How can collaboration with external researchers and industry experts help in managing identified risks associated with AI systems?", "8b380630-208a-4c55-966d-062a5e9a9011": "What types of unacceptable use should be identified through stakeholder input according to the AI RMF Map function?", "8468373b-2238-4dfa-bf03-7b39957896ce": "How should organizations maintain an updated hierarchy of identified and expected GAI risks related to model advancement and use?", "d41f3d7e-ccbb-4f6f-ae1b-84d1de865478": "What are employers in California required to provide employees regarding quota systems?", "89d9c052-49a7-43a5-8c7a-a3c85710eb0b": "What is the focus of the research being conducted by NIST on AI systems?", "2c8fa2c5-eaf6-4a67-801c-8c1dc6ce8952": "What was the purpose of the listening sessions conducted by OSTP regarding the RFI?", "0f2fc869-a4ec-4d91-a223-58ad6dc4f398": "How many participants attended the two listening sessions organized by OSTP?", "b53ff3e7-9c7a-4ce7-9b11-b0fe224f0a3a": "What are the key capabilities and limitations of monitoring systems in the deployment of GAI technologies?", "1655aa5a-1ad2-42f7-866e-17aa2ab82839": "How can organizations effectively document GAI system objectives to identify gaps in provenance data usage?", "214d7243-3fd2-42c2-acbc-8cb4bb577349": "How does the Blueprint for an AI Bill of Rights address the impact of automated systems on communities?", "3537b252-2811-42c0-bbbf-439364d72015": "What challenges do existing legal frameworks face in protecting community-level rights in the context of data-driven automated systems?", "227009f5-73b5-4982-8167-674f67fd430c": "What are some examples of transparency artifacts that should be reviewed for third-party models?", "523b4958-6783-40d0-ac83-9f107027d950": "How are pre-trained models monitored as part of the regular maintenance of an AI system?", "d1120818-6ca3-443a-a2a7-b37a37d564d9": "What factors should organizations consider when measuring GAI risks based on the characteristics of the model or system architecture?", "d9e7f269-d35c-423d-b36d-7ee5f314d24d": "How might the severity and likelihood of negative impacts influence the allocation of risk management resources in GAI applications?", "0c3c7fcf-cdd0-4df7-994a-8e4321981ed2": "How do body scanners at airport checkpoints determine the scanning setting for passengers?", "11ac3348-096c-4523-9eef-b88cfab259e6": "What recent plans has the TSA announced regarding the treatment of transgender travelers during security screenings?", "08b064d7-d0db-4bba-ad77-28aaa5f58d3c": "What are the key considerations for organizations when conducting field style tests on GAI systems?", "ab1bd086-2354-4ed7-96cc-0f550ae05a98": "How can organizations ensure compliance with human subject standards when collecting user feedback on AI systems?", "4f8822e6-da81-4446-83c1-e69ceb47852f": "What factors should be considered when tailoring explanations for different audiences in a dispute or contestation process?", "67f06504-bf89-45cf-86e6-c6716d60990c": "How can user experience research be utilized to assess the effectiveness of tailored explanations?", "5753d99f-826d-4052-b526-d8e76c24eead": "How can documenting and reporting GAI incidents assist AI Actors in managing risks?", "6c9c1fd0-a1b9-4afb-aa5a-a59fdfaeed25": "What measures can organizations implement to prevent similar GAI incidents in the future?", "4fcb16bc-e618-4d2d-a74f-b11b83d1c8b3": "What are the key components involved in the evaluation of AI systems as mentioned in the context?", "321f3d69-1c79-47b9-b597-55f9ff1936c2": "How does the MAP function contribute to the examination and documentation of privacy risks in AI systems?", "85305491-3146-4832-9c4b-4ba64eddbbb7": "What were the four primary considerations relevant to Generative AI that the GAI PWG focused on?", "45505d03-3864-4838-b03b-b0323b492b3c": "How did the GAI PWG obtain multistakeholder input on GAI risk management?", "8cea9dd3-2a0c-4dbf-8917-a237ab2779d8": "How do GAI systems impact the preservation of endangered languages in everyday processes?", "a33fcd18-3083-4a37-ae9e-584f58f19626": "What challenges do lower-resource languages face in terms of model adoption and accessibility when GAI systems are used?", "c04c3ef5-fc22-485b-b837-d0022ca05dba": "What criteria should be used to determine the appropriateness of opting out of automated systems in favor of human alternatives?", "e86f13e1-c0b7-4ee9-90dd-6d4420591789": "In what situations might a human alternative be required by law according to the provided context?", "725035af-ce84-41e8-a51a-2ff9ee7b3038": "What are the potential rights violations associated with AI development and deployment?", "29f7e13b-4e48-4502-aa77-65ab9da6f304": "How can governance and oversight mitigate rights violations in AI systems?", "9d897557-b011-4e1f-ac9f-b07cb471f683": "What organizations are associated with legal defense and civil rights in the provided context?", "007c1095-b237-4cf8-9186-1911d363b072": "Which technology companies are mentioned in the context?", "c52783a7-cbe8-4efc-a470-f4ac8250a737": "What are some potential negative consequences of system use mentioned in the context?", "1a8ada12-c96f-4b7e-a0ed-077023394efc": "Why do panelists believe that transparency alone is insufficient for achieving accountability in technology governance?", "de34dd81-1c67-41da-a981-89f79dc2d0aa": "What should be tested to ensure users who have trouble with the automated system can access human assistance?", "0fa06655-c9c0-4704-a952-f17dc84a4960": "How should mechanisms for human consideration and fallback be designed in relation to the automated system?"}, "relevant_contexts": {"0f7ca60e-78a7-4c19-94cd-b98471043def": ["0216ed9f-c5ea-43f6-afb7-c0fb4ff44223"], "96d62b9d-d92b-4d6b-aa65-b4bcd27c1a46": ["0216ed9f-c5ea-43f6-afb7-c0fb4ff44223"], "f138c496-711b-4d24-b116-7e852d9e3761": ["ec5b6e5d-5f21-45cc-b25a-ab89951ce9f8"], "532cca04-9f3b-4f2e-b160-fb025efbd538": ["ec5b6e5d-5f21-45cc-b25a-ab89951ce9f8"], "05df20e2-f4e5-4344-b7a8-4239ec0f65e7": ["03435e48-7db2-4cb5-9aa7-04c8d08ffe62"], "af1fa2ea-8182-486f-8911-b0c78707026d": ["03435e48-7db2-4cb5-9aa7-04c8d08ffe62"], "27a22958-257d-414b-8c0c-a535808fe157": ["aad8bf96-00a0-4cd4-9733-51e92bc306fe"], "f54c33a1-6d93-4d14-93cb-26b49e1467b5": ["aad8bf96-00a0-4cd4-9733-51e92bc306fe"], "985d2f5c-bf11-4b3a-8a0d-3902f0d00e97": ["c7302d34-43e6-4627-8887-144b91086503"], "553b41cd-3b35-4c68-b59f-84f6001bd8ed": ["c7302d34-43e6-4627-8887-144b91086503"], "d3fa1bd4-0aa4-4661-9303-8d56ffa15407": ["03f53429-159b-4268-9abb-60ff59e96c8d"], "2b50a56f-b312-4eb2-b1e6-41777b9ae89c": ["03f53429-159b-4268-9abb-60ff59e96c8d"], "1ae9029d-65c7-45dc-815c-0243c25762db": ["ffe4bd5e-e851-4131-bb3d-bafc8a9b19b5"], "7912e90d-b021-4226-b4b9-0c44db96e7e5": ["ffe4bd5e-e851-4131-bb3d-bafc8a9b19b5"], "48fa9ed1-0f08-477a-bb26-9b17638a86e5": ["ca254912-1583-4ffe-b9c1-294610eb5097"], "30e5fcdc-6d84-4998-8aef-2826da250e98": ["ca254912-1583-4ffe-b9c1-294610eb5097"], "b3db14d0-8f7f-4d6b-8f66-61438802c0e9": ["7ac38cf8-1be4-4be2-a29d-f38b3cb34243"], "ac7793c5-60d7-47f8-a704-90aea802aed7": ["7ac38cf8-1be4-4be2-a29d-f38b3cb34243"], "7f78b0fe-cc1d-423b-ace7-dc4179078d4d": ["94df81ae-d453-4fd5-9f6f-8201e5edf6d0"], "b9a08058-39c1-4c74-a070-91eae0b12a4f": ["94df81ae-d453-4fd5-9f6f-8201e5edf6d0"], "d5323090-6d6f-446b-ae47-a1d9baa5c081": ["001f9013-d806-44c7-a09a-88f5705e3c95"], "4dedef7a-a584-455b-857f-343db1a59f92": ["001f9013-d806-44c7-a09a-88f5705e3c95"], "fc957c78-6974-4abb-a1fd-7e88803c1659": ["590cbbaf-ffbf-4aa0-96db-3ad50207c739"], "99df1e94-f2b9-478a-8448-dc33cb266b5f": ["590cbbaf-ffbf-4aa0-96db-3ad50207c739"], "3aa5df95-e5a0-4286-8e88-4836bfbbcdc0": ["a3f392f6-8d4b-435c-a168-b6ed2284510f"], "eec8cc8a-54e1-4194-a888-2034b26916ce": ["a3f392f6-8d4b-435c-a168-b6ed2284510f"], "b7eb08df-39c4-4721-b0e4-9001abdb8ca2": ["c26e6566-e2d6-41d7-947f-4082567b1645"], "77b659b4-1b8e-4324-9fd7-c277d59c8474": ["c26e6566-e2d6-41d7-947f-4082567b1645"], "75fc0622-1104-47d9-8af4-dfe76939abaa": ["339a9678-f5f2-4f08-b4fc-72ba57bfa24e"], "ed644c24-adc9-42c2-9a5d-34fffc7e2014": ["339a9678-f5f2-4f08-b4fc-72ba57bfa24e"], "975a212f-fef5-4125-8848-f6cc20a8fc93": ["cfc2824e-fc30-414f-8a83-8990e776981d"], "92282249-58d3-4416-bf25-bcb63cb12cae": ["cfc2824e-fc30-414f-8a83-8990e776981d"], "0ee4436b-15a9-4d2d-b316-f07b4d6f86d5": ["c3fa6ae1-d5cd-4e90-acfd-c200818d5b5c"], "cb86aaae-8577-4b65-b35f-b9a6b1322c60": ["c3fa6ae1-d5cd-4e90-acfd-c200818d5b5c"], "f16c11fe-118d-48d1-b285-dfc88fe57f49": ["ab419f41-670d-4306-be20-e1c9a1051027"], "9e2f1fac-e054-4d81-b17f-63f109e07466": ["ab419f41-670d-4306-be20-e1c9a1051027"], "24487d5e-f936-4aa7-a592-1793df2585f1": ["ca41c82d-7d81-4a87-af76-370aa39c7ef5"], "26718fbd-55f0-4633-a141-d13440a6df51": ["ca41c82d-7d81-4a87-af76-370aa39c7ef5"], "a44625d2-ee3d-4701-b1d2-7e4f53e38644": ["79ee0771-c7c3-404c-a347-ac22684f44bd"], "b43cb095-4afa-4d9b-a743-943ab103c7dc": ["79ee0771-c7c3-404c-a347-ac22684f44bd"], "387d16f7-e55c-4e8a-8078-227d6611aced": ["83e0fe65-3c07-4a7c-a265-67f78a7baed0"], "e3fb2593-08d6-4683-948c-a5402f663583": ["83e0fe65-3c07-4a7c-a265-67f78a7baed0"], "2d6d3cd1-8871-452c-a6de-3107a70eb4ac": ["e7997965-0254-4999-b856-0fd6a21cc5d0"], "c7ac3186-9be3-4d28-ba99-fe7242a3b8f2": ["e7997965-0254-4999-b856-0fd6a21cc5d0"], "77383788-89b0-491d-b928-e749ad4ce4c7": ["1ed43c88-f1b9-4f7f-abd0-81cf06f444cd"], "6346d44e-82d5-40ca-a8a8-6285c0ce9a36": ["1ed43c88-f1b9-4f7f-abd0-81cf06f444cd"], "239c55b0-8728-4013-a2b8-fc829b62dd37": ["d3d8dc3b-7f87-4548-ad2d-afbe0961431c"], "d63d1666-24f9-41b1-9a60-f37f46d46513": ["d3d8dc3b-7f87-4548-ad2d-afbe0961431c"], "85bdd22f-225b-417e-a1f9-87b31f9dccc0": ["e9c1187d-8c84-4bcc-a920-02a23bc346ce"], "ae2b6484-60b4-4fc9-abcd-9ca42114593d": ["e9c1187d-8c84-4bcc-a920-02a23bc346ce"], "c4b5543a-7d6e-45d7-ab51-666b8b48beaf": ["cec6da72-ff6c-4a2f-bb3a-19f9913f6531"], "c6e5a3c3-b702-401a-9583-4668144eff4d": ["cec6da72-ff6c-4a2f-bb3a-19f9913f6531"], "b7fbacf4-38ea-426d-b6e9-dc77d503d6c9": ["9f1cc654-bfab-4767-ae0b-9ddde8438a98"], "e0edbf9f-1c89-4162-9517-cea42e7e4095": ["9f1cc654-bfab-4767-ae0b-9ddde8438a98"], "eee8920f-fb61-4ea8-a30e-9f601adf6ffa": ["01758ed1-699b-4a12-a34a-1e057238df65"], "84a19560-f086-442a-94c3-aa00e97a0058": ["01758ed1-699b-4a12-a34a-1e057238df65"], "378eae45-1c5a-4e2b-8376-b61712e9375a": ["7745fce1-3274-44b2-a933-08919b3d4408"], "7e0fe01c-1f05-4d4d-8c0a-cf8e41e3ed7c": ["7745fce1-3274-44b2-a933-08919b3d4408"], "4b30af55-8c6c-4709-a790-70646f413c5b": ["caa96f9a-0685-47c7-ae68-743c98d7b0d3"], "fee326e9-5fb4-4aef-9937-9df01d8eeb9b": ["caa96f9a-0685-47c7-ae68-743c98d7b0d3"], "e20d343c-9547-4073-a5cc-99bdd64acbf5": ["49a1d424-d1b6-4ee3-8b59-36dbc79d0943"], "22339da4-e28f-4563-acd0-82318f4162bb": ["49a1d424-d1b6-4ee3-8b59-36dbc79d0943"], "d4cfdcba-cff9-43f0-9191-817dcd174a94": ["f4142adc-0420-4531-b5e0-4407cbf61b62"], "d076ccc2-81f8-4f19-9dbb-4d51d07b7e15": ["f4142adc-0420-4531-b5e0-4407cbf61b62"], "260139a5-3e7d-45d3-a9bb-f434614251aa": ["337d986a-3c9f-406e-bc0f-57c9e46332ce"], "01722004-d524-41cc-93c7-d8b03e4ae4ef": ["337d986a-3c9f-406e-bc0f-57c9e46332ce"], "0748ff61-68f5-41ba-815e-0b191943e4ab": ["9b8493c3-42c4-4670-bc90-562cbd9fbd2a"], "9ca5e319-4c96-4a89-bb4a-b1a20ec2861b": ["9b8493c3-42c4-4670-bc90-562cbd9fbd2a"], "14022269-ea75-4d36-9988-6fd604f5e26a": ["417fa0f5-a350-4ad7-8f38-a5b2d925e2bd"], "3f4bcb61-7f13-4ee6-a3e6-7c564f580348": ["417fa0f5-a350-4ad7-8f38-a5b2d925e2bd"], "c8091eba-ef4d-433b-bcf7-ccbe5f9040cd": ["e612e2cb-fcd5-4d4c-be6a-2065f5bdf802"], "f2bb8b60-0290-444a-a722-7f547269040e": ["e612e2cb-fcd5-4d4c-be6a-2065f5bdf802"], "98948c3f-d420-4cb2-83cf-a797052f80e6": ["79f4b807-456d-4a60-ab31-c22599bf60af"], "defe2607-d4b0-43c3-ab4d-c69c20439287": ["79f4b807-456d-4a60-ab31-c22599bf60af"], "05137c9e-7640-4feb-992f-2e3664f32bbe": ["c301569e-1326-428a-8c93-19fe6cec8432"], "50453581-c57a-42c8-9db5-c540df9d1083": ["c301569e-1326-428a-8c93-19fe6cec8432"], "0aead898-5597-4edb-af6f-cbcdee0810de": ["5bd8ca16-dec4-4393-b00f-94aa6262a21c"], "128a68bf-00f3-4d32-9c24-3e8f09cd28e8": ["5bd8ca16-dec4-4393-b00f-94aa6262a21c"], "6fe9299b-65a8-4701-b1af-6edfc5e8d296": ["5bef627a-6954-468c-94ed-e4c913852659"], "260f7dd4-2172-4f32-8d72-4f3d5fc824c2": ["5bef627a-6954-468c-94ed-e4c913852659"], "cfcd2f97-95d7-4b18-b1d7-dc0cb7e3a753": ["5e75677a-1bde-43bc-9b7e-c77cd8b769c3"], "8f07c5bf-469f-4342-bee3-f976483a5a07": ["5e75677a-1bde-43bc-9b7e-c77cd8b769c3"], "af2a6dbf-2c8b-4b50-ab48-1b1b0bb6b934": ["3ee91061-54c6-400a-9340-9257e1432685"], "0e9554e5-afe3-45c8-8f08-2d4250579e1b": ["3ee91061-54c6-400a-9340-9257e1432685"], "ec06b05f-932c-4f36-886a-f606ef99a7ff": ["457eaf9d-cc6d-407b-958d-241a13a65f47"], "d5221de0-22f0-46c9-b8e8-953ac7f97a57": ["457eaf9d-cc6d-407b-958d-241a13a65f47"], "0a16e9cf-c47a-403e-bd71-99cab1363cea": ["30660f82-2d89-46a6-a3fd-3bf67a9776d4"], "10dc30eb-a600-41ef-ad4e-fd300108d622": ["30660f82-2d89-46a6-a3fd-3bf67a9776d4"], "0fcea0d4-97f4-47b6-8ab1-19c5f5c571b2": ["60167c92-dbd2-494c-963b-3f31e181a800"], "feda4622-d65f-476a-9967-b45cad2d1353": ["60167c92-dbd2-494c-963b-3f31e181a800"], "44cf5a79-5cbd-4e04-8869-ec62cb1d406e": ["1efaf9f1-7365-4988-8b93-849ff3a01745"], "64c02a6a-ae30-47ce-bd1d-9e77ffb8c934": ["1efaf9f1-7365-4988-8b93-849ff3a01745"], "33275b8b-11d0-4d50-a605-ea200aeadd21": ["60a8208e-9df7-4421-a9ec-3c4297faf861"], "f4bf7390-04a2-4f50-bcdc-36f66aa12d41": ["60a8208e-9df7-4421-a9ec-3c4297faf861"], "e8091260-c92c-43cc-8b15-f4ddd413a2f2": ["6787b150-12d1-4559-bc54-1c5847f73b1f"], "8e3a176a-4dcc-4b5b-8512-cc18db8fae54": ["6787b150-12d1-4559-bc54-1c5847f73b1f"], "58c850ab-8879-40ec-840c-1afbbfb65968": ["5cae1fe9-118c-44f9-8320-1a5b5b433a73"], "3252fc4a-3f77-431f-b677-92f55b71b5cb": ["5cae1fe9-118c-44f9-8320-1a5b5b433a73"], "ad6161da-245e-4e91-8dc0-8a7378bc6f4d": ["7b2946e4-8724-41bc-ae7d-ff2996cda535"], "ad266a00-749b-40fa-b385-f0c00af2a247": ["7b2946e4-8724-41bc-ae7d-ff2996cda535"], "44377fe1-76e4-4117-9b76-72fb60cfb3f1": ["ea0df4dc-3898-4aa4-8384-6c0d41db63a0"], "a0bbe061-13de-43ab-812a-1f3b967e4504": ["ea0df4dc-3898-4aa4-8384-6c0d41db63a0"], "20b5bca8-a57c-404c-88e7-62c675449ba1": ["36f37833-bacc-4484-bc9d-04c7dc93017a"], "3f43fea6-7153-4ce4-a026-cdf06b23b90c": ["36f37833-bacc-4484-bc9d-04c7dc93017a"], "fe502be2-b7a3-42f7-ab2f-c5b022164d17": ["155eb125-4e17-4ad2-93e5-3e8313f40a5c"], "9567e7ee-1238-4168-98ae-11edf4824567": ["155eb125-4e17-4ad2-93e5-3e8313f40a5c"], "fcee5a9a-ae21-476a-aacf-4ba1724d9ace": ["02ce6c37-80e8-4097-9888-6168118c69b5"], "8f038bf6-519f-4100-a4cf-b229e801aac9": ["02ce6c37-80e8-4097-9888-6168118c69b5"], "25e5731c-73e5-4d33-8d75-fac6b810a91c": ["bd772a34-6072-412f-87ba-034f08540e91"], "ca446694-1b6d-49b3-a7f9-f61db9add940": ["bd772a34-6072-412f-87ba-034f08540e91"], "fc82102c-9b26-444f-a9a8-537d97a67afc": ["191339c5-cc5b-4e71-94b1-d0c5c66e1188"], "2dce3bae-03bb-4c6d-8e2f-e37f363a1b2e": ["191339c5-cc5b-4e71-94b1-d0c5c66e1188"], "f50c06fd-ecd3-41dd-8418-67e3179c261a": ["8521c116-063f-4dc9-ab60-8d337afe6acf"], "31ad489a-3696-4fcf-8a82-f2d4051b5652": ["8521c116-063f-4dc9-ab60-8d337afe6acf"], "4e3b8ce9-f7aa-4df2-96c8-e2bdc7dad4cb": ["df5e7404-a205-4f8b-bbd1-1690e139c827"], "ebd69ef9-d1b0-457f-9397-c20a72afbf20": ["df5e7404-a205-4f8b-bbd1-1690e139c827"], "4154d15a-6499-4dff-91eb-575bd18e17b6": ["32f73e05-b05b-4f35-8eed-8b316d048ef8"], "378582b0-a7e6-48af-a418-59816de61d15": ["32f73e05-b05b-4f35-8eed-8b316d048ef8"], "992773b4-2991-46ac-9b92-8059f956c5f7": ["77e7e5a7-e286-481f-8375-3aaeed4fe8be"], "25ef1744-9265-4ee4-8b06-41e5cc3b18a1": ["77e7e5a7-e286-481f-8375-3aaeed4fe8be"], "f17af81a-470d-4b94-84a7-7b3ea0ef0a8a": ["1bca70bf-cead-4810-aed5-edde21e17460"], "185402b2-a325-406b-b0b2-22cc04de4146": ["1bca70bf-cead-4810-aed5-edde21e17460"], "dcd91941-ba09-47c7-b5e3-9fdfc022a783": ["564201ed-4586-4d13-a896-9ecfb1f153bd"], "4837d867-7e55-44dd-a579-1b29540a3bcb": ["564201ed-4586-4d13-a896-9ecfb1f153bd"], "43a3d4e2-8525-4b96-84f5-60368f572518": ["b44b4bce-f81d-41d1-8be0-b23f0f18666f"], "2cb10044-c665-41c9-acd7-901abf606c49": ["b44b4bce-f81d-41d1-8be0-b23f0f18666f"], "952b6b2b-6cd5-410a-b2ba-8363af36f58f": ["02834885-face-4975-ace5-cf3d57f9ad7c"], "34a7049a-a0d0-4782-94c5-d68d7dd31de4": ["02834885-face-4975-ace5-cf3d57f9ad7c"], "4976207a-7204-43d2-8118-382f7a10532e": ["1394202f-d8a8-4e19-a59c-4c9f9fb6fb62"], "b6fe5356-47e5-4d44-b0d7-c0d913be6fca": ["1394202f-d8a8-4e19-a59c-4c9f9fb6fb62"], "046fc834-ddad-424a-aad2-65ad80ff371d": ["d2344fb5-011c-45ba-ace7-1acb88f63018"], "0e840111-bb92-4409-8025-206307af9805": ["d2344fb5-011c-45ba-ace7-1acb88f63018"], "66285d26-619d-49a3-87de-2ef51c90c97f": ["2ee4282d-942e-40cd-bdea-4fb3e6e68afc"], "1a92ea19-ea32-47f4-b8ae-8eb5ac844b8d": ["2ee4282d-942e-40cd-bdea-4fb3e6e68afc"], "3002a41a-b82d-4206-94ac-a2f2c3a6fe56": ["f291b814-691c-4171-8a1a-9afa5860f45d"], "06fb85c3-a7a5-4785-a580-ab810f6cf834": ["f291b814-691c-4171-8a1a-9afa5860f45d"], "001ff0a4-5877-4093-b183-987cbe2abf4d": ["36dbb9c4-f30d-493e-8275-80ee701af8c6"], "b5b16f53-163b-4185-8e12-5163124eb0a0": ["36dbb9c4-f30d-493e-8275-80ee701af8c6"], "e80b1947-e4e6-4650-8fa5-70ec0c0fe034": ["80f98fe0-e885-4096-8094-82b771b77ca2"], "762492d6-5a22-435e-86dc-cd361c5dac6a": ["80f98fe0-e885-4096-8094-82b771b77ca2"], "09550520-0191-4e3e-9b22-142500bba2d9": ["059d3c70-5315-477c-8bdb-406f2ec09817"], "5a3f596a-6699-412d-992a-defc0809ceae": ["059d3c70-5315-477c-8bdb-406f2ec09817"], "2394ffaf-eb59-4bdc-b750-cdf78619f5ec": ["6ea62602-dc34-4794-ab50-6b22af1ceeb8"], "e3c89cd5-177b-445d-b14a-079a0e00841c": ["6ea62602-dc34-4794-ab50-6b22af1ceeb8"], "a18daa82-00fa-4a44-8cb0-952373f9d5f5": ["9b9c6e72-1784-4e5c-aa61-2a4cea8346a0"], "e2366176-bb2a-4b1a-841e-3c11c530668a": ["9b9c6e72-1784-4e5c-aa61-2a4cea8346a0"], "01ab90b7-d1be-4d5d-93e2-63554a2d3a40": ["c6bf671c-cd26-4d32-86e2-37441df870b1"], "9e2ffe59-fe64-4a7f-b90c-b0003fb2f9f1": ["c6bf671c-cd26-4d32-86e2-37441df870b1"], "7a6e3946-854c-4517-9978-da4b0db5d94c": ["9796f896-a283-4e02-ad1c-d8b665f7e361"], "605a5e60-dae0-477c-8682-76882e7e75b6": ["9796f896-a283-4e02-ad1c-d8b665f7e361"], "fe445912-0231-4cab-bd24-bb215399f0b9": ["b8938228-dfeb-43a4-95fb-fb5a1221ad8a"], "8fac1e57-864d-4fa1-981e-a3c6a7fdde0b": ["b8938228-dfeb-43a4-95fb-fb5a1221ad8a"], "8a1efb5f-b2d4-41bd-8eb3-9e488b9c5d18": ["895ae1bb-1256-45f1-8af5-ad9f2cd32b17"], "22d8ba5a-bcbd-463c-a488-816866358e6e": ["895ae1bb-1256-45f1-8af5-ad9f2cd32b17"], "93d8726e-a6f0-4d45-a6d1-41731ce3e05a": ["e257e1b1-536e-421b-83a1-6b9ae1db2a28"], "5a45e402-f2b3-47ed-96e9-02705cfc87d5": ["e257e1b1-536e-421b-83a1-6b9ae1db2a28"], "eca7b312-d8a2-4311-9017-07b0b5e56b93": ["e55f8c90-abca-42f1-afda-3249c25a3618"], "0e571312-f9c7-4752-9002-0405cb2bb0a4": ["e55f8c90-abca-42f1-afda-3249c25a3618"], "89a176e3-df57-4792-a648-b2abeca915a4": ["9768118e-cf92-40c4-88d7-bc37592a721b"], "3904fb02-e9c2-4060-99c6-9e0433ee2d0a": ["9768118e-cf92-40c4-88d7-bc37592a721b"], "1c914045-a993-40e7-8c30-04baa540d60d": ["85fc5b68-07f0-4ca1-ba53-9f11d4d22521"], "2c023338-54aa-4e76-82ed-758897e7e44b": ["85fc5b68-07f0-4ca1-ba53-9f11d4d22521"], "a69e9d06-2a4f-4752-bc72-15c68d003c6b": ["1272b39d-6e6d-47a2-b666-aa68ea0fe1e1"], "3dc75c43-c19e-48a6-91e3-78f949db44eb": ["1272b39d-6e6d-47a2-b666-aa68ea0fe1e1"], "41065a5c-5cfa-437b-9961-7890c386f90a": ["f2accb27-f20d-4396-a080-75175060f834"], "a1007b8e-4966-460e-8479-302da9aefbea": ["f2accb27-f20d-4396-a080-75175060f834"], "3587e733-81bc-47c0-920c-7f9c20cb1b73": ["36fa8d95-eeed-4c31-8c1d-0a7261886509"], "d8bc7a39-d8b5-40f8-bbad-2757524f1a63": ["36fa8d95-eeed-4c31-8c1d-0a7261886509"], "9c9e7bc7-4df9-40ff-b9d2-66a57b9a4da4": ["0cef9333-d5a1-472b-b126-7f72a2929eab"], "9d776712-5caf-49b5-a0ee-1deb9c089a40": ["0cef9333-d5a1-472b-b126-7f72a2929eab"], "b53d81ba-959e-4f88-9926-de966a1294ac": ["ed7641d8-3327-4749-8851-83aa0f899e1b"], "353aa795-f3ec-4c5c-9119-984a7c74ff89": ["ed7641d8-3327-4749-8851-83aa0f899e1b"], "168e288e-dd6f-49ad-89de-56e87885ca7b": ["a4ac73a1-0d42-4c6e-bdb4-b7cca071f9bf"], "f5abd789-a0d9-415d-8682-1105dbd81968": ["a4ac73a1-0d42-4c6e-bdb4-b7cca071f9bf"], "67c5c5ab-4f38-45cd-8866-04a158294507": ["de0ff031-b2aa-4d3f-b605-b6ebe8d3146e"], "0e5f22ed-073b-4d2b-8d4c-e450dca94f97": ["de0ff031-b2aa-4d3f-b605-b6ebe8d3146e"], "4c451868-283b-4e49-a4c8-09a506238432": ["2dddb78c-a2e8-4459-8024-5dfd638b3e9b"], "3604df64-bbff-4c12-b418-de489d5dab0c": ["2dddb78c-a2e8-4459-8024-5dfd638b3e9b"], "f3167d71-f4cf-49d1-af3a-7422fd2c0594": ["9a0b4f76-1cad-470d-b14f-aa094811e7d9"], "5e702a71-fc4e-49cf-abde-d6a716943b5b": ["9a0b4f76-1cad-470d-b14f-aa094811e7d9"], "a438f42a-3086-42f3-8a49-42abaf5d34b3": ["937db36c-ff0d-494a-9df4-66218305d23e"], "ac97e320-c03e-4454-aa37-fb32904f2552": ["937db36c-ff0d-494a-9df4-66218305d23e"], "2e2bc17d-3103-4950-92b5-ba10d3c7ee18": ["9499c4f5-baa0-4b1f-ae86-05ae1b53c902"], "e88181b4-4432-480d-95ba-a7dde648b2b1": ["9499c4f5-baa0-4b1f-ae86-05ae1b53c902"], "ed39ecc2-b783-4a52-949e-5b0e842bceda": ["8b5e9910-4644-4461-be63-4a60d3792fd8"], "232b6d9d-c5b9-4b30-aa2f-ad7cd6d9164e": ["8b5e9910-4644-4461-be63-4a60d3792fd8"], "249929a6-58b5-459f-8c52-9628e3b7b63b": ["ad2fdff1-2d80-4fab-a668-a069b3d3580b"], "b88290d6-a49f-4240-b57c-11459a59677b": ["ad2fdff1-2d80-4fab-a668-a069b3d3580b"], "fd451664-5428-4dc8-b3e4-936e4b31b41a": ["54e02784-dbf9-4e8f-a8a6-a83e79263bfe"], "bbeb58da-3994-4c78-b6f7-65ce5fa3c465": ["54e02784-dbf9-4e8f-a8a6-a83e79263bfe"], "9a3e32fe-5879-4da4-a0e9-9232c4a628b0": ["d4ee39d7-5357-4426-a2f0-e6a3cad8b039"], "6dfb1435-6402-45b1-ad69-6a245e4ba3ad": ["d4ee39d7-5357-4426-a2f0-e6a3cad8b039"], "f8ecddf8-ad53-4908-a522-22235dcc866d": ["c95375c2-2f67-4a96-89b5-58ed18eee638"], "d329f4d2-7b4b-4c8a-82d2-59e294d3b928": ["c95375c2-2f67-4a96-89b5-58ed18eee638"], "95d5dc10-8724-443d-969e-b8d33f7a17a3": ["53b1aca1-e2d7-41fd-956f-dc4f8aa0f9dd"], "1531e01c-8dae-4edb-b08c-e361586fbb6b": ["53b1aca1-e2d7-41fd-956f-dc4f8aa0f9dd"], "bd9cac00-116f-4d0f-b0e7-dce1119b9b76": ["9c2d829a-3c53-42d0-bdcf-05e7a4905af3"], "f9ea52e2-6d0c-43b0-81b7-bcbb7d07f127": ["9c2d829a-3c53-42d0-bdcf-05e7a4905af3"], "03a3eab1-7023-489a-8983-ca7fb742a940": ["41bf260e-3300-4502-8f29-e692ad5caf1f"], "a98f6f04-a113-457a-8068-896fee5529b8": ["41bf260e-3300-4502-8f29-e692ad5caf1f"], "ad8e8fbd-741b-45dc-96c4-79c64a818cdc": ["fb5be542-830c-48a6-a905-68a6823b56b0"], "ba774841-6a7f-4e2e-bb65-8d45925e75f0": ["fb5be542-830c-48a6-a905-68a6823b56b0"], "21ae7cf2-34e1-4f53-bbb8-f786457f6901": ["c4c1c089-0de8-42d5-92b0-c3a3cd99b15f"], "684d0489-4dce-40da-973e-35452c6efba8": ["c4c1c089-0de8-42d5-92b0-c3a3cd99b15f"], "353ae25e-224f-455d-872e-c3fa012038f5": ["ca9d0e33-f428-48f3-931a-7d3942b13320"], "5288c627-b89e-4d7e-b9f3-9c9fbf7d34b3": ["ca9d0e33-f428-48f3-931a-7d3942b13320"], "6e786805-092e-433c-aae8-9a1c6eed5961": ["c141386f-2ea3-441d-9d7a-c7f039acd879"], "8feb5d6e-6e09-4f53-b1ea-901ecd3dfedf": ["c141386f-2ea3-441d-9d7a-c7f039acd879"], "20868ef2-0c59-4ac4-9282-6a07200a2a8d": ["e3fc9d0d-cf94-40ad-acf2-dbdad4a97188"], "5f8bc318-78db-4d5b-946e-288d67e057cb": ["e3fc9d0d-cf94-40ad-acf2-dbdad4a97188"], "868e67fe-727b-4267-884c-fc0cc7caa09d": ["1d158095-1a03-4e45-9a4c-ca965c847edc"], "e01879b4-183b-4c67-9514-a5b2bd07c77e": ["1d158095-1a03-4e45-9a4c-ca965c847edc"], "b705d103-9346-452f-ac3c-4354efb64d2b": ["f387aa5e-f051-412b-af3b-3731ab385a6d"], "0f752dfb-e06c-40d7-8ab3-d3b400341151": ["f387aa5e-f051-412b-af3b-3731ab385a6d"], "a4c8c8b3-27fd-439c-9f38-30a3ed3ee746": ["4d0f658a-ac8a-49e2-9327-812db1e0e23b"], "c19c1cc5-de5f-48eb-9356-cd81cdffef72": ["4d0f658a-ac8a-49e2-9327-812db1e0e23b"], "66494484-94fa-43eb-9748-8e0211cd7bf1": ["929a108d-4fd7-4484-8efd-13d00b6dc989"], "06395dbf-9875-4064-9b6b-dc0b3aa52922": ["929a108d-4fd7-4484-8efd-13d00b6dc989"], "182d614d-8dc8-4a63-a16f-960bfd228523": ["32fac763-65e3-4391-9ce9-90c2315fd9d4"], "afe0c956-44fb-4001-88d5-8a6fdafc20da": ["32fac763-65e3-4391-9ce9-90c2315fd9d4"], "5a94ac37-8166-4f0e-a923-8303dac16a3e": ["93697f59-d0d1-44dd-9e79-da8afba99331"], "fdb2b4f2-7ba4-46b0-8692-86101e9380ec": ["93697f59-d0d1-44dd-9e79-da8afba99331"], "dbc10ada-4086-4c76-9ffd-64515325728f": ["dd4c5874-9148-4745-9d48-5e4ca04474ce"], "3cb7983b-7989-4697-b853-154e17adfc6d": ["dd4c5874-9148-4745-9d48-5e4ca04474ce"], "bfdf7e0e-d15b-46e1-8ca5-d85f99577d5c": ["e3fd901e-357d-4b1f-af5a-ccb21232e3b3"], "fa458c20-5467-4157-9fa2-cd037edc0a74": ["e3fd901e-357d-4b1f-af5a-ccb21232e3b3"], "980233ab-89a8-497d-a459-44ddce47dfe9": ["86451219-1349-4093-8cb3-bea25e36c1c8"], "07677f12-28c7-41d5-acce-5dce94167091": ["86451219-1349-4093-8cb3-bea25e36c1c8"], "e742054e-0139-4116-b968-50675a3377db": ["4ea3b58c-574b-473c-8a8c-5e4506a3ea43"], "38090ee8-c020-4091-911e-3b3d4e930252": ["4ea3b58c-574b-473c-8a8c-5e4506a3ea43"], "7da3e9e2-6d33-4371-8cca-3d6dadff1ce7": ["9c02759b-f473-4941-aa64-8607897a0c4f"], "ff636ab9-b9bb-42fe-8d94-a72e6577e31d": ["9c02759b-f473-4941-aa64-8607897a0c4f"], "7d643c6f-c7d0-4961-b09a-cb382eeab677": ["c4adab40-585b-44f3-8b2a-51d4fd84a550"], "7b25bd79-e13c-43bf-9a05-f28b4b9bdbf5": ["c4adab40-585b-44f3-8b2a-51d4fd84a550"], "16f005ea-0a56-4b4e-8ac8-04c5fdcdb1b8": ["ca6189b7-21ab-4791-9291-4e5f5c7fdcee"], "05c813c3-1fad-40f6-9e89-410deb049c59": ["ca6189b7-21ab-4791-9291-4e5f5c7fdcee"], "4be30042-f927-467d-928e-703fe5a8a6d3": ["77b0528f-9d90-4f8a-9447-7d2ec7c46c92"], "5aa01b90-fced-4a9e-87fc-d30a4ca0e5b9": ["77b0528f-9d90-4f8a-9447-7d2ec7c46c92"], "de9c2ee4-d68c-42b9-a459-7fcbc717adf8": ["d4dea87f-2617-4f1c-be46-51b91ffc2c7b"], "62697d18-bf94-44a0-bcb8-98a77333f367": ["d4dea87f-2617-4f1c-be46-51b91ffc2c7b"], "f5296a0a-e949-4cb5-9583-dcb0b84a7810": ["d5076212-a26f-465a-b67a-c1cf3fb2b844"], "c9ce896a-f400-46ba-b6bc-5771ed6f30f6": ["d5076212-a26f-465a-b67a-c1cf3fb2b844"], "dbdc0890-c9dc-4070-adba-f4cb26049d48": ["871dc8a3-6efc-48c6-bf23-e53aa58a51f9"], "62ddead4-cefc-4030-ace5-7a790df8123d": ["871dc8a3-6efc-48c6-bf23-e53aa58a51f9"], "fb9e22af-687c-4029-b992-44c95effb1ff": ["117e0473-7d4a-4409-957e-4db24f4d0f1e"], "887c4816-5de2-4c15-8062-a35a72395621": ["117e0473-7d4a-4409-957e-4db24f4d0f1e"], "7014face-0845-45c8-beda-4df0ae436a3f": ["4d4a9f01-eaef-40fa-a282-c152d07b6c2a"], "aa0cdd24-3358-4bd3-b60c-e1c5a1671274": ["4d4a9f01-eaef-40fa-a282-c152d07b6c2a"], "4f10bd37-7af5-456e-be90-6f6cfd33ae16": ["22ec510d-46ad-42fc-aa25-797d3c6bdb0c"], "8a62c41a-5405-4c6f-8b17-0f12effff319": ["22ec510d-46ad-42fc-aa25-797d3c6bdb0c"], "929bb11b-28ad-466c-b6b6-15e6ab5da67e": ["8331588d-d14c-4a5d-8eb9-ac71dc9599b8"], "fa80aea2-d643-4f4d-89d1-78fa10825bf9": ["8331588d-d14c-4a5d-8eb9-ac71dc9599b8"], "661e735a-d6a7-4f82-b065-850f7700005a": ["20d46384-b267-4c69-815d-2682eecbba44"], "6bf08eb6-9c94-4e0d-a497-29e42eb72f95": ["20d46384-b267-4c69-815d-2682eecbba44"], "dc4b0766-3bff-4e90-a38b-14f90c123001": ["c3076c66-7f63-4ac2-982f-e4eb99db2802"], "e41fc621-9f8d-480b-973f-73551f6bd90f": ["c3076c66-7f63-4ac2-982f-e4eb99db2802"], "43ef8173-bfe5-4c58-9e39-abb227107104": ["ff44fa0e-a029-4c23-8a2a-2292f7582c0f"], "cbf99439-fa2f-4557-8c51-9b1f163727cc": ["ff44fa0e-a029-4c23-8a2a-2292f7582c0f"], "a5f04537-355c-472a-bfcb-0a2c74df3a6f": ["a9d93246-3fcf-4b3b-b3cd-2d61f11a4de8"], "ae770724-5d6c-477d-a930-8d4d2acd7029": ["a9d93246-3fcf-4b3b-b3cd-2d61f11a4de8"], "c707357e-b8df-43c5-8bd1-86ad9c9e3d16": ["8612d4af-9a3d-4137-9fa1-c3b206f0c50e"], "71dddf88-37e4-4d5b-a434-4a71d88ac1aa": ["8612d4af-9a3d-4137-9fa1-c3b206f0c50e"], "e9f912ae-a635-4ff2-bdac-5db06be39d65": ["64af9c2b-78cf-4d88-9a22-f95aadd0f22b"], "2537f072-2b3a-48ce-b02a-622d3cb9e46c": ["64af9c2b-78cf-4d88-9a22-f95aadd0f22b"], "227c46de-3282-4f05-b2eb-c3e35ac4026c": ["4a72c92a-02ae-494d-a157-b0c55a0d0c46"], "0bbc56dc-9cb3-4c1b-82b7-5ece8c458380": ["4a72c92a-02ae-494d-a157-b0c55a0d0c46"], "3bbda291-cedc-405f-8d74-4dd51035a807": ["80fa1877-4106-4d64-918c-815755213f1e"], "d67d9b48-86f5-4649-9633-add75575441e": ["80fa1877-4106-4d64-918c-815755213f1e"], "263888bc-6c5b-4c2d-9c74-022e430b8c32": ["ab42b592-7c0a-4539-8627-ef4474c8da16"], "abda5e5e-668d-41c1-98a0-a393327ca225": ["ab42b592-7c0a-4539-8627-ef4474c8da16"], "617558e3-627a-4bbf-8a13-3e6d25cef463": ["ca9a2c0b-b3eb-486c-b23e-970ea26ca3dc"], "fa52b8a5-eb19-494a-b68f-e2da9e7f54ee": ["ca9a2c0b-b3eb-486c-b23e-970ea26ca3dc"], "2da8a740-e120-4c66-a6ef-f72114a9a802": ["5a612712-29fb-4831-9aff-aed10fd5c196"], "4b4622a2-3006-41ef-8399-9dc5c2a3f8cb": ["5a612712-29fb-4831-9aff-aed10fd5c196"], "61487855-7b7d-4740-b7aa-395746e2b5d2": ["2cdb171b-0008-400a-8944-edd3008f2c06"], "4275b89e-3a7e-4a6a-9f56-f824334f58c3": ["2cdb171b-0008-400a-8944-edd3008f2c06"], "26b4c7c7-dc67-4e4d-8d8d-dff55e9abe44": ["d3f1eb44-2105-4506-80d8-5d3c67a9bb2c"], "92c2a379-3568-42c4-8bee-49a4205b6063": ["d3f1eb44-2105-4506-80d8-5d3c67a9bb2c"], "be28a0c2-846f-4707-877f-e7135ff70f65": ["1f95a910-874f-4ce5-9598-ae3c3a9f778a"], "57b5c032-efe0-462c-976b-21c696fcae00": ["1f95a910-874f-4ce5-9598-ae3c3a9f778a"], "875616ae-273a-4e7a-a313-10ebea0419cf": ["9df1a0a1-c582-4083-8d84-8c275d4ed394"], "0ac26bc2-a123-4a71-9948-38fafdd48dcc": ["9df1a0a1-c582-4083-8d84-8c275d4ed394"], "69ac2751-0e75-4cbc-812c-b68cb690774b": ["e94037b4-b43b-437a-aedc-6d11d3b8d3da"], "0fe6b401-f093-43f7-bbb5-66889006bdbd": ["e94037b4-b43b-437a-aedc-6d11d3b8d3da"], "a2fce441-0cd1-4224-b09d-05cd16512c44": ["b33cdf17-69bf-493f-a095-006e250f63ac"], "2f77a449-7aa0-4af3-a494-a9ec1d3b56d8": ["b33cdf17-69bf-493f-a095-006e250f63ac"], "1dc97abb-6090-4ecf-b57a-35a30fb9a28c": ["212e5309-27c4-46e0-a0c2-cb1c7ba883c8"], "733b1d44-96ed-4157-8110-5c79abc02f20": ["212e5309-27c4-46e0-a0c2-cb1c7ba883c8"], "84df0f9b-5053-4c04-9267-3bac77361771": ["0611f2ed-3933-4781-8496-91f6a9e2c053"], "a8f77b95-eaa4-4c62-9b28-60ec90356726": ["0611f2ed-3933-4781-8496-91f6a9e2c053"], "bdd907d3-90bc-4b5c-b2f8-22a14e2e4eea": ["57322dd9-0f28-47a1-96b9-82a4fb46ae9c"], "7d6a4a7f-529e-4eeb-bc5f-dfed19a4836f": ["57322dd9-0f28-47a1-96b9-82a4fb46ae9c"], "379409a7-11a5-46f8-a922-f01822752245": ["158ef2f4-a985-4568-8140-1c10a19a16ae"], "5038d784-f939-44ff-8421-d957b6a2ef5d": ["158ef2f4-a985-4568-8140-1c10a19a16ae"], "f825e730-70d6-45e7-a991-d84b70dedbdc": ["1d384063-9796-4e43-b68a-a6f4a585635b"], "983fa531-c273-4f2e-8412-31414dfa2427": ["1d384063-9796-4e43-b68a-a6f4a585635b"], "0431f0a4-1c06-4193-b56e-8f1954b1bf6a": ["fe46bbca-da69-42c4-bd66-20a39c3a69a8"], "01bb100e-f860-400e-a49e-bf3326ff3b88": ["fe46bbca-da69-42c4-bd66-20a39c3a69a8"], "732298cc-a7cd-4afd-aaa0-156689318281": ["1f866a62-f886-473e-8beb-79265e963505"], "49171449-883d-4c0c-bf2e-bd800c4b8a73": ["1f866a62-f886-473e-8beb-79265e963505"], "b2bf3d18-362b-4c00-8fc3-7a3aa226d22f": ["a78624b2-fcde-4ba1-83eb-bf3d7b3eca6c"], "f7041767-28f1-4cbc-be37-2d9215a3f908": ["a78624b2-fcde-4ba1-83eb-bf3d7b3eca6c"], "2d426057-d7ae-460b-819e-c2a8e32c316e": ["2c200e89-561c-4595-855d-6c138482ee24"], "084682cc-e738-4536-b480-4ff210f8ebc1": ["2c200e89-561c-4595-855d-6c138482ee24"], "56014d00-cca7-467c-890e-d1cea73d3e2e": ["cf84cf61-b70d-4e80-8edb-51a7986b90d5"], "b62d5388-f2a9-4dc8-a5f1-f65237eab5e5": ["cf84cf61-b70d-4e80-8edb-51a7986b90d5"], "51bda860-1005-4957-85c3-5c3494db2268": ["f2bb2073-d674-4594-9bd1-f11d0f570c5f"], "2a49441b-382a-4d78-8610-ab81b9b92095": ["f2bb2073-d674-4594-9bd1-f11d0f570c5f"], "e1e4f53a-b337-4f26-ac49-7cab55868102": ["dcf31fb9-043d-4218-babd-0d9f3fdb152e"], "37246c5b-bfa3-4e88-b39f-363a2745b787": ["dcf31fb9-043d-4218-babd-0d9f3fdb152e"], "f7715b04-2bf7-4733-bbb9-177cf53ac0ac": ["4402e59c-06c1-4bc6-971f-0c46eacd45a0"], "23cb44ce-136d-47f6-bf20-20a4c72c8819": ["4402e59c-06c1-4bc6-971f-0c46eacd45a0"], "db491d38-6e46-48a0-ae93-1f58468ec535": ["c9157761-f523-4ba8-82c2-f2eec26e39ba"], "b27eaebd-974a-4c14-be3c-c30042612cc3": ["c9157761-f523-4ba8-82c2-f2eec26e39ba"], "b3529031-625c-4528-984b-1b225d0ebf9f": ["36d92bd5-e77c-4d6a-985b-db9cec746655"], "7aaecc09-c051-484f-8f59-03288be6693a": ["36d92bd5-e77c-4d6a-985b-db9cec746655"], "77440e07-7a72-4e6b-80bc-454888f3684d": ["7100404b-f757-4491-a821-fcc66012136a"], "b9c9a65e-f5b7-41e7-b6b7-15485cdf441f": ["7100404b-f757-4491-a821-fcc66012136a"], "356bb6a8-9094-4e50-a284-8d6ff3a9b659": ["aafdac84-63af-4389-8250-100cca29a102"], "971a0a03-e3a7-48e5-a914-0763d20e61e4": ["aafdac84-63af-4389-8250-100cca29a102"], "9f7af070-2a14-421b-a2ea-01b90e59a12e": ["dac9109e-3667-4928-bfb2-f788f504237e"], "ee8f89f4-1125-415b-b45f-ecce7120ef2c": ["dac9109e-3667-4928-bfb2-f788f504237e"], "5fcc3605-d518-42b2-afad-7c3d5307c668": ["1a74427b-5479-4e89-8abb-c71ff8c57074"], "5b9edce2-2386-43da-a7fa-eb9d4e1dc866": ["1a74427b-5479-4e89-8abb-c71ff8c57074"], "b7b191f8-d54e-407c-833d-a59910bc2fc3": ["5a43d2ed-3c98-4a72-b479-a4883aa41fd3"], "1d5717ff-856c-483f-bb45-e9bfa86af9c6": ["5a43d2ed-3c98-4a72-b479-a4883aa41fd3"], "35020e63-ee1d-44c0-9cec-aaff1bc83dc2": ["19273e70-0dc7-4d9e-80e4-8ebea56bf851"], "700a27d0-fd9d-44db-b1e6-b1f6a1321ae3": ["19273e70-0dc7-4d9e-80e4-8ebea56bf851"], "004bc31d-e125-47af-9b8d-935ebdb245d3": ["19a8c5a2-0beb-4e75-8338-c40c1972fce2"], "d8ec5e9d-6254-4753-9e32-6d9cf4644335": ["19a8c5a2-0beb-4e75-8338-c40c1972fce2"], "0fdabd43-29e0-4431-97d1-26703e5ced15": ["72bd413f-eddb-4fda-a73a-d9cd18debd40"], "912370ef-6945-4672-b64e-35e0dd936bcb": ["72bd413f-eddb-4fda-a73a-d9cd18debd40"], "d555f200-a1bd-41d7-bb08-c55c709ef10b": ["175ba1ef-d1df-4129-8936-5f0cc3218720"], "520f5c33-c60e-4952-b4b0-81448a82d187": ["175ba1ef-d1df-4129-8936-5f0cc3218720"], "786fad00-f7ff-4ecc-800e-5164c6f2c8c8": ["0c3a7c3a-92ca-465a-a06e-172351783856"], "08b5b0df-0afc-42e8-ad8c-53b66f749264": ["0c3a7c3a-92ca-465a-a06e-172351783856"], "954d1448-4e8b-4376-b29f-4f60731c0a80": ["98d2b378-962b-4db3-9198-029a2c73e6be"], "98a79e92-2a8c-490b-9106-6a2131d839bf": ["98d2b378-962b-4db3-9198-029a2c73e6be"], "e0d51396-2dbc-4605-93b3-0b84d55ef15c": ["e2d7f3e1-ff81-45a6-a5c4-432398cd8832"], "fd06b7f6-0454-4494-91ec-ebd057e3e76b": ["e2d7f3e1-ff81-45a6-a5c4-432398cd8832"], "9d229864-4c98-46d1-bf94-5f82a4027b93": ["6cce1e4f-eb93-4880-be58-b09aeb712cbb"], "49eea1a9-360d-421b-9f53-bd4b133441cb": ["6cce1e4f-eb93-4880-be58-b09aeb712cbb"], "3e5bb9db-2f15-4257-91c7-10771c71ac85": ["33b59760-1515-48cb-abc2-d427006c0a3b"], "cd88aab0-6ccd-4d9b-947b-8d1ab3101801": ["33b59760-1515-48cb-abc2-d427006c0a3b"], "72cb5b32-d4ed-44f7-be99-04f2427297e3": ["de7bf04d-361d-4a01-8bf6-2acd9380375c"], "8c9879a8-b85b-4b26-82cf-2c4781491103": ["de7bf04d-361d-4a01-8bf6-2acd9380375c"], "458f2be6-4458-4a3d-a4e4-46cbdb34208d": ["c150358b-4e94-459f-900f-9815e2d6ccb4"], "c54d037d-03f5-44b4-b17f-5773115ce5f4": ["c150358b-4e94-459f-900f-9815e2d6ccb4"], "6c25d095-8f4e-460d-bfdc-1c00de18e98a": ["97818157-8e95-47ac-8996-1d7de467522e"], "06d23801-c0ea-436d-a3c4-9c0ae74a89ea": ["97818157-8e95-47ac-8996-1d7de467522e"], "beed923b-9632-465b-8945-6188e7417627": ["40f63228-9d88-4b07-92ce-1cf217d93ca2"], "f0b72c15-a5d5-4868-ba7b-f0841bef1f59": ["40f63228-9d88-4b07-92ce-1cf217d93ca2"], "51693b37-f0fb-4003-bc19-82044430a50e": ["bef03974-7c31-44cf-be99-9af8c09cff69"], "32d118c0-43d3-41d8-b7ea-5f731a11aa69": ["bef03974-7c31-44cf-be99-9af8c09cff69"], "26a57c8a-15a5-41bd-b361-5a3063a9039c": ["007d0d5e-206f-4fbd-9215-c3eccc2ccb16"], "9752d5bd-37b5-41b2-979e-ff6bf01cfef3": ["007d0d5e-206f-4fbd-9215-c3eccc2ccb16"], "82580fad-cc16-41dc-a454-0cd340cb542f": ["e19746c0-7a41-4d51-9cc4-f13c00d68406"], "aa722549-21c4-4a23-aa9c-791d3f502887": ["e19746c0-7a41-4d51-9cc4-f13c00d68406"], "63f6abc9-62fc-45e7-a660-0cc6c0b13d91": ["2041aef2-054d-4b01-87dc-259c0b37dd04"], "f67be9ce-c3f1-4287-b92a-b32b27f32a59": ["2041aef2-054d-4b01-87dc-259c0b37dd04"], "3bf60769-6455-4fe4-984f-dcba696b2361": ["0d5e7229-6e8b-4da0-b2cc-511429f50f73"], "9aae4761-e502-4163-9bc4-688f16fc6f6b": ["0d5e7229-6e8b-4da0-b2cc-511429f50f73"], "417b6bdf-4fbb-4063-8f7f-8e2701992674": ["18342763-e7bf-4866-9622-35cc0c82e105"], "16e59462-cdac-41e7-bc1f-268f6157185f": ["18342763-e7bf-4866-9622-35cc0c82e105"], "cc2eab1d-4bd2-4ea8-b85f-848435a62b78": ["9f104fa3-7067-4d07-b418-029a70b4b1a2"], "ad14de61-54ab-4819-8135-27811f223694": ["9f104fa3-7067-4d07-b418-029a70b4b1a2"], "3fd54119-7334-419d-93b9-81a81943cb96": ["fadfc9bd-69c4-46bd-ac7c-6980c5610cdf"], "2181f3db-4508-464a-bff3-47a13aa0f2eb": ["fadfc9bd-69c4-46bd-ac7c-6980c5610cdf"], "97eb2b86-5cb1-4067-8b3e-238ffe524dbe": ["c63ed0e3-e277-4b2e-b801-25aff67d59b1"], "f08c3dee-07ea-4aca-a552-23551165216a": ["c63ed0e3-e277-4b2e-b801-25aff67d59b1"], "8a89c0ec-05ad-42a6-80ec-5731b87da313": ["9743487e-5b7f-4e0a-a879-d7065bda1dc8"], "da91d205-0f53-48d4-aaa0-4652475a5669": ["9743487e-5b7f-4e0a-a879-d7065bda1dc8"], "d9f719ba-8a1f-4a79-9681-f89d004f5737": ["b2ee1df2-173d-4a98-8589-7831652e7dc7"], "e95df5e6-5ba1-4a69-9a59-00edeaadfc0b": ["b2ee1df2-173d-4a98-8589-7831652e7dc7"], "f933d896-f53d-48c2-90d8-294ea06404ab": ["e52f6cee-5a14-4c5e-94f1-4cabbbe82979"], "93a6e5b2-6563-4bad-b36f-76417d1b7957": ["e52f6cee-5a14-4c5e-94f1-4cabbbe82979"], "3faa9db4-95ac-41a5-992e-80b799e94d1e": ["9571ef0e-1693-4708-a141-33e3e22c88b6"], "44d6504c-a7ed-46de-8487-836032e6c09f": ["9571ef0e-1693-4708-a141-33e3e22c88b6"], "00b93ab4-597d-4aaf-8adb-24e047da7432": ["551c7cae-a6c1-4903-a574-9aa068bf6862"], "2d001394-e5e1-437b-99f9-18ff2f904852": ["551c7cae-a6c1-4903-a574-9aa068bf6862"], "73012a6f-b05e-409f-b7a8-3e723dcfef4a": ["234c07c8-8baa-4f07-9267-04ddec10d3e9"], "4f471ed3-bf87-4055-bc52-d3ede6c01552": ["234c07c8-8baa-4f07-9267-04ddec10d3e9"], "9be7480e-bc18-4330-b7a6-192eb8d3d094": ["c1ef358b-6aa8-43e7-b19e-3e4da5fb3de5"], "7466e7c9-8d04-43cd-8727-806c048d70e1": ["c1ef358b-6aa8-43e7-b19e-3e4da5fb3de5"], "ec6465db-3f03-4ee6-8cde-36da907acf6f": ["335c0645-b28f-4ced-9b6e-800aaae18c62"], "b8940ee1-5f9a-41f9-a976-85795854574f": ["335c0645-b28f-4ced-9b6e-800aaae18c62"], "d6a01d7c-873d-489c-8980-fc16c62b3f98": ["5066d454-f176-4e8c-b276-de95f057ae9a"], "166fb241-6f91-4d1a-8948-339f4f56d962": ["5066d454-f176-4e8c-b276-de95f057ae9a"], "ec28b524-df88-473c-bcba-bc62e415e0ad": ["c0627672-0f3d-4a79-9b0e-7fd49ff9979d"], "58a86d0a-e7fb-4536-bc96-117d497cfe9e": ["c0627672-0f3d-4a79-9b0e-7fd49ff9979d"], "08f6c04e-6be1-44d2-8d2b-266cceaa2bea": ["4adb9db7-387c-4af5-bbc8-cb5d08514d40"], "2bb117c3-a4cc-4704-a90c-dea986f1fc4e": ["4adb9db7-387c-4af5-bbc8-cb5d08514d40"], "87f1a12a-7437-47d9-9dc5-fb9cbc55599b": ["d713c31f-bccf-47a9-871a-a00e96ec8246"], "96913c42-c028-498d-8ce3-f55043c341a4": ["d713c31f-bccf-47a9-871a-a00e96ec8246"], "a52c8c8f-6d0d-41ab-aa89-321a392b8b80": ["dae6e160-6075-4060-beb9-ddde2378ce90"], "a9771743-0615-495b-ba9a-d4360bb74a2b": ["dae6e160-6075-4060-beb9-ddde2378ce90"], "305a54e7-47f5-464f-a20e-8aa5577d2032": ["6c17a241-76ef-4acd-87f3-509ee676aaa2"], "6d30af9e-5158-4291-8433-2ced6c8042a7": ["6c17a241-76ef-4acd-87f3-509ee676aaa2"], "fb5749e2-bea1-4ed9-a502-706a4b9bc3b9": ["d0becd04-0e95-4f50-aa14-250bd4d65f34"], "2294513c-d261-4c6c-bd49-df9f27255742": ["d0becd04-0e95-4f50-aa14-250bd4d65f34"], "baa4870b-f3a5-48ed-8cf9-9f92726e4105": ["508a6edd-35f1-400f-8d83-5d5914320c25"], "ed94b388-a541-4681-b726-394322950c20": ["508a6edd-35f1-400f-8d83-5d5914320c25"], "f596d7fd-0757-4241-b41d-32d393b7cf1a": ["54a1d489-f687-421f-8455-4a78f75814bc"], "d474d256-c67a-4127-9f02-d14eeb3ddffa": ["54a1d489-f687-421f-8455-4a78f75814bc"], "6c38a794-61ab-4649-a3a6-edce03d8acc0": ["cc45443a-58a2-4592-bf3c-8d5243666ed2"], "d0669463-cb91-458a-a746-f16e12625302": ["cc45443a-58a2-4592-bf3c-8d5243666ed2"], "f4d9dfe4-c111-4d37-b709-9f45bf4849c4": ["0d1c8a5e-859a-426e-a900-6b4a12e3a5aa"], "9ef8f338-7f27-437b-bad6-9ba96f8327c3": ["0d1c8a5e-859a-426e-a900-6b4a12e3a5aa"], "ef603791-797d-4ede-961a-3e88890b0590": ["8dcd6693-f972-429f-a804-add9bd825ef1"], "161fadd9-9d76-49e8-9bcc-96323e62c156": ["8dcd6693-f972-429f-a804-add9bd825ef1"], "90baba5e-a92d-492a-9609-cf95cb942c79": ["5a679e15-2cfb-45cd-8940-9d229c2de461"], "99b96a64-cc84-4a85-bff0-125a23188807": ["5a679e15-2cfb-45cd-8940-9d229c2de461"], "eff8c255-0e86-4d8d-9e33-c9051eab2260": ["dd01609a-0262-48f7-b686-4ba1a98ad6b6"], "2d18dbc8-2c70-48c3-ad45-9e35afb823ed": ["dd01609a-0262-48f7-b686-4ba1a98ad6b6"], "9da1eebe-bd9c-4c2a-88ae-afe9f9f832ab": ["bdcad5c1-2f9f-4d89-bd79-88fa9ce5ca07"], "4db9bf4b-8967-4add-b1ce-df46bacc26ae": ["bdcad5c1-2f9f-4d89-bd79-88fa9ce5ca07"], "eacf1e17-a149-4ff4-ab67-33ca8708eda2": ["752eb996-0113-447f-848f-fbf6b774fd54"], "5214d914-1f0a-4b9c-95f8-d68a34380192": ["752eb996-0113-447f-848f-fbf6b774fd54"], "fa030f8b-43ad-4eb4-8021-c1d1bf17bd2e": ["8fdab119-6819-4957-ae62-2cd19f5422af"], "55483612-9daa-4013-9d63-35487cf2245b": ["8fdab119-6819-4957-ae62-2cd19f5422af"], "ba16a05d-c693-4c57-8f68-caf13976352a": ["c905cd33-346d-471c-adc1-fecfd341271e"], "9108a1be-0851-4551-8abf-f48c57745831": ["c905cd33-346d-471c-adc1-fecfd341271e"], "76187161-7bf9-473f-bdad-52943f58630a": ["ca324670-5ba1-448d-a546-4c66c8e5059b"], "51c1162e-c451-467c-ab38-d04d925ecc7a": ["ca324670-5ba1-448d-a546-4c66c8e5059b"], "b1d55148-137d-4244-8383-336754a0e9ac": ["c81f26d2-a52c-415b-9348-a100446838cf"], "c9aa2c01-3093-4b77-9909-7b1164ef09bd": ["c81f26d2-a52c-415b-9348-a100446838cf"], "eb90834f-0717-4562-8c96-84c576041e08": ["c40d9e15-ef75-4d5a-a932-3ae367ebae5a"], "a1388208-65ec-45f4-8d15-40eed225e57b": ["c40d9e15-ef75-4d5a-a932-3ae367ebae5a"], "6d160348-a777-4aa3-a897-ec1e0936c1a0": ["d9ad80ec-df7a-42ed-95fc-3744c0586e1d"], "6a916ce0-e95e-4242-8dcf-6a0a1c9f9654": ["d9ad80ec-df7a-42ed-95fc-3744c0586e1d"], "9bf60638-6f9a-490c-860d-d0f869078488": ["7d77f570-3253-435a-ad0a-1cc8f1351be8"], "b4e90fbc-bbf9-4f4e-9be4-80c8c414ed98": ["7d77f570-3253-435a-ad0a-1cc8f1351be8"], "b28d2b18-9546-492a-a77d-97d079e9675e": ["cde65a9d-0d10-4de4-a075-17dc02be0540"], "857d547f-f6e4-4cf1-8273-1535a51dc077": ["cde65a9d-0d10-4de4-a075-17dc02be0540"], "6d471bbe-5906-4f18-92cc-cadfab11febe": ["d557b3bf-1dea-42a1-a781-0a890677e104"], "616bf44d-3c5c-4199-8f47-21fa9891a24c": ["d557b3bf-1dea-42a1-a781-0a890677e104"], "2911f142-5a22-4310-8c84-811d74956c2c": ["e77f7c42-045f-40c5-a66f-7a86c4825e2d"], "927042dd-6a23-4e8e-925a-30b18f418e8c": ["e77f7c42-045f-40c5-a66f-7a86c4825e2d"], "59e551e5-956e-4217-adae-e9728a4b092a": ["4c5deccc-9af4-4749-8d48-daaa87787534"], "2c797751-76c2-452a-bb2b-5d046a626e13": ["4c5deccc-9af4-4749-8d48-daaa87787534"], "5727e49b-f824-4ee1-8717-c69ace3d181a": ["6a2894a1-7754-43ab-84d6-838cf40df894"], "cac4b91a-ef89-4329-bda0-de1306184e94": ["6a2894a1-7754-43ab-84d6-838cf40df894"], "b71ac209-d228-4bc7-9ccd-baf21df11483": ["9c0416af-cd44-4efe-90eb-bb6732a2ca7a"], "b8315e29-7762-426f-8d10-aaef49f38d9a": ["9c0416af-cd44-4efe-90eb-bb6732a2ca7a"], "122b07a9-9fa9-45ad-a73b-9aec4cb5c08a": ["d04df1f3-70b4-43b7-804f-3d4bbd644072"], "a68160d3-0567-4343-a40f-7d89f0aecb0a": ["d04df1f3-70b4-43b7-804f-3d4bbd644072"], "6c0f3fe9-3d59-4bff-a72c-ac9594b178de": ["9af40c8f-e645-46e0-ad2c-01aadb72e30e"], "47d8c023-4e9b-4c7d-8fd5-666e04deeff3": ["9af40c8f-e645-46e0-ad2c-01aadb72e30e"], "0ea62a7c-c6ac-4dbb-a1a2-c6b86253c26b": ["b6d388d3-e9b4-4331-8845-f20e189df1b5"], "c4106a36-e5ee-47ca-a40e-51026ab777cb": ["b6d388d3-e9b4-4331-8845-f20e189df1b5"], "e79daf3f-c86a-45de-a8ad-ff4161513537": ["0a673722-599c-4f86-bfb3-fa0d5124264c"], "83fcaf62-6991-4387-a7d3-187b74487e42": ["0a673722-599c-4f86-bfb3-fa0d5124264c"], "714ed52e-e058-4224-9dfe-00dabe17db10": ["88f5a9e9-414a-4cc5-a233-02b5b1f3df77"], "c618d475-dc14-4be2-a23d-1c48370862ee": ["88f5a9e9-414a-4cc5-a233-02b5b1f3df77"], "6611077f-eedc-4bb6-a96a-1d4d786ab0c3": ["2d4b9a5b-d031-4f72-8ebb-3fc4aa60a1c9"], "41e73b94-9f1e-46ca-bb92-56e225c88ca2": ["2d4b9a5b-d031-4f72-8ebb-3fc4aa60a1c9"], "d10a9bd4-e4b5-4a51-8b28-26cd73189db4": ["ec56134e-1995-47e0-bcc1-3e00a48d2229"], "06e1aa92-d446-420c-885c-893376904274": ["ec56134e-1995-47e0-bcc1-3e00a48d2229"], "af10c236-ccc0-4eab-b631-dc58a43fbd43": ["d1337aff-43c1-45a4-9091-84095101cb65"], "66006e24-b009-4b20-b673-657f77dd250f": ["d1337aff-43c1-45a4-9091-84095101cb65"], "089e485b-34ae-4a3b-897e-04fba7415116": ["418543b2-ee33-4df9-8a3d-69789812a562"], "f85c37cb-b434-4bbc-93d9-db1ebed6ca5c": ["418543b2-ee33-4df9-8a3d-69789812a562"], "f5dce8ee-2be9-493c-bc14-c5b579e81d6f": ["3d7dc9d0-e3e1-4ac2-b7dc-cd94adbd2cda"], "5e08a1e5-1255-4e4e-b07b-aac1b71a7541": ["3d7dc9d0-e3e1-4ac2-b7dc-cd94adbd2cda"], "36f2cad8-3003-46c7-bd8b-e63232bdd010": ["8e2ccfdf-b551-4406-85b3-7ce2ba90d39c"], "e9f1d0e2-ef65-4867-8e57-79ea0c329423": ["8e2ccfdf-b551-4406-85b3-7ce2ba90d39c"], "b0b492f2-87d5-4804-b84a-2d4180354466": ["60ed1fa9-ab5c-4f1f-9936-246f7d980b34"], "8a6cd034-4f47-43fa-b296-386579efba27": ["60ed1fa9-ab5c-4f1f-9936-246f7d980b34"], "f6d6e8c1-7663-4640-9f07-deeb8b7b8e74": ["26e03b9f-ebdd-4bfb-8df3-cca92cddb723"], "9aaedae3-7d67-4247-aeb5-7b34b9304ac9": ["26e03b9f-ebdd-4bfb-8df3-cca92cddb723"], "945a7ce4-91fd-4bb1-b3f9-51c9eff03961": ["19fd319c-2994-4d81-bb9d-1ef855b28f8a"], "495097bd-f455-477f-90ec-87aec5446543": ["19fd319c-2994-4d81-bb9d-1ef855b28f8a"], "d7518a3f-1733-477b-a336-39510d569853": ["eba02204-359d-4556-930b-e1edfad72023"], "130a2170-3e80-4a93-8fe4-8c96367e34e7": ["eba02204-359d-4556-930b-e1edfad72023"], "b839d9de-29dc-44bc-8cc9-cd5a84f76f5f": ["f0d8a48c-79b2-4109-831e-044c35f0dba6"], "93cd906b-b7ca-4ff8-950f-c864a6ffe9ca": ["f0d8a48c-79b2-4109-831e-044c35f0dba6"], "2ad6d02e-d6a5-4c24-8b34-a123d193fd5a": ["715a5a00-13e4-4b9d-ac06-318c21f3a293"], "ac52fd98-ad98-4508-a21b-6a0f6d816f3c": ["715a5a00-13e4-4b9d-ac06-318c21f3a293"], "7bd39d7a-241d-4703-8cea-bbfca7733fc8": ["69b0bf44-5ca3-4a5e-a296-3f98016fa43d"], "7d9eb089-4c9b-4bc5-8dc7-cc2330e0ed55": ["69b0bf44-5ca3-4a5e-a296-3f98016fa43d"], "3778ab16-dd62-4119-a14b-6c5926550c44": ["491fc5eb-2ac4-46e2-bd56-532a8c2233d0"], "bc7dc686-b036-4398-a9b0-a3ccf302f926": ["491fc5eb-2ac4-46e2-bd56-532a8c2233d0"], "656019f7-8de4-4cdd-8168-205382847f30": ["99c80147-6176-4789-97db-30a485a9d898"], "4d3a20d9-d9c0-4a35-8d72-e3ad07cd8146": ["99c80147-6176-4789-97db-30a485a9d898"], "c317a02b-226a-4d85-b702-7498342d0e00": ["8c0e6004-6152-4a40-a251-4eb0222379bf"], "10deb2db-b3ec-492f-bc9f-d900c4959dcf": ["8c0e6004-6152-4a40-a251-4eb0222379bf"], "0ebe9bf9-c57c-4b46-92d9-533f6417b023": ["90914ac7-9d35-4f7a-a05a-587565f14f9a"], "8110ffb1-0ce6-46a8-abfd-74223dee61f5": ["90914ac7-9d35-4f7a-a05a-587565f14f9a"], "3935dde0-383c-431b-9750-fd27c40ecc70": ["e4d77a78-ba19-4954-be88-77c5b4430a07"], "b9de3306-ba8b-40de-9a47-6d56aedfca24": ["e4d77a78-ba19-4954-be88-77c5b4430a07"], "cb35b789-148c-4c72-91c3-c820e95910c6": ["65898c9f-f8ec-45f0-8384-09d777f84338"], "20db5e88-2ccc-49b0-8cc8-e502be3ac630": ["65898c9f-f8ec-45f0-8384-09d777f84338"], "ccd77b49-dd6d-42a0-bd75-752367bf3fda": ["dbfd4eb3-0e22-426b-86bd-5a8f2a31d021"], "9a7fa9b1-de78-49d7-85c2-98d75667a3e6": ["dbfd4eb3-0e22-426b-86bd-5a8f2a31d021"], "56cee28d-8f3e-4388-a961-0ed6feb4eb55": ["9ed070c1-b3c0-4887-84ca-17423b7cb855"], "13fd240c-c5d1-470f-a63e-49db4b3534b8": ["9ed070c1-b3c0-4887-84ca-17423b7cb855"], "4c8a0c94-616e-4874-bb18-18dfaae5579f": ["31c13214-e2dd-4095-b3d8-219a57b89c63"], "8f2b2c91-010d-4e0c-8ae7-8419478483e4": ["31c13214-e2dd-4095-b3d8-219a57b89c63"], "50f5c5bc-3a7c-4e59-9899-6160dd8a0cd0": ["1d3805cb-82e3-4af0-8528-dd63feb37ea7"], "9a1cf5df-24ee-445f-8059-0d7be65bac75": ["1d3805cb-82e3-4af0-8528-dd63feb37ea7"], "fa083022-7f0c-42ab-8b54-6aab42e4190c": ["2169af4a-7958-4396-99d1-90752f1cabfb"], "c50f9c2a-167d-4ba2-854b-3cb9a17bee44": ["2169af4a-7958-4396-99d1-90752f1cabfb"], "9ab3d54c-0f0e-4db5-96b0-58213489ec2b": ["82ddc0ca-3af2-46ec-bbc9-f0bd3a3c13f1"], "c267ed1c-25b9-4001-9c7d-ce762c25efb4": ["82ddc0ca-3af2-46ec-bbc9-f0bd3a3c13f1"], "91d3fb6e-d6ad-4d1d-9c91-ea68c34efb70": ["50863956-c8ba-4b76-8e9f-ed5aaad6d70c"], "71c8629e-2135-4d21-90f7-eb86c3115b2c": ["50863956-c8ba-4b76-8e9f-ed5aaad6d70c"], "308ad885-574a-49bb-a36a-e368b01bda7c": ["aaf2987a-4038-4689-94d7-96c61252854b"], "91c3ad0b-2f84-4c9a-9739-937f3660c353": ["aaf2987a-4038-4689-94d7-96c61252854b"], "11d22e1f-5ca0-49fd-9476-285764bbc724": ["af90afb8-299c-4847-9a7e-f34152c8edb6"], "3fb526fc-94d9-4752-b1c3-ef29446e338c": ["af90afb8-299c-4847-9a7e-f34152c8edb6"], "15ac65b5-cd14-4b8e-a054-9aa3f8d01671": ["c65a398d-00ae-4acf-8fb4-31377547e3b5"], "a6cb139e-3465-4cb9-a7b7-056e2b9ca4e2": ["c65a398d-00ae-4acf-8fb4-31377547e3b5"], "d9b33503-daaa-45f1-9182-a32d1618bf32": ["778d5af1-9db8-46dd-bd57-1bb4a358dc31"], "61288b27-9f80-4307-82bd-ea61f8f92693": ["778d5af1-9db8-46dd-bd57-1bb4a358dc31"], "56333e99-2b70-4956-8876-50d3166cafac": ["e1b85e76-978a-4443-a07f-9e442df26866"], "0ccd4664-8637-4810-9268-3f510d46f723": ["e1b85e76-978a-4443-a07f-9e442df26866"], "d9e47b65-2160-4c25-990c-d97d48b9f3bc": ["267aeb76-7161-4873-8649-16b83839ebdd"], "e12a5b2d-10db-4000-985e-746a0e8ac848": ["267aeb76-7161-4873-8649-16b83839ebdd"], "cc75ef46-6e66-43cd-af22-977eee389821": ["5ea1e077-4a45-42a1-b70e-9cfabac90b2c"], "d99a10e2-0bc0-4648-a976-823ccb212764": ["5ea1e077-4a45-42a1-b70e-9cfabac90b2c"], "3d687266-478f-4d0d-bce9-e4c19f28d1e8": ["7485aae5-8016-4dd3-9316-d65c8157f253"], "ffe8cef9-bb4e-40cb-ba13-a5954823616a": ["7485aae5-8016-4dd3-9316-d65c8157f253"], "5ae68c19-ce9d-4e17-85c7-aaa8f21d3430": ["b4abb967-84d6-4153-9be8-189e17710295"], "6719067e-5248-4170-9256-c3838f6354a6": ["b4abb967-84d6-4153-9be8-189e17710295"], "a6398c65-3d0a-4157-b42e-d9739cd5c8c3": ["a3e5969e-ed80-4405-93ea-e5e7db7bba05"], "4a612055-ba4b-414f-b5ba-6dac5895439c": ["a3e5969e-ed80-4405-93ea-e5e7db7bba05"], "6731ed13-2847-44c5-b083-314efffeccc6": ["2cd0a75b-978d-4408-98f1-d59e7ee8f92e"], "248048f3-dbcc-45e8-93d9-e1b97b3019e8": ["2cd0a75b-978d-4408-98f1-d59e7ee8f92e"], "5a0c24cc-7817-46f7-90fa-f789cebe53a8": ["d9bb0ba3-00c9-486d-b5fd-c01a94ac15d7"], "1391bb83-c561-4a28-b3db-14befca4e8e8": ["d9bb0ba3-00c9-486d-b5fd-c01a94ac15d7"], "96769580-6e3c-4146-a5ea-9a1ecd31f393": ["e9e7102b-fe6b-498a-8647-c41a5717e6d4"], "a4d84aa7-cfaa-4c02-8b3f-32dfa8dbcc0c": ["e9e7102b-fe6b-498a-8647-c41a5717e6d4"], "b64252cd-b8d8-49bf-a8ed-e14bfa1495e2": ["7900d2e0-5c07-475d-b812-50859a4ce992"], "2c0dc893-4c31-40c2-a859-d5991a6fcd0d": ["7900d2e0-5c07-475d-b812-50859a4ce992"], "1be3b222-6179-4eb6-856a-34cfeb9e6936": ["b6f6feb3-a411-4def-89b7-f9201f0ea078"], "35b652df-c78f-402a-8c7c-e7f98b39b37b": ["b6f6feb3-a411-4def-89b7-f9201f0ea078"], "c3043bc4-6858-48ff-ba2d-82c2b8f1100e": ["a5381894-fb5d-4dc4-b2df-cc3a6090417e"], "eaf9d28f-4861-4d70-bd8a-495d8c0a786f": ["a5381894-fb5d-4dc4-b2df-cc3a6090417e"], "a302b788-f0f0-457b-ab4f-8a8051d4c851": ["9b34855e-aef0-4908-b7a1-634324a25e9a"], "a031b2a2-3ba0-44a6-8914-df82985a20c0": ["9b34855e-aef0-4908-b7a1-634324a25e9a"], "bb7d29d0-612a-4b2e-99bc-52f256eac44d": ["53be903c-00f8-4fd7-b364-6beaf119f0d3"], "95271837-9565-4fd8-99be-c19d1b865958": ["53be903c-00f8-4fd7-b364-6beaf119f0d3"], "3a1e9480-9bbf-4c18-baa1-32d96af2151b": ["83d7842d-92fd-4896-8c9a-4e741273470f"], "f1fd0080-6ef2-4e09-8be1-7f63f9850e3f": ["83d7842d-92fd-4896-8c9a-4e741273470f"], "a208b877-6a39-4ff3-8c91-26ad2f7c1797": ["4ddf47d9-b607-4408-ac19-53610bc6f8e7"], "6294c3d9-8509-4c03-b6ab-99fdf4b6c569": ["4ddf47d9-b607-4408-ac19-53610bc6f8e7"], "b6e5fa4f-a8fa-47ff-b8cc-30d6a6dfd93e": ["0eb0daa8-88da-4c0f-b273-950ddddcde34"], "8409739c-5f4a-418b-8678-f1923e88580e": ["0eb0daa8-88da-4c0f-b273-950ddddcde34"], "672f8105-add9-473e-802e-6910437cdf51": ["792ad7e2-0e9e-4d81-9940-ff85e9f9a665"], "e99e2bed-bbc8-4104-af98-55e187963eab": ["792ad7e2-0e9e-4d81-9940-ff85e9f9a665"], "1e338f74-3c26-40ac-90ab-7c33de3bf1d0": ["def3fa26-1ab7-4e71-8e89-1ae0d62bfbd4"], "c1f1ced1-ed2d-4957-8830-5ab690ced3a4": ["def3fa26-1ab7-4e71-8e89-1ae0d62bfbd4"], "f7bb5c35-a0db-40db-b458-e74166a89309": ["9a11f646-9b8e-4ea8-ba7d-95edaba99003"], "d2e42cc8-4017-49b5-841b-cdf11f84089d": ["9a11f646-9b8e-4ea8-ba7d-95edaba99003"], "c34af4dc-1fae-49b1-8b07-cd4075e75e4c": ["15a7bb79-e9a5-477b-8d9b-cc6e0dbc4ede"], "6b6fdf49-d5b7-49fc-94b0-bff6e35e11cb": ["15a7bb79-e9a5-477b-8d9b-cc6e0dbc4ede"], "aab12fbe-97ff-47a9-8f77-20ccb98d81b3": ["7340a371-67a8-4489-9fcc-0e0a88639ed2"], "25759a5a-c795-43ef-82cf-fd3d185673ef": ["7340a371-67a8-4489-9fcc-0e0a88639ed2"], "71527165-7333-463a-946f-6e22855eef94": ["f56cc5c5-251d-4ac9-b4ab-4ed404c20012"], "48cd4170-c424-4fbc-990a-5467b1764538": ["f56cc5c5-251d-4ac9-b4ab-4ed404c20012"], "51bb4f4e-f47b-4c66-a397-5be5381ace48": ["ae371cc6-2614-4057-95f6-cdae9fa3b08a"], "dab7cbce-efbe-4fd7-9301-84e5ae53f67f": ["ae371cc6-2614-4057-95f6-cdae9fa3b08a"], "56dc2516-0002-4d0a-adbf-1199188cb74a": ["cf5a5e6f-af78-4259-a2df-3c80a47aa27c"], "8a84ca85-944b-4be4-b97e-cc7630ba9be4": ["cf5a5e6f-af78-4259-a2df-3c80a47aa27c"], "44dde9b8-4b95-4813-9ca3-15654cc7d921": ["33f5a150-f45e-4f15-b008-169f56c45a70"], "375fbfa5-008e-43e1-80c3-481dd0e9730d": ["33f5a150-f45e-4f15-b008-169f56c45a70"], "d54947c9-8307-4c7d-ba6f-5533ffe21af9": ["9a5ca8f0-dd57-4b2c-8254-a84f977d0e34"], "95ee3e7d-a8d8-4a60-9e78-2d68878b8cfe": ["9a5ca8f0-dd57-4b2c-8254-a84f977d0e34"], "729f5870-b11a-4365-8989-f515002fa829": ["c600bb54-4905-4102-9cc5-18b9f610ad67"], "75edceaf-9502-4f92-b0cf-a841b040182a": ["c600bb54-4905-4102-9cc5-18b9f610ad67"], "5a34551c-8bad-48ae-a2c9-60e9eeaf942a": ["fb286798-e471-4e00-8d93-48416640a890"], "46741257-8814-46ae-a83c-3c3aa11d6087": ["fb286798-e471-4e00-8d93-48416640a890"], "a1b26141-c8df-47fc-99aa-c832311b22b3": ["02820321-bc0e-4f3b-8bcc-e6bb6a63470b"], "d3a8425c-09ef-4ee5-acc0-e985099208c9": ["02820321-bc0e-4f3b-8bcc-e6bb6a63470b"], "a2141cd6-31ea-4d56-a6eb-7825c04cfc4e": ["a613cdb0-6297-4ba6-a54f-5b9a452786da"], "93fcf7b5-1a8f-4304-aae5-e513ff0655a3": ["a613cdb0-6297-4ba6-a54f-5b9a452786da"], "ac9f4683-9abb-4b67-9cce-3d58efcbcfee": ["102af882-748a-4418-97ee-e1a5f711174e"], "ddec3f83-c0e0-46e2-bca5-7cbb6bdd2c03": ["102af882-748a-4418-97ee-e1a5f711174e"], "5d8c8ee8-4d26-4682-8cd6-4b0bd16fd613": ["40f5ad98-a346-4f21-811e-01114345f147"], "dc6fb1a8-dbb5-4969-92a3-5ea50240c921": ["40f5ad98-a346-4f21-811e-01114345f147"], "3eee8e7e-25c9-4a80-ae3b-5a8a67530786": ["f00bc4ea-f8ab-4620-bef3-9b302bf389ff"], "91d004f8-6290-48ec-9aa1-ff0bf7b503e4": ["f00bc4ea-f8ab-4620-bef3-9b302bf389ff"], "fe260adb-ea2f-4fa8-8a78-049064b00beb": ["b8570e39-cab5-4bfb-9219-0cbc3a1117e9"], "3b7fd31d-42dc-4985-ad02-ff6ac833700b": ["b8570e39-cab5-4bfb-9219-0cbc3a1117e9"], "0ff1c6fc-f6eb-4e07-a76c-594238041b36": ["544c807e-98c9-4d9d-a0cb-faa47055f69f"], "57fb06a3-2cd5-426d-9ed2-be57428f4a67": ["544c807e-98c9-4d9d-a0cb-faa47055f69f"], "c7637342-0d73-4674-a703-4a61d31f2ee3": ["94f85952-e349-4b21-a566-fa13067c0574"], "499cddfa-6249-47f0-aaf9-d763514d9722": ["94f85952-e349-4b21-a566-fa13067c0574"], "deffafd4-36f9-4eba-a8f8-ebf586a30c78": ["b06033c9-d4c8-4e7a-aa22-22a9bbc72ace"], "b048baf2-ebab-4425-919a-d42bb1bb37ce": ["b06033c9-d4c8-4e7a-aa22-22a9bbc72ace"], "63ee738d-c834-4c5e-87ed-d280e251b648": ["018878e7-96cf-401e-8f8b-52f4a4ecbae0"], "bf0d281d-e84b-4c04-9184-538c7ea2d34a": ["018878e7-96cf-401e-8f8b-52f4a4ecbae0"], "bbb2db35-bf23-4c84-8ea8-6ce14e46d106": ["1474222d-3bc7-4acf-bada-82cb1712250a"], "43c380be-38e1-4753-a6b5-a68781d21dc2": ["1474222d-3bc7-4acf-bada-82cb1712250a"], "a011d33b-0471-4e52-a9a4-30b4894d93de": ["9754ca48-303f-4cb1-b99e-37d07fd12ad3"], "e5aa8331-5997-4145-914b-a7a58e22746a": ["9754ca48-303f-4cb1-b99e-37d07fd12ad3"], "c801d50a-a565-4e69-ae74-15d1bd25588b": ["fb35d71d-76fe-4b4e-9e59-fb408612d321"], "c82a449a-568f-4f6f-97c2-78e7e0fa2330": ["fb35d71d-76fe-4b4e-9e59-fb408612d321"], "b4f0e682-6ecf-483b-940f-6def580edd55": ["71a468cc-1791-45cc-b518-84b7f6a84fba"], "35bc819b-20d6-4ff4-9c2d-3561208179f2": ["71a468cc-1791-45cc-b518-84b7f6a84fba"], "22a9627a-0fb0-4972-a1de-0365e2800996": ["8ffcd263-22ff-4150-9545-1a0c0e01607b"], "039a799e-593e-4420-a405-2da7572ed195": ["8ffcd263-22ff-4150-9545-1a0c0e01607b"], "1a739202-16cd-4c20-b8e5-6659c3d7d4e4": ["d46635b7-6805-4b6b-a2f9-7ad9d71372b9"], "3dd92ae7-c64d-4eff-acfb-616010afebc7": ["d46635b7-6805-4b6b-a2f9-7ad9d71372b9"], "e95c1ea3-f55f-4a8f-ba5a-465adbaa805c": ["c3db2379-d822-4360-b5a8-dbbcaff89447"], "08b616b7-20d9-478c-9d8d-bd11f367d2ed": ["c3db2379-d822-4360-b5a8-dbbcaff89447"], "dabb41eb-37f4-4edf-a608-d47b49205b3f": ["35afcf44-8f0a-407a-a58f-dc0312d0b348"], "c6ee5c15-f5b5-4035-b4f9-719c36a78245": ["35afcf44-8f0a-407a-a58f-dc0312d0b348"], "8681e320-7137-4114-a24b-24a3405fb2b9": ["0e85145d-5fa3-417e-808d-54610a5c18f3"], "daf2e8f0-f0e5-4f8b-b563-d0a8cebe9629": ["0e85145d-5fa3-417e-808d-54610a5c18f3"], "ad0eb872-f5f2-4b86-bda3-962ee89af7c8": ["c7a9b913-57c9-49ed-b3e4-6c0654a50993"], "bfdda532-1d7b-4781-afbe-2a0c43f77220": ["c7a9b913-57c9-49ed-b3e4-6c0654a50993"], "11ce0ccd-3b5a-4308-be37-812b238b4449": ["29b09b0e-310f-47d8-b4ce-115ce99fc486"], "077f5d7c-a8f6-4d3b-a147-9f5ece276b08": ["29b09b0e-310f-47d8-b4ce-115ce99fc486"], "5e81d0f4-c40a-4f11-957b-577221cf120c": ["9cf9a362-96b8-42c4-b213-09e8aa52b4c6"], "3be256d3-d533-47db-9dd4-bdafe59b5f88": ["9cf9a362-96b8-42c4-b213-09e8aa52b4c6"], "3a215422-10a5-499a-9988-694c5db5035c": ["b8244a0f-64aa-4ccf-86c4-ee5fab04bd61"], "9a69c417-928e-43a9-abf5-f217a1e49d44": ["b8244a0f-64aa-4ccf-86c4-ee5fab04bd61"], "6d42bf4f-1edc-4db9-bf6c-93e1b42ecf2a": ["7bbb4e26-9509-4777-ac17-764dec27516f"], "20fdf738-8c29-462c-b1d1-7bc3c0cb5d9f": ["7bbb4e26-9509-4777-ac17-764dec27516f"], "f1c13d85-e215-4cc0-b93a-e7dcd84b7105": ["94f08b11-e4ad-415e-891d-5136f266d96e"], "c7e59ed4-55af-4f6c-9fc2-8177f0fc1ad8": ["94f08b11-e4ad-415e-891d-5136f266d96e"], "9560f9e5-6670-45a3-8da6-a31f463dc58d": ["f98d24fc-7104-4613-9a3d-d799566cae2a"], "9690ca23-bac5-4319-8a85-74f2dea67e9b": ["f98d24fc-7104-4613-9a3d-d799566cae2a"], "ab19af0e-2a67-42f0-b1d0-c71eec70f050": ["c0aeda94-1d7e-431f-b056-2b04f9bdb2b6"], "d4f3a8ae-5be3-4efb-aa54-00472e0a33e9": ["c0aeda94-1d7e-431f-b056-2b04f9bdb2b6"], "aa9f4bfa-b630-4c6d-a6dd-f3e56e510669": ["b9abd627-ee7e-4cb4-b934-f7955d117fe5"], "9560f275-f052-410c-92bd-1a94236ce6ad": ["b9abd627-ee7e-4cb4-b934-f7955d117fe5"], "97caf6fb-54d6-43ec-a509-ba1363f9d698": ["58a90729-3204-462a-91bd-bfc6554cac8c"], "488becf7-54a5-4153-b02b-324087267b4e": ["58a90729-3204-462a-91bd-bfc6554cac8c"], "793ff485-6ea7-4ad2-9528-65c0bf041fec": ["b38fad9f-bf31-4780-b089-7b343c57208f"], "b4d1c2ec-d999-4023-8c63-76fe6f00f9a2": ["b38fad9f-bf31-4780-b089-7b343c57208f"], "cac4e2fa-fa97-43d1-b2e5-12d433f321a5": ["0d8dcce6-ac7c-4956-ad10-88d8d289a7bc"], "d1b34049-f238-4a7e-bb0c-0cfb548abbfc": ["0d8dcce6-ac7c-4956-ad10-88d8d289a7bc"], "d3335d75-2d5a-40aa-b0ed-bbf27a6c747a": ["aeb526e3-d1d9-4a8a-a556-9bfa0bd08772"], "7bf1e819-3fde-4580-a5ea-92a704138f1c": ["aeb526e3-d1d9-4a8a-a556-9bfa0bd08772"], "30269bc0-2c64-455d-8593-d8f893fc4df3": ["d3c6cf0b-a630-4376-aa31-9051595a4683"], "50c62687-0afa-44b9-a1fd-b40757549647": ["d3c6cf0b-a630-4376-aa31-9051595a4683"], "6e0d80ee-842a-4cd0-b712-47d48481979b": ["f7603c35-fcfb-4c42-bf03-1c14db589026"], "2183dd8b-6bd7-4b68-88cc-563ee832f3cc": ["f7603c35-fcfb-4c42-bf03-1c14db589026"], "590cdd7b-1634-4d19-9fb4-a2ae6e11a307": ["f2e7f5e2-f0fc-439e-ab7c-7a7fed01bba5"], "c324526d-e094-4306-8cb2-6e2312c43356": ["f2e7f5e2-f0fc-439e-ab7c-7a7fed01bba5"], "66ac5796-d5d3-4303-8c9b-cfafddbd8810": ["4a8bb5ce-f047-4111-8a36-8f30c9fea579"], "80e1ca04-256f-4e3e-bcba-212144f989bf": ["4a8bb5ce-f047-4111-8a36-8f30c9fea579"], "811a80de-b8b0-40c9-af47-a1446c68dc4a": ["74e127da-915d-42dc-9835-419d317fc3cd"], "824170fb-7ff6-4531-a319-d9a29b1aaa63": ["74e127da-915d-42dc-9835-419d317fc3cd"], "8a581d4a-0f07-45e0-a1a0-367b3d3078c6": ["ee260027-c2db-4f31-8bad-80cc728184a6"], "de9928e3-fac6-48aa-90c7-c16c4b74c0b7": ["ee260027-c2db-4f31-8bad-80cc728184a6"], "6053208c-e7b8-4395-84d8-12dcf21adab7": ["10742ac9-7c29-40a8-8418-6986b28192f1"], "ad777204-4ac2-42d9-9029-a4be3bf49789": ["10742ac9-7c29-40a8-8418-6986b28192f1"], "b0285db8-5763-4327-bdbf-be133814aaae": ["e43f9a2a-d5b4-49f5-835f-4493bf2e8f8c"], "a2ca3e93-793a-4a0c-8b02-63e8a34c5b5c": ["e43f9a2a-d5b4-49f5-835f-4493bf2e8f8c"], "561c0cf8-a3dd-44b4-9679-984f3790d3fe": ["55c46a0a-cd5b-405b-8184-0b2b78de329d"], "ecf01b7f-1eb4-48fe-b320-81f327c062cf": ["55c46a0a-cd5b-405b-8184-0b2b78de329d"], "42a4f4b0-bfba-4cfe-a6d8-f1f95bfd2fec": ["563ec54e-cdb1-4365-9e82-445211d2045e"], "187c8383-1e8f-40a5-aa00-07b8e948dc50": ["563ec54e-cdb1-4365-9e82-445211d2045e"], "6c767f4a-5834-4427-ac07-51a1ced67771": ["7d2f169c-0eed-4de7-befe-3e388113ddcf"], "baabc0fc-a123-496c-877e-d6201aee81aa": ["7d2f169c-0eed-4de7-befe-3e388113ddcf"], "1b80d2eb-cfd5-4442-9ff7-fa905bd419fc": ["076b15b9-9812-4e46-b701-f0e3a5eb92ce"], "1e5a3799-ba5f-4881-b4a8-ac4b65bc26ca": ["076b15b9-9812-4e46-b701-f0e3a5eb92ce"], "b06d7587-17d8-4670-9a5a-7006fd02141c": ["1331130e-af6d-4a86-95ce-a674da04e4c5"], "4e30e6f1-492f-4886-9096-52ea609d95bf": ["1331130e-af6d-4a86-95ce-a674da04e4c5"], "40dcad7b-a44c-4728-8df6-bde4416a2552": ["ba7bf32a-73e7-4d13-a237-6f125aaa9baf"], "578330a9-8c5c-4413-8ea2-7721e3168a29": ["ba7bf32a-73e7-4d13-a237-6f125aaa9baf"], "d4eb2c7e-08ce-4de4-8187-2bf8fc097531": ["4c2ca60d-29b9-47ab-9b1c-b9aba2f7547c"], "a0722c5f-319b-4b10-8ae2-70b0f1f2df06": ["4c2ca60d-29b9-47ab-9b1c-b9aba2f7547c"], "9007b3d0-d32e-4431-8a1f-ccddacc956db": ["95ea404a-34d5-4183-b7cf-518c69f14804"], "e94aa728-daac-4c90-81bc-5cd241c0fd6c": ["95ea404a-34d5-4183-b7cf-518c69f14804"], "aa1a0081-f7b3-425d-93c1-98a3d2aeccb1": ["ac8df4fa-5e36-4a73-a5c9-6689d9ac38b0"], "ce02657d-7c17-479a-b6a0-ef9138efa4a2": ["ac8df4fa-5e36-4a73-a5c9-6689d9ac38b0"], "94b9eef6-9fcd-44a9-98b8-5d6062b534fc": ["c84c8ed5-4a22-4b7e-b05b-27cc36ec8d1c"], "2854f950-63c1-40b4-91b9-63e32f3977ac": ["c84c8ed5-4a22-4b7e-b05b-27cc36ec8d1c"], "86c090f2-69f6-4f9f-aa4e-666a17e09214": ["b2ecf04f-6035-47fd-bfae-8f1b117e1cc3"], "ed4c49fd-e5f4-409f-b8e3-7cf394d8bd91": ["b2ecf04f-6035-47fd-bfae-8f1b117e1cc3"], "91ce403f-b4e5-426c-9d7f-d69fa16299e1": ["29fa1dfd-359d-4b98-861a-29fce118ebb0"], "1757c62b-c5e3-43c5-b651-a2b3fb74cdb8": ["29fa1dfd-359d-4b98-861a-29fce118ebb0"], "4aad5967-68a7-43a0-b7e3-7b6a3ae38580": ["7690f94a-9a0a-4bb3-8ff2-8a52c5a89e86"], "e612ace4-4672-4f30-9638-eef693523924": ["7690f94a-9a0a-4bb3-8ff2-8a52c5a89e86"], "3b7c9217-1430-4132-a186-334a27f5f96a": ["f149548c-a4fb-4bfb-9f1f-b3a40284bb32"], "4b09d600-32f0-48d4-bdb1-79fca60a61c1": ["f149548c-a4fb-4bfb-9f1f-b3a40284bb32"], "ba090ba4-1d4c-4e65-a49f-1038b01fb6cc": ["4dcc6606-53cf-4f6c-a102-9652fe5197af"], "0ac31c0a-ef66-475f-a438-b1d0d6154024": ["4dcc6606-53cf-4f6c-a102-9652fe5197af"], "fa95ca75-ce77-499f-ba7f-6087b4e030a3": ["8de89375-ee6f-4deb-8f6f-20c3a1a18022"], "facc56f2-a2f2-4199-96f4-27e94d1e0d00": ["8de89375-ee6f-4deb-8f6f-20c3a1a18022"], "d9a45b03-0811-4081-ad54-1bb6b7906485": ["66967d52-c7b1-4982-9f9a-717d4df482d4"], "e88c2c19-1b01-4b2c-922a-be5b0a8ca8bd": ["66967d52-c7b1-4982-9f9a-717d4df482d4"], "8f28bf2c-7135-41dd-b761-3666add3ac42": ["304c5367-d311-45bc-aa5b-dc3c4dd31bd6"], "08f0ea96-3dd8-428c-bd34-9baace4bc21e": ["304c5367-d311-45bc-aa5b-dc3c4dd31bd6"], "a454087d-3254-4a33-a88a-940dfa0aacd4": ["37101cb2-67a0-4069-a2dc-581286515834"], "b0cd94ce-1a3c-417c-af7a-528faef54158": ["37101cb2-67a0-4069-a2dc-581286515834"], "8915492a-26c0-443b-a065-f78972585f21": ["671a27f6-4bc0-4651-a401-d2e7979fdd01"], "b0c1731c-1692-443e-813c-953917dcdac6": ["671a27f6-4bc0-4651-a401-d2e7979fdd01"], "fe507a13-f73e-4720-b7cc-e05e92733a03": ["b75b0701-dbd3-458e-a174-d1b59a580802"], "2524b46f-dc41-42ff-ac6b-f8aadff9677c": ["b75b0701-dbd3-458e-a174-d1b59a580802"], "c115e84e-28c8-4306-b07f-e4ecffc1988b": ["31f7f2aa-6a43-48c9-bc75-d9df3fc14a32"], "c5d664cc-31c6-482b-90e2-1b680ce2a94a": ["31f7f2aa-6a43-48c9-bc75-d9df3fc14a32"], "6e69799f-4b6f-49a0-859f-cc8f3822f526": ["6f491c10-2010-4536-8b18-8cc87c43620e"], "75cdc265-38c9-4767-8b5e-2af493d44cbd": ["6f491c10-2010-4536-8b18-8cc87c43620e"], "0850484b-d693-490d-849e-340c674d47d2": ["83cceff9-b38e-4a3c-8695-acd37305c793"], "b1dd2d9d-2bc4-4506-a68f-6dd03b73a91f": ["83cceff9-b38e-4a3c-8695-acd37305c793"], "03802873-d7f3-4aba-83d8-bb34299acc72": ["356f6ea7-7e69-40f3-9a47-d11182b510d0"], "07e90b29-c913-4a0d-995c-236ac6dde596": ["356f6ea7-7e69-40f3-9a47-d11182b510d0"], "fb0a3530-8e29-4053-aaed-7e1c805d19f7": ["41014a29-ff68-4181-80ae-32faa6fe7a4e"], "29d60fff-cdb9-481e-8e19-7a9eb158a871": ["41014a29-ff68-4181-80ae-32faa6fe7a4e"], "7b373969-0869-4753-8f49-1130e698bf22": ["ee4a53b4-3703-463b-b267-bfa5a27926fa"], "3975d869-8ee3-40d2-b50c-b30b992a52a5": ["ee4a53b4-3703-463b-b267-bfa5a27926fa"], "13f6dcfb-b287-4388-a01b-b7b324e78064": ["833eab77-92a5-4d34-8641-0761440d6bef"], "89e78744-1a50-4fed-a43e-a01440dff205": ["833eab77-92a5-4d34-8641-0761440d6bef"], "f31c0308-6237-4be1-b692-1e555350d6cb": ["f3a66ae2-29d8-4619-a6a3-00c94c0d02f7"], "e5121b5d-ea6c-489a-837f-d6fd264039e9": ["f3a66ae2-29d8-4619-a6a3-00c94c0d02f7"], "e48a859c-4473-448d-9bfa-6dac9953f4c1": ["405a360a-d099-4ca1-af06-5c08d9f5d64f"], "79092675-9644-4531-9cdd-ccc849f67b9f": ["405a360a-d099-4ca1-af06-5c08d9f5d64f"], "f996eda2-f980-4cd5-93bf-ec6886cf731e": ["7a511679-10b2-4427-90d9-ca4b329329d5"], "80f5ff42-b5c9-41d6-8ebd-50c03b146179": ["7a511679-10b2-4427-90d9-ca4b329329d5"], "93b7ddaa-c5e3-45ba-8b4a-712a31e5b80e": ["370ddbe4-2469-44c9-af19-34b01ffd2689"], "6c581332-ed07-4eb8-beb4-5ed2e664a391": ["370ddbe4-2469-44c9-af19-34b01ffd2689"], "fc0d8a9d-b98c-4a11-949b-6b61a2353e3c": ["27c89c57-c154-4b04-b98c-a6fe5c7398b2"], "1b3de213-82b6-4dc5-83c8-517ae262cdcb": ["27c89c57-c154-4b04-b98c-a6fe5c7398b2"], "bf2784d6-b500-4547-b3e3-686d53755a9d": ["85987bca-6e6b-4595-be00-b9edbf67257b"], "34605653-cd3b-4622-b348-3d09da5c9e7e": ["85987bca-6e6b-4595-be00-b9edbf67257b"], "4c5a9606-3e7b-44a3-a59d-fec04295bb4c": ["ec686833-94f1-4d56-bea9-71ec9609cf02"], "8c46a334-7984-4ed5-8544-14318036aeef": ["ec686833-94f1-4d56-bea9-71ec9609cf02"], "a6599822-5c70-431c-9250-38a1c38ba28d": ["14b7715e-bd7d-48c3-a332-434d3ee4c402"], "c8b0c22d-9f31-4b2f-a03c-954f10d56f28": ["14b7715e-bd7d-48c3-a332-434d3ee4c402"], "f32ff14f-96df-4dd0-bf0f-640971290bb5": ["a603000c-bd1f-4908-b059-dae05e69517c"], "33020145-d44d-4f52-89f7-b9b9a9de1740": ["a603000c-bd1f-4908-b059-dae05e69517c"], "f4f0b003-2c7d-40d3-93f4-a0957245e5fd": ["f94103f0-1896-4b0f-a4bd-bbe9a2e5f610"], "98af905a-7720-4910-9767-a6c4d31e3203": ["f94103f0-1896-4b0f-a4bd-bbe9a2e5f610"], "ef7bf3fe-fe7b-412e-b931-39d1ddde8388": ["d36cf73d-7b8c-4761-9668-5c9e7cdb6dc1"], "db59b972-a01b-4b08-a0c5-7800d7bc0e0d": ["d36cf73d-7b8c-4761-9668-5c9e7cdb6dc1"], "deaceffa-0db6-40d9-a05a-176847e3d306": ["7baa9ec7-bcd0-4f77-9325-e1e8bd8b2c7e"], "d1e7da0c-6e92-4f2b-9cb5-82a18784d75f": ["7baa9ec7-bcd0-4f77-9325-e1e8bd8b2c7e"], "067fb92d-368b-4156-8fd5-b455613a7df7": ["eb36cac9-04e9-4472-8597-8ac22bf41230"], "dca53166-da24-4db8-adf1-e79d599d7f0f": ["eb36cac9-04e9-4472-8597-8ac22bf41230"], "f3b12aa2-63c4-49c5-8ed8-6c85a2f1a878": ["80b9c020-5bfd-4cc3-8448-2f44fe03d67b"], "c9a7c111-2b4d-4b59-b09a-5c847eda9fab": ["80b9c020-5bfd-4cc3-8448-2f44fe03d67b"], "4cacd155-b23f-45e9-b301-bf2f1c4afdb6": ["396b03dc-e478-4fd0-a060-28eeca1727c9"], "141e65af-cd35-4c7a-9981-379efd1b6bc7": ["396b03dc-e478-4fd0-a060-28eeca1727c9"], "34d918a9-e2b4-4b4d-bbe8-1538eb777a4b": ["0e576866-a682-48f1-8c0f-1b8059e50b3b"], "68485945-37a6-4382-b75b-981f07aa8221": ["0e576866-a682-48f1-8c0f-1b8059e50b3b"], "92ed4f14-26b4-429e-9c21-70da64912501": ["876196aa-616e-4c86-9a95-15b8b5e9aa2f"], "dee0b60c-0d85-4096-9415-a723f7ca149c": ["876196aa-616e-4c86-9a95-15b8b5e9aa2f"], "14a52970-4e49-4abb-b4a6-cd21eb2b076e": ["ba2329b3-9970-40b5-9213-74f81d8b30f8"], "4a1b4636-ca48-4e0d-b156-9382f7be133d": ["ba2329b3-9970-40b5-9213-74f81d8b30f8"], "ed237ad9-46b0-4d64-b316-47775c598a0d": ["2d1860a0-4108-4fe8-a4f8-28362aae80e5"], "90684a4e-5d8b-4c04-94b8-bcdeb72ba8d9": ["2d1860a0-4108-4fe8-a4f8-28362aae80e5"], "45092704-1ff1-4b1f-8bd1-480637c49e0a": ["444359ee-b99a-42bc-bf97-c2938e4caa18"], "4b8c2d33-0d0f-4488-b446-5d74bf2939c1": ["444359ee-b99a-42bc-bf97-c2938e4caa18"], "e1bc5dec-0525-46aa-bd92-44f71e76368c": ["f4f6180f-f191-4f4a-a27b-6173b0cb7f56"], "ec86734e-003b-4bb0-ab2d-a15c874ca711": ["f4f6180f-f191-4f4a-a27b-6173b0cb7f56"], "66e4770a-e6eb-4e4a-b7f2-314a3bbc615b": ["c30675d3-1e25-4e33-8e63-3df8fa79b543"], "82ea0853-c631-472b-b865-2ed77fcad5c7": ["c30675d3-1e25-4e33-8e63-3df8fa79b543"], "9ce45542-ab27-4c78-979b-981d36ac3c21": ["3cfdfc37-c2be-4e2e-8336-566a2b07c878"], "d6075fee-9472-46fb-a581-65aadb2544b7": ["3cfdfc37-c2be-4e2e-8336-566a2b07c878"], "1bbd5dc5-d41e-406e-bb40-1eb5b9d754c7": ["e16ad710-4cb1-49ff-9d9c-4b03b88bba3a"], "ad6f8c33-a11d-430f-ac07-b0c3020ef7e0": ["e16ad710-4cb1-49ff-9d9c-4b03b88bba3a"], "32095d18-23c9-4baa-8c49-35dbcee5ebaa": ["9ea3314d-c0b7-4724-96bd-c98e3628f269"], "9c91aaef-7c78-42ba-9b71-8a2a3e833500": ["9ea3314d-c0b7-4724-96bd-c98e3628f269"], "717c4598-0a41-40e2-a0ca-2a05494630f9": ["ffda8e51-f721-48b7-8b1d-3456a25fa6a1"], "112a0ed5-8c67-419d-b081-eacc8aee5282": ["ffda8e51-f721-48b7-8b1d-3456a25fa6a1"], "21912c63-55ee-4d52-9e33-5b31407c29d6": ["625f39db-871c-4e42-871d-aaa88cda9a3b"], "7d862deb-a668-452f-8ce5-0968068b2b59": ["625f39db-871c-4e42-871d-aaa88cda9a3b"], "0718475f-5cee-4829-a6cf-32e5581ecf46": ["c7851f7b-26db-4f5f-b8fb-cb67492e6907"], "afab3f40-d769-42b3-9a02-48ddcad92d5b": ["c7851f7b-26db-4f5f-b8fb-cb67492e6907"], "e88fea9e-1c99-4895-b657-7f302c3b8149": ["5c41b57f-5e28-4896-a585-6756c2e76c63"], "e139d38f-e74b-4aca-9cf7-ca16eb63d1a6": ["5c41b57f-5e28-4896-a585-6756c2e76c63"], "a4ad5f05-6b2d-4e52-b4c7-07f3ceeb3023": ["32009780-7da5-46ae-b978-9e75ead5ab84"], "4aea276a-b3cb-467d-a013-3c58a562abf1": ["32009780-7da5-46ae-b978-9e75ead5ab84"], "afa6fb9f-22fe-4c72-aeec-eb5cd385e6ed": ["0f2e095b-28df-4700-97f6-df7b4adb2632"], "eba65977-58b8-48af-a443-ab04c3c26286": ["0f2e095b-28df-4700-97f6-df7b4adb2632"], "d10f4697-498d-40b0-b642-bfe0fc7b55d8": ["a957d342-1c58-4485-9eea-3afc4d587c20"], "1fe15653-a6d0-450b-92f7-d3ef49b9da47": ["a957d342-1c58-4485-9eea-3afc4d587c20"], "95be6474-41d5-4597-aba8-1665468ca8f1": ["10da020f-62e8-4c10-8b97-c5400d5a4bc1"], "ea563177-8920-4b03-ac51-337ff4a8c58a": ["10da020f-62e8-4c10-8b97-c5400d5a4bc1"], "0d4cfd2b-0441-4e25-9571-8bf0d5c3f95b": ["288c87c7-a613-4eef-a141-c2a1da271858"], "d49d2f48-ab82-4170-ad36-38b1591b962b": ["288c87c7-a613-4eef-a141-c2a1da271858"], "5d54af50-08e9-494e-8273-e322e9aefe1a": ["e2cba6a6-c66b-47bc-bdae-c624f0de5945"], "e7f239d2-569e-4c9f-acd7-cbfd1d5d2708": ["e2cba6a6-c66b-47bc-bdae-c624f0de5945"], "24602a76-696e-4371-9f0a-14dd43246645": ["6afdb57b-ab0b-405d-a19d-d7588ebf6bdd"], "a63b17e9-59b1-48e7-aaa5-686d8db0ab98": ["6afdb57b-ab0b-405d-a19d-d7588ebf6bdd"], "aad07b57-5721-4065-95ed-338dab8c31f5": ["dfe53d04-704d-432c-8aba-f9f222876af2"], "4e5d0aa8-363c-41c9-b93f-86c5889c47ed": ["dfe53d04-704d-432c-8aba-f9f222876af2"], "27e3f506-4eca-4347-b257-fa78ac1c3aef": ["ff012b42-7f94-4bf9-afaf-df4788daa2f5"], "2ed6da6e-a2af-409f-94a3-cb150b87111c": ["ff012b42-7f94-4bf9-afaf-df4788daa2f5"], "b537a00a-178e-458f-9148-20b375ee1136": ["2905a7c8-4736-4dc8-8d54-ece22d6fe05c"], "a9bfb2fe-e919-4b46-a067-413d44934161": ["2905a7c8-4736-4dc8-8d54-ece22d6fe05c"], "c9a1472a-0d25-4101-98cf-be09ece44c7b": ["d3cb4069-9e89-4ae1-9279-6c84a317223e"], "bd5dab36-b7ec-4ee6-b733-f5e0721fe98f": ["d3cb4069-9e89-4ae1-9279-6c84a317223e"], "4d56e4e0-d4ce-4c81-beda-0b478831a70e": ["5bda8728-1192-405c-a66c-dc2245e2858a"], "042e053c-e52f-4ae6-989a-0ccb72304d7b": ["5bda8728-1192-405c-a66c-dc2245e2858a"], "9da59a71-fc38-4d44-b8bb-d63099b500d5": ["823c91d4-2c65-4788-82a4-a87a98cf5301"], "9cf6599c-beaf-4d73-89d0-cacb42e77ddd": ["823c91d4-2c65-4788-82a4-a87a98cf5301"], "aafc2864-b147-43c3-8d9a-3f6583cb9761": ["0e980c31-ca5a-4756-9c7c-768c2d4301c3"], "b7972ac6-b9df-4bb7-a7c2-d4b2331374b7": ["0e980c31-ca5a-4756-9c7c-768c2d4301c3"], "0d8a8f21-9d23-4ef0-aac0-50155e49ac55": ["30d3a9d0-2796-49a0-b697-598c2108688a"], "b30de182-206f-4438-b8d4-647920e77954": ["30d3a9d0-2796-49a0-b697-598c2108688a"], "441f2a5a-1b7b-4e3a-af91-452b3061baea": ["296b63ab-c644-40f9-b78b-8f721c29d864"], "6d295c91-8ef2-4a60-a61e-0006be0cee6c": ["296b63ab-c644-40f9-b78b-8f721c29d864"], "c27d36f0-9645-4ce7-aea7-ea84649b9112": ["215df9f8-01b9-4fc2-bff1-0146f000950a"], "996fe255-ce39-43f7-ad44-288e42c72134": ["215df9f8-01b9-4fc2-bff1-0146f000950a"], "8b869c2a-7b4e-47e9-bfce-e894bfbe9548": ["9f5ab3e0-638a-49d1-a730-c7af7382c643"], "11a8f5d6-da42-4822-8f42-9e0bda171a2e": ["9f5ab3e0-638a-49d1-a730-c7af7382c643"], "bc5e6261-06eb-4aae-a32a-80c17084685b": ["0c2ef4d2-a416-465f-bc9e-74907e92ff8e"], "f716d2f7-f08a-43c7-8456-9fbd3fa6eceb": ["0c2ef4d2-a416-465f-bc9e-74907e92ff8e"], "fbf5fa11-a725-4416-a4aa-3d8a253cb99e": ["e01ab0b9-52a3-45f3-a7b7-a2070b1c8461"], "8d02f47d-c2e2-4f14-984f-c6fe3f3a572d": ["e01ab0b9-52a3-45f3-a7b7-a2070b1c8461"], "e571b4aa-f274-42de-934d-18cab9ba459d": ["56c04205-344a-4159-bb64-8e3515000740"], "3ec4b7de-4534-4ea7-a7f1-95446ac1966a": ["56c04205-344a-4159-bb64-8e3515000740"], "9462862a-524f-4ec4-a466-ac3a9d853d93": ["5fb124ad-891e-41e8-9837-0086804787d4"], "445da68b-62fe-4788-ae6f-de7b95f42bed": ["5fb124ad-891e-41e8-9837-0086804787d4"], "1696d067-68b4-492e-8c0d-5f8e97cf688e": ["f93042e7-98e5-4e82-aff6-83c7148279d9"], "850b2aa0-e04c-4b61-a539-60fd96cc2417": ["f93042e7-98e5-4e82-aff6-83c7148279d9"], "512af064-2574-45bc-9988-cdbf2adf7b54": ["a70912ca-1bdc-4cae-b938-e03d4b7a2e17"], "4dd0e7f5-47c5-4f4d-89d6-35513d7934ae": ["a70912ca-1bdc-4cae-b938-e03d4b7a2e17"], "061e92cb-0315-4ee4-abbe-471ea8de0924": ["7be6686a-8dd3-42d2-9549-40212f4f405f"], "f3e4d990-69e1-42e7-b0f5-87f408d48a4d": ["7be6686a-8dd3-42d2-9549-40212f4f405f"], "f613c86b-af8f-4ce4-8f10-10a323a8ac38": ["f1b8262d-b5ef-4dba-90c1-578234592c3e"], "70c7008b-62de-41cd-99eb-f7c1379b1dcb": ["f1b8262d-b5ef-4dba-90c1-578234592c3e"], "e7c544ba-d0e5-41cf-9973-9d3f68320936": ["3e6554c6-add9-43c9-a712-23f922bd9963"], "7a444949-3784-4e86-9d60-76147fe850c6": ["3e6554c6-add9-43c9-a712-23f922bd9963"], "ad2f3ce7-ff43-4b6d-a9b7-8be870356a20": ["068d87d8-51a4-4adc-ac91-23e6f0c5fbcd"], "b7297088-2948-4d58-84a3-f21525a45f44": ["068d87d8-51a4-4adc-ac91-23e6f0c5fbcd"], "fc5fa57a-1d5e-4661-b6c7-7e56d000634e": ["59afe854-c372-434e-8ac4-5d9c3b9825e8"], "59ed8c0a-6803-46b9-8f0d-ca91dcbb17c9": ["59afe854-c372-434e-8ac4-5d9c3b9825e8"], "21a864ea-e446-457a-9cbf-fa4ba9cf4012": ["7323fc41-ba10-4412-9020-094e3284bf0e"], "7fbc1d52-7bd4-422d-9c2a-02ecaed5ae42": ["7323fc41-ba10-4412-9020-094e3284bf0e"], "1de0b29f-a11c-42c5-8622-961425244709": ["7965986e-e2b3-4cb3-b989-bac338130d2c"], "5317043f-ec08-4e3f-b5d8-bffd4fe64c06": ["7965986e-e2b3-4cb3-b989-bac338130d2c"], "2524319a-7a71-43e7-919a-5d618e29ea68": ["286f9b15-50c8-4579-803e-33a82492c45a"], "af6ab579-e6c4-4914-af08-7a7bfc448bd8": ["286f9b15-50c8-4579-803e-33a82492c45a"], "269fbe37-fd07-4bef-9f2d-bdcecd1e6d36": ["12959615-a3ce-4975-80bd-34bb2adc1ad1"], "957f1104-8811-4d46-b6af-8a90d50b43bc": ["12959615-a3ce-4975-80bd-34bb2adc1ad1"], "58d010d3-af16-4736-87f7-b83b56dd1419": ["16f69c2f-c82a-41ba-83f7-d15a332f0237"], "8eb85195-2331-4f04-9b6e-e0efff2e577f": ["16f69c2f-c82a-41ba-83f7-d15a332f0237"], "7fa271b1-90be-401b-916f-f9ef4bfa2e3e": ["e87e7b39-1ba6-49da-b267-dea97afa316a"], "63afa79c-57c0-414c-94cb-6ffee2062c44": ["e87e7b39-1ba6-49da-b267-dea97afa316a"], "5bf35ff2-e9e4-40f3-9e97-715f06bb65e0": ["4c7a3ea7-e611-4474-96f4-ec8f382135ba"], "af60013e-38cc-490e-bc74-e7c5d439e5e0": ["4c7a3ea7-e611-4474-96f4-ec8f382135ba"], "f32165a4-efa5-41a2-a65d-d5f0de917a84": ["b35bdf5f-397b-44ec-ae19-5af41d4f86f5"], "a014b4a4-51a3-451b-9cab-1f8094a7dee1": ["b35bdf5f-397b-44ec-ae19-5af41d4f86f5"], "6470b0a5-e3ff-4652-9764-1f95d0f0eb5c": ["ea311268-962f-4326-b89b-5e2f9e9614d3"], "e00e8f7e-45ef-44a2-a703-643cea119224": ["ea311268-962f-4326-b89b-5e2f9e9614d3"], "df585d41-5806-40ae-9dc3-4410acacb9fa": ["38d0d82c-afaf-4c18-b21d-26a1a5762e5d"], "3a10b960-37d9-4e60-983f-051c431cb4c5": ["38d0d82c-afaf-4c18-b21d-26a1a5762e5d"], "cc7cc11f-447c-4918-a647-03573175e57e": ["7f96d90a-30fa-475a-8d3e-a9581fa02e56"], "a209d751-4453-4402-8607-79f03cf15a8d": ["7f96d90a-30fa-475a-8d3e-a9581fa02e56"], "4ac3b948-6f86-4b0e-bf4a-848242469fe1": ["52c7f939-1c50-47dc-9b47-30df7891e3c4"], "b3049077-be8a-4ae2-92c5-c4bc89dc864f": ["52c7f939-1c50-47dc-9b47-30df7891e3c4"], "4a85ff19-57a9-4108-bc90-38eea2d02bdf": ["bffcaec0-d2bd-4800-8d40-3c3a8c11a875"], "d9b7f9c0-c092-4307-8359-35c1b683f921": ["bffcaec0-d2bd-4800-8d40-3c3a8c11a875"], "7aac8b81-d0a6-4216-bb56-2ca1c74e5200": ["ff4fc6a3-79b8-46a6-908a-5825d5636f99"], "2277c8e3-aaeb-42ca-b9b0-7142b2db3920": ["ff4fc6a3-79b8-46a6-908a-5825d5636f99"], "4d9fb74a-61b0-42e0-bc93-178c3bb4ce18": ["20d20479-5a78-466b-9f25-332166b274dc"], "8b45e1b4-dd65-4558-9cd5-1be7076f0681": ["20d20479-5a78-466b-9f25-332166b274dc"], "1bf7ed90-e52f-48bb-a37b-471444f51082": ["2562aca8-faed-4716-b0b8-4507aacbea73"], "0f4148d8-a445-4597-9018-10a433791429": ["2562aca8-faed-4716-b0b8-4507aacbea73"], "d9b99410-dddd-47be-9e3a-b9fcfdb174e0": ["7d8fbfc3-fe74-4613-bd68-7238c6674fec"], "8e9cbd49-1894-4fc2-af2d-c105c124faf7": ["7d8fbfc3-fe74-4613-bd68-7238c6674fec"], "5f39174f-404c-421d-8b07-822e7dfd896a": ["981b4a03-c6d6-469b-8883-80136cc9bb75"], "000f9284-29d1-4406-b8b7-4ebed5d88206": ["981b4a03-c6d6-469b-8883-80136cc9bb75"], "749af9cf-0261-4210-8386-73ebe7d73ec7": ["e38bfb8a-e780-4538-b23f-a17d867c4941"], "7ebe645d-c2a1-4cf8-8294-39783e150b21": ["e38bfb8a-e780-4538-b23f-a17d867c4941"], "e417a9c2-fa64-4f72-a578-691bdb44ab42": ["1de19176-c31c-4b39-9666-47f59eed9d8e"], "71e97510-def0-41a1-b9e8-81348f5f753d": ["1de19176-c31c-4b39-9666-47f59eed9d8e"], "e77cfca3-3e32-4d60-aa9e-2b3c09a0863c": ["7e3b1e83-0808-4ad5-838a-85c5225efa3c"], "94cde78b-0315-41a5-9e02-a1ab8afdae92": ["7e3b1e83-0808-4ad5-838a-85c5225efa3c"], "bd5502d8-97f7-407c-8cea-715d50c96b8b": ["cf102159-229e-44c7-a1f3-079e8a4db54a"], "d9ae537f-225f-4c85-aa01-6bdde2a1ee08": ["cf102159-229e-44c7-a1f3-079e8a4db54a"], "39899c65-44b3-4b4e-b754-53de3d096fac": ["f2fb7464-8083-4fc7-965f-59cc1eacf3c2"], "78b0bbc2-1736-4a45-8354-ac2102279837": ["f2fb7464-8083-4fc7-965f-59cc1eacf3c2"], "98873820-06ba-4ec6-b304-6f82d1589091": ["87c3bc49-05ad-49ac-8666-1d19006bf268"], "9f9a5070-bfc7-4aa2-951c-aa4d9acd4a21": ["87c3bc49-05ad-49ac-8666-1d19006bf268"], "dfebf95a-65bc-4438-95bf-1e34443d7f6c": ["8fd4b88f-c25d-4eda-80be-ccc18bece0b3"], "2ea70b3b-d21a-4780-82c2-e8902768da4c": ["8fd4b88f-c25d-4eda-80be-ccc18bece0b3"], "c81525b2-4b11-4899-98b7-a7845e77cd1b": ["9d76471d-3a9f-439c-a426-abc2987358ad"], "08e2d040-758d-443c-972c-38d0e00ce3e6": ["9d76471d-3a9f-439c-a426-abc2987358ad"], "6e60b11a-3043-4de6-8121-ab36959d0377": ["26c92b6e-9190-4def-b8b6-59672b25fb2c"], "30067a3e-d415-48fb-83fb-e3dce76ac5b8": ["26c92b6e-9190-4def-b8b6-59672b25fb2c"], "ac9c690b-3a8d-4878-acb2-0654ac6cb053": ["de4b379b-b4ca-4b19-ab3e-135025517ade"], "44f9659c-1a03-4b69-9d0c-2bc05316708a": ["de4b379b-b4ca-4b19-ab3e-135025517ade"], "3e5accc5-3fdf-40bc-a324-f0068329acd2": ["bd013e69-90b6-43c3-9c37-99443d5eb795"], "e9370df0-43ae-40fe-82bc-11b319e1ebdf": ["bd013e69-90b6-43c3-9c37-99443d5eb795"], "f9c636c7-429f-433b-8012-ed75397a85bb": ["16809d4b-78ad-4b8f-8dd2-e0427a5be4f9"], "28583001-9db6-48fb-b995-9319defa0f8f": ["16809d4b-78ad-4b8f-8dd2-e0427a5be4f9"], "b81a7847-d493-46f9-97ec-0f352064a1a9": ["59ebe40e-5539-403c-9b78-30577dd0b34e"], "005b3743-2ca5-4539-afce-22e829c78dab": ["59ebe40e-5539-403c-9b78-30577dd0b34e"], "6d94599a-f2db-4a3f-ae8e-d897c80b15f1": ["ec8f80da-39e8-47a8-b840-b95d5b47792a"], "6502d1c8-fd8c-458a-9a49-e608bbc424be": ["ec8f80da-39e8-47a8-b840-b95d5b47792a"], "f76e3244-0855-4b1f-b76c-7c395d7fcccd": ["48c2e593-2f9c-40bd-b0b1-b92ad3a985f7"], "d7a13428-d56a-4056-b42f-0d158418b139": ["48c2e593-2f9c-40bd-b0b1-b92ad3a985f7"], "5abde1cf-9576-4791-b8c8-3bcebd95e3fe": ["5ef3c350-ec64-4b02-9ace-127d8f1f8324"], "fd571694-a553-4abb-acf4-976e7397496f": ["5ef3c350-ec64-4b02-9ace-127d8f1f8324"], "444c5c4e-e9d8-482b-88d4-a489a19f5241": ["4450f029-08e2-44b3-8227-62489008a644"], "8b3ffa18-7813-46d1-837b-8b9fb13ee687": ["4450f029-08e2-44b3-8227-62489008a644"], "610f5449-2b20-4a99-ac91-e59b0656d031": ["3f1efb65-b141-4a49-b0af-e749cc7deeb8"], "a6241056-ebb5-467d-b297-a329896fd0c7": ["3f1efb65-b141-4a49-b0af-e749cc7deeb8"], "11d817b4-0a14-43e0-b67f-4bae32e99283": ["cf87732c-f50b-494d-a70a-41064b90ca41"], "81cf6251-f279-4e11-b278-c7d27aac2970": ["cf87732c-f50b-494d-a70a-41064b90ca41"], "600b1568-c99e-4c2e-b9df-8c29ae1111d3": ["ff82ffa4-3918-4f06-a912-85f6752dd699"], "2f3d2bc3-86f3-4b0c-bb0d-b7979a26e7a6": ["ff82ffa4-3918-4f06-a912-85f6752dd699"], "6bb2c64c-c50a-4d76-8af7-56c0a596e670": ["ca9147e1-84ff-4b61-8ad1-e9ede2855126"], "5014be90-6134-4e50-9435-2bc4e49ca490": ["ca9147e1-84ff-4b61-8ad1-e9ede2855126"], "ae20035c-aace-47d5-8d1a-bbcad61294ee": ["8c0b1dc6-17b0-45d6-a58c-2bdffae6322e"], "38b29b0b-261c-406f-ac14-e1615ba59e84": ["8c0b1dc6-17b0-45d6-a58c-2bdffae6322e"], "c6aaeb50-fc98-4af6-b4df-9ac7e752bea5": ["a33767a8-d0c1-45c9-a9d5-dd3b24d2ed2b"], "0d071c65-cd9b-4b16-a0bf-54411ae9795a": ["a33767a8-d0c1-45c9-a9d5-dd3b24d2ed2b"], "e8f9a4c6-8302-480a-819b-8e0115deded6": ["e7612c5e-57db-4ad8-82cb-6e41468106f6"], "eec5a3fb-aaa2-4fd4-9084-8d740cf4402c": ["e7612c5e-57db-4ad8-82cb-6e41468106f6"], "96ce4c93-676c-40c0-b910-8d0a56b5b031": ["a05de235-758e-48b1-a8b0-a0f0bd7c040b"], "b2860df7-ad59-467f-862f-e4892c776b7e": ["a05de235-758e-48b1-a8b0-a0f0bd7c040b"], "b32a838c-2a15-45dd-a8b2-c2f172a9f6e6": ["608bd561-c17d-42a6-a801-7c117c715fd3"], "1b642d13-a28a-483b-be05-5dc80068cc26": ["608bd561-c17d-42a6-a801-7c117c715fd3"], "e5190bbf-1cb6-48c2-ae8d-5fdb57124488": ["389d71c3-6613-4e7d-9d12-8f61150e6a57"], "6417c74f-6e10-4f5b-8053-6fbe574c7358": ["389d71c3-6613-4e7d-9d12-8f61150e6a57"], "f865f5df-bfb1-49c2-bda7-215f4d20d90b": ["d78354fd-3d5f-4a3c-9bf2-99ef005bf7ec"], "04643b5a-3270-445c-b78b-90d38541650c": ["d78354fd-3d5f-4a3c-9bf2-99ef005bf7ec"], "f6ff90d8-f04c-42a3-bedf-a0b99697957d": ["041cfb59-f366-4e91-beba-b871d79d5398"], "75a813dc-4ba1-4cfd-bf15-2d63bfcd0d8d": ["041cfb59-f366-4e91-beba-b871d79d5398"], "430ee8f0-4a85-4242-8174-f8174f2cfc1d": ["500574c3-5859-4039-9fae-d721e40880a8"], "6a26d8b9-20ae-4024-a7dc-9189fae68696": ["500574c3-5859-4039-9fae-d721e40880a8"], "c343cd0a-608c-4b05-84a9-d4a061f7f019": ["086351cb-446f-4324-ad7b-08319e7d6f8f"], "388c6006-2055-4b5d-bc89-fa48ae623ba0": ["086351cb-446f-4324-ad7b-08319e7d6f8f"], "33d306d3-a528-4528-8cd5-43ba60163839": ["83c8e55b-82f5-4122-9833-7aafb1753ac2"], "3c76e65b-246e-4a8d-afdb-2e91b488569a": ["83c8e55b-82f5-4122-9833-7aafb1753ac2"], "4f2aaa7a-7556-49c6-88a9-829093603584": ["0199d822-3ee7-40a4-b3e9-5ca1d70440ca"], "23ad22c3-693c-4c7e-a0ab-980657f5fca5": ["0199d822-3ee7-40a4-b3e9-5ca1d70440ca"], "9fa12471-add9-480b-a140-3cae57530a34": ["b8e57007-cb42-451b-b815-c73eb5b0146b"], "36ea99ac-9f78-4db4-b3bd-c2a268d20ce7": ["b8e57007-cb42-451b-b815-c73eb5b0146b"], "350a1822-87af-47eb-97f3-06c05950ab63": ["a2811877-bb7f-4a73-abe3-45b9cc5c240e"], "5515be41-e20c-41b0-b2d1-fe9ab4304bfe": ["a2811877-bb7f-4a73-abe3-45b9cc5c240e"], "afc6c1fb-6962-49d6-86a8-d2934475bc20": ["e59ff7fc-cb53-49b7-b47e-67feebf7da9b"], "96309fb2-8fe8-4333-9aba-3421bc01310b": ["e59ff7fc-cb53-49b7-b47e-67feebf7da9b"], "c6097f74-b0f6-4b46-b853-4e26f8b303a3": ["0914db46-283a-4964-8f45-4b535be988a1"], "732ca28f-5556-4501-ad3d-6401f4cab353": ["0914db46-283a-4964-8f45-4b535be988a1"], "fe499e35-8c01-48d8-916e-e6baa327c380": ["b5ea21ae-0edf-4e38-bce2-5032ee1f05a5"], "6fd42231-7236-4c2e-9866-4507c130a92e": ["b5ea21ae-0edf-4e38-bce2-5032ee1f05a5"], "6df0dcb9-213f-49ce-86e0-072947f59a25": ["fcde6347-d612-463a-93d3-a718a01f89cb"], "74d98cb1-65c6-49a9-b1b8-07eb49929a80": ["fcde6347-d612-463a-93d3-a718a01f89cb"], "8ada4ff1-199e-4226-bb95-babc1b57bb17": ["4ee64941-0e7a-42f7-ac71-696a24a49cf3"], "3397c162-1952-40cc-8884-ad34e60a75a2": ["4ee64941-0e7a-42f7-ac71-696a24a49cf3"], "4156166d-f251-49e7-93b9-439d1cd8bd84": ["f3ea99ed-bd39-4d7e-9159-2ccfb1b50c4d"], "bf29bc9b-402e-4877-8efb-359a0c6db3c9": ["f3ea99ed-bd39-4d7e-9159-2ccfb1b50c4d"], "307e90f5-a744-4452-b956-cc678e18d2cd": ["17b36828-7ee0-4045-84a6-339d4f3575fd"], "86b733bf-0ed6-4490-81c9-dc4f6d85e491": ["17b36828-7ee0-4045-84a6-339d4f3575fd"], "02217bfe-d5f2-40e2-915b-4ef3c09c3252": ["dcbd62ea-5c06-440e-8379-608b0a41acd9"], "b30dfa42-f7fd-4074-9f73-7032abff349c": ["dcbd62ea-5c06-440e-8379-608b0a41acd9"], "58559d9a-3ec2-40f7-ace7-2336d2c7b205": ["ade5dcda-567c-41ab-ad1c-38f6e12ec243"], "38ef40cc-5352-405e-b8eb-aa9241477bf6": ["ade5dcda-567c-41ab-ad1c-38f6e12ec243"], "6c64d0ff-7d98-4b28-9949-cd00c2eed68e": ["0ebc4cec-5f80-4254-99d8-cdf3a203660a"], "f65e1396-55f6-4fcb-ba4e-e767afae959f": ["0ebc4cec-5f80-4254-99d8-cdf3a203660a"], "94a42faf-2ba5-4ec7-8748-39a3116a4d53": ["db6eb528-d6ce-410e-8b02-f18744c447cc"], "45eba1b1-9baf-4d7d-b7a1-d08f23535f37": ["db6eb528-d6ce-410e-8b02-f18744c447cc"], "31d5f00b-c730-4a62-9bba-625b972a2a99": ["f5b6dd7a-e3d9-4b83-aaf7-a286f9c48f94"], "94ec81f7-37aa-428b-b6b7-066353feec83": ["f5b6dd7a-e3d9-4b83-aaf7-a286f9c48f94"], "491ae79f-2926-45e7-b18d-d67053b38552": ["91172346-fd8a-4b29-adf7-515e348a47cd"], "e011d282-cefb-43f5-8ab0-ea6442308303": ["91172346-fd8a-4b29-adf7-515e348a47cd"], "a50cfe25-c693-43cc-b17c-3840d6b7a160": ["e995116a-5145-450f-8430-b72c872aa61f"], "e85be9e8-a000-4db8-af5f-9486dd6dcf9e": ["e995116a-5145-450f-8430-b72c872aa61f"], "1f390439-3dd3-4ee7-948e-06e94d829624": ["4352a2e3-16b8-4abe-a151-e5a16fe76f7e"], "02022286-ecf1-4c44-9ada-ec5950cab661": ["4352a2e3-16b8-4abe-a151-e5a16fe76f7e"], "95fac599-6b25-468a-9228-68939694684c": ["26741d2e-61fe-428a-ad44-9f36ab22f995"], "d6dea6e8-5af9-4b5d-90b2-1f7dfc7c399d": ["26741d2e-61fe-428a-ad44-9f36ab22f995"], "c7366164-f8dd-4bf1-93ea-3885bc1a6808": ["ead11afb-d87b-4194-bee7-bfee7ae265cb"], "067879b6-28dd-48d3-b66a-7a02ab23130d": ["ead11afb-d87b-4194-bee7-bfee7ae265cb"], "810cc726-606e-4327-b787-083e29d37f48": ["13f2b508-0ffa-44b4-b495-d0f192adce01"], "a19bf3ba-ac6b-4f79-9ebb-09f471ee378e": ["13f2b508-0ffa-44b4-b495-d0f192adce01"], "1864bd3d-a0e7-4e05-8d70-61fcd630efaf": ["5c12d028-da33-40a0-93ec-ea3142dcbf30"], "8f65424d-1858-4821-b637-ff00e7f97807": ["5c12d028-da33-40a0-93ec-ea3142dcbf30"], "a5849622-f8c9-4ef4-b456-c07c0cd6b789": ["22960e5d-cbad-404c-b7c0-9d316b4a4542"], "cea64ad3-a16c-4010-bcfa-e944477f3312": ["22960e5d-cbad-404c-b7c0-9d316b4a4542"], "73825310-9b67-4ca5-a11e-bd3d6059048a": ["ba53ffb2-c7bd-4a9d-9323-d8297aa088cd"], "3039170b-ab00-4fab-9c24-01f9efaea2b2": ["ba53ffb2-c7bd-4a9d-9323-d8297aa088cd"], "0a751c70-b6ba-46d2-a06a-d3634c899308": ["0f491396-bcae-4aca-9116-870c5d13f11a"], "84788036-cee0-420a-859d-cb1c76227fac": ["0f491396-bcae-4aca-9116-870c5d13f11a"], "ed3efb94-fb87-4b0f-a4c3-de44b25db9a5": ["bc068d9a-3dfe-4ff8-a7a3-c05c0b2eb25d"], "882a6a65-5819-41e9-af95-7369028915b0": ["bc068d9a-3dfe-4ff8-a7a3-c05c0b2eb25d"], "847c955d-4967-4cb4-b887-e386df7e7a73": ["ce6696a4-df9c-4628-aaad-5209a52bf428"], "eb97baaf-8d09-4845-9096-8fb6246b35e7": ["ce6696a4-df9c-4628-aaad-5209a52bf428"], "519fc7a5-5312-430d-a352-88c9e629582c": ["8f911958-0105-4b8b-889f-fbdfc27c7195"], "b0d564c8-7cb6-4d8b-a17c-43705d1f3515": ["8f911958-0105-4b8b-889f-fbdfc27c7195"], "10c1772d-d5f4-44bb-9ecd-865f3c6044b2": ["7f0ce253-124d-496e-8538-efddcf8604a5"], "fd959889-7bea-4d4b-b9da-c2de4a4dda5a": ["7f0ce253-124d-496e-8538-efddcf8604a5"], "af8fa2e6-2375-4be2-aabd-11cd9580b7f8": ["10b78654-7b44-4cb3-b6b7-4e449b5e322b"], "3df35550-0416-4fa4-836e-157cfc138073": ["10b78654-7b44-4cb3-b6b7-4e449b5e322b"], "6f2ac104-7ba2-4f62-9adc-46ea4bdfec81": ["65507ba8-bfa9-4b1f-a7bf-c16015e37ed6"], "7b5f26bc-94d0-4a2a-b843-9ae3b81d81f0": ["65507ba8-bfa9-4b1f-a7bf-c16015e37ed6"], "f20a40d4-16bb-4a06-9d07-b39cd01afac9": ["aa47a658-b4cc-49c8-a4b9-0cd3b2773a03"], "e9cfb3f1-3eeb-42f7-aa22-c2c53b475122": ["aa47a658-b4cc-49c8-a4b9-0cd3b2773a03"], "63ce4b31-6a30-44d1-ab24-a0fa64a4b790": ["778311b4-ae28-41bd-a3ed-d34844586897"], "bba5f22c-3fe8-4450-8fb3-9e996e42818b": ["778311b4-ae28-41bd-a3ed-d34844586897"], "4973be89-d89f-4e04-8890-a8840c276123": ["b7d8726d-d900-479a-ac67-3fd7425a74ac"], "416cf4aa-9895-4318-9499-bdb752172e17": ["b7d8726d-d900-479a-ac67-3fd7425a74ac"], "c94162d0-9e34-49a3-82c2-614fa6fd3e2b": ["a8f97317-1e5c-4d8d-9ca3-0b4a547e3946"], "1f6f576e-ebc2-47df-87cc-3a763daf72fd": ["a8f97317-1e5c-4d8d-9ca3-0b4a547e3946"], "165cabfe-d697-4bea-ac2d-db1f7efb7b89": ["ea8c772e-89ad-4be7-b827-8dca78cd1166"], "5e3864fc-20f0-4964-843d-4f2d6a08b98f": ["ea8c772e-89ad-4be7-b827-8dca78cd1166"], "38934b1c-3153-4383-9d13-79f641cc3271": ["e85a488e-91bb-4f4c-b7e1-0643b40d8735"], "83b31149-78ca-48ad-a421-13f455dc1a5c": ["e85a488e-91bb-4f4c-b7e1-0643b40d8735"], "17c1eaeb-8a02-4304-9c3e-9ee9232a3fbd": ["0bf2cc65-f78a-429b-9cb3-5745f3b7bb32"], "a170a38a-f0bd-4a5c-89d8-0d0999b20f5e": ["0bf2cc65-f78a-429b-9cb3-5745f3b7bb32"], "bf7e4330-67aa-4c0c-b320-8dbf6dbc3711": ["5fabc5cc-353f-43a9-9909-ea4c09bbb53e"], "31afab54-9270-49c3-9bc7-bb98f3a22d38": ["5fabc5cc-353f-43a9-9909-ea4c09bbb53e"], "857595d8-8f73-48f5-97b7-4497db7f3121": ["957dafe8-ccf7-4b5d-8887-6625c5cf9503"], "da4b4aa1-da76-41b2-89b1-ae6ccb1faefc": ["957dafe8-ccf7-4b5d-8887-6625c5cf9503"], "a44f58f1-9b9d-4239-b636-44f5a9e5c11a": ["38ce99d5-4ae5-4d33-ae53-836ab54588a0"], "4e595de1-caba-41fe-a046-a040bf7ab60f": ["38ce99d5-4ae5-4d33-ae53-836ab54588a0"], "cb812d0e-d86e-4628-87e2-2ec104e62b32": ["f7e95a75-2281-4b96-9b12-c9c0a971bc9f"], "5b769470-f2da-450d-8ca9-ce1fb3f0466f": ["f7e95a75-2281-4b96-9b12-c9c0a971bc9f"], "3e42dbb8-5c1c-4406-8976-36547580f04b": ["56a1abef-1f38-4dd2-89e8-90b8290e239f"], "74366bf3-23c5-44d9-9909-ad60e9d6c0e5": ["56a1abef-1f38-4dd2-89e8-90b8290e239f"], "ebae6b5b-5715-4e92-af7d-f873b23aee58": ["8ab603b4-0897-49d1-a797-66e7d7c5e904"], "f8563ed2-de0d-4bc8-b726-30e55501a07b": ["8ab603b4-0897-49d1-a797-66e7d7c5e904"], "13365d5b-4aac-4281-afb0-b4499217165e": ["372b2dc6-2b14-4f6d-ab01-c3906b2e0a5c"], "34d901db-047b-469a-93d1-aef28ed58472": ["372b2dc6-2b14-4f6d-ab01-c3906b2e0a5c"], "861cdb16-559f-4f5a-9b46-27ad9e846d80": ["c76a613f-61c3-47f3-8c59-a224323ff10c"], "c4b4beb5-bc50-4fc0-8e5a-8d85511b0678": ["c76a613f-61c3-47f3-8c59-a224323ff10c"], "e0622975-699e-4e3b-aeba-bcbe9fa1c268": ["6e707030-f501-44b1-965a-69fbf71fb914"], "79236b46-6748-4a30-a82b-e7c674568551": ["6e707030-f501-44b1-965a-69fbf71fb914"], "3bd3efc5-a542-4a68-a216-b4879fd89c6c": ["6522b45d-8703-4d38-9df0-18ddaae3c7fb"], "1ef71476-55af-44d9-9fcf-14263974690e": ["6522b45d-8703-4d38-9df0-18ddaae3c7fb"], "b9badc0d-8ccb-448a-a966-41ab05c005ad": ["69de2498-4a88-4163-8cb4-ececf4f74a24"], "230fb635-9548-4672-b797-1b575ff48db8": ["69de2498-4a88-4163-8cb4-ececf4f74a24"], "43b40c0d-9c6c-4fcb-985c-6e8cdd4dc8f5": ["ba1769e7-8097-4eb3-ba39-0cf687648ac0"], "5fa5c49e-86b6-4b56-ab7b-2008504e664a": ["ba1769e7-8097-4eb3-ba39-0cf687648ac0"], "73d2b114-db7f-4786-827a-22e91e87cc24": ["67a09d8e-a68a-4757-8d72-0e3c9567a32d"], "d2e732ca-f3b9-41c2-837e-b129a1da3c87": ["67a09d8e-a68a-4757-8d72-0e3c9567a32d"], "6e834a06-38e0-4ab5-a8bb-4c330c8b8849": ["986c754b-5c39-4c6d-aaea-b9288bdb4a78"], "a0d654fb-227a-4891-aaac-3163ad42b8fe": ["986c754b-5c39-4c6d-aaea-b9288bdb4a78"], "b234b55d-b69d-476a-a6b6-798bfb917036": ["5b404c31-8999-4e9b-bb47-d4ea6cc8b3e8"], "ab52af4e-58ee-40c1-8390-a0e086b3a602": ["5b404c31-8999-4e9b-bb47-d4ea6cc8b3e8"], "5960f654-a577-4068-929d-6f0bf3b893ec": ["00fc56ad-0e7b-4629-933e-20c4b7fd5dac"], "55afe1aa-509f-43b4-bacf-24fa7d1117fb": ["00fc56ad-0e7b-4629-933e-20c4b7fd5dac"], "32c3fbee-70f7-4fdd-b12e-5798ff0e8c96": ["c5d4f8d5-7941-4fe6-a0b4-51320a3d1b76"], "cf120356-4331-4a32-bcf1-59997b9f3cf4": ["c5d4f8d5-7941-4fe6-a0b4-51320a3d1b76"], "755d6c81-4e63-429c-966e-4566e3ac7bd0": ["920b0e65-0035-4571-a147-437b2e5763e9"], "1cfe4880-b551-4ba6-9318-023c415eaf25": ["920b0e65-0035-4571-a147-437b2e5763e9"], "bbf89691-521e-4ef4-b704-f006409c5e0b": ["0f729b4b-7c88-4ccc-9570-8eb27956d172"], "d6bc63b1-0104-4768-bbc3-77d09544e320": ["0f729b4b-7c88-4ccc-9570-8eb27956d172"], "6b58f561-3584-40bf-82b1-e526461f6bb5": ["808e8fff-15a9-413c-8917-37b3aac27c73"], "d8aa1526-aef3-48c6-b3b5-53868a0d59f0": ["808e8fff-15a9-413c-8917-37b3aac27c73"], "0036ef04-4e58-41ec-95f1-97eaa4d03952": ["0aac1368-f7e6-41fd-b4ca-d265075f454d"], "0e2dc1a7-b6a4-4d23-915a-10fd8ba7d7c0": ["0aac1368-f7e6-41fd-b4ca-d265075f454d"], "3ee7390b-713e-442f-8e9e-c748f2509898": ["d03803cc-69e0-4b05-b335-fe57bc0bb83c"], "fd5cd8db-2d0c-45d0-ba81-afab4fb7bbbd": ["d03803cc-69e0-4b05-b335-fe57bc0bb83c"], "f8feaf50-5e49-4ca7-bbd2-fa220ee41cd6": ["c95efec3-ea28-4dfa-9ec2-2da460b84bd0"], "eb66d742-6c1b-4dc0-9047-9b7660d1310c": ["c95efec3-ea28-4dfa-9ec2-2da460b84bd0"], "478c9a2a-1d78-4631-9624-71c48fa4a9d9": ["790cf8b4-5b08-4c54-99ed-c7ed45df0e35"], "486c26b4-1176-42d0-81a8-ab2792a665f3": ["790cf8b4-5b08-4c54-99ed-c7ed45df0e35"], "3d73fb6c-18d9-4037-934a-5dab4c5fd00d": ["371f284b-3620-47fc-8118-fe7acaaf3021"], "fd3136a2-1d66-4596-b1da-bfe00c32fdaa": ["371f284b-3620-47fc-8118-fe7acaaf3021"], "bf8f397e-3fa2-404f-8e61-07fde6ea4fcb": ["996f1e36-148d-4204-9c38-fa728560b7fd"], "25ee3d67-d288-4b56-8310-ba22a663478f": ["996f1e36-148d-4204-9c38-fa728560b7fd"], "763bf30d-db02-41ff-8fb9-2c4cebc08bdb": ["7956110c-3b63-4976-96a1-d3882ab30c87"], "8985243f-eedf-4259-a2f2-80991a6a4e81": ["7956110c-3b63-4976-96a1-d3882ab30c87"], "c77b9ea8-28d9-444d-b8e6-e27141ca11a3": ["12256f0c-0d5c-4586-b73e-fe5633cbd2d4"], "e02f4d31-abb6-4969-9a35-1256007a07f8": ["12256f0c-0d5c-4586-b73e-fe5633cbd2d4"], "653aac08-c3f5-445a-865f-370d762f3b4d": ["c8e6a5ef-c53f-422b-8c75-0026f399106b"], "a6af37fa-fb89-4e4a-96d3-b5bb23a37177": ["c8e6a5ef-c53f-422b-8c75-0026f399106b"], "77eea05d-e8ca-48d1-89a2-e97a5de5eec5": ["ee5f82a4-f4b6-4470-927d-22a650a1c0cb"], "99339f1c-1f71-48a1-9801-98990bd5e233": ["ee5f82a4-f4b6-4470-927d-22a650a1c0cb"], "548cc5b4-a78d-4f27-a266-68ad5c5fe75b": ["ef41c2cd-8dc9-4af0-a821-ba39d4872b6e"], "cd576c5a-9e90-4744-bb16-fb1b6d9035c6": ["ef41c2cd-8dc9-4af0-a821-ba39d4872b6e"], "81514d81-d0f9-4894-850c-98ce264ecf0c": ["a3fcead8-12b4-4223-bd51-6da3bb130faa"], "d4e76dfc-69d7-49b6-89d7-46dc5d7f14ce": ["a3fcead8-12b4-4223-bd51-6da3bb130faa"], "069346dc-2702-47ac-b1fa-e63ceee007ea": ["b9eb35ce-4997-45d9-b48f-fc75941bf099"], "277149b9-e4c7-47c6-9443-d700150e842a": ["b9eb35ce-4997-45d9-b48f-fc75941bf099"], "6d8942b6-7c11-44d6-a758-fba9f519402f": ["98854e60-f50a-4133-adfd-ab2f4a252f92"], "ea50abc2-7dab-4dc7-a5df-81e725761de3": ["98854e60-f50a-4133-adfd-ab2f4a252f92"], "43434e05-f092-4112-874d-48eee034d2f5": ["e7167e35-434d-45ca-88c1-4e4b84c47f9b"], "0827d342-b494-4447-bc47-805f99c3708f": ["e7167e35-434d-45ca-88c1-4e4b84c47f9b"], "942580d1-fb7b-4fab-b194-e8f94f97b25f": ["87e0f6f1-73b0-4dd6-b49b-1a3a1f1c9f09"], "74fa6ef9-81f2-47ba-8633-d92ba835eeda": ["87e0f6f1-73b0-4dd6-b49b-1a3a1f1c9f09"], "ac382de5-e963-4bfa-9b5c-df62bd916530": ["8a4344c9-4c24-4180-9f2b-96f9ac05c59c"], "c30d0097-78f9-4446-a954-1614f3c9ae1c": ["8a4344c9-4c24-4180-9f2b-96f9ac05c59c"], "551b762e-4680-421b-9369-b7dc0f4b14c6": ["fe0107a5-6633-4353-9f43-d4f162a7cf04"], "060b34d3-fe93-48b2-89ea-65ad890bed00": ["fe0107a5-6633-4353-9f43-d4f162a7cf04"], "b3ff1c60-3768-47ab-b20a-d842f27f9e8f": ["b7581976-f63a-42b4-8001-1f6c4b65ceb7"], "a872ff46-6d23-462d-89d1-26137a2c28bb": ["b7581976-f63a-42b4-8001-1f6c4b65ceb7"], "d08c07b2-2399-4460-979d-60ef2bf84170": ["b1758ac6-9e80-43a0-86f5-03411a33ebc9"], "a14f23c7-a428-4756-89ab-bc878ec812f8": ["b1758ac6-9e80-43a0-86f5-03411a33ebc9"], "ef1d8fd5-d2d9-4f6e-9507-acbbf2ce511b": ["53d65668-ddd2-4e44-9769-3f0cc77534a5"], "437768ec-9ba8-481d-926f-e800cd1df5c3": ["53d65668-ddd2-4e44-9769-3f0cc77534a5"], "8869cf94-03e3-4166-aadf-727bd60e8b31": ["8be765a1-29bb-4db2-8ff5-02aa5335f03e"], "eb586687-25c6-4aa1-b8a4-c211a3d17c85": ["8be765a1-29bb-4db2-8ff5-02aa5335f03e"], "a6335481-7ed7-424c-af30-9b1c05acba60": ["9c23afc0-f4fe-42d5-a26a-d56778aee7aa"], "f3f3acb3-66b7-4f0f-83f4-cb3a00575eac": ["9c23afc0-f4fe-42d5-a26a-d56778aee7aa"], "dec930a3-4a52-4dd7-8c40-c584e80cd4f9": ["665ae071-719b-4b42-a1ca-708ecca22ef7"], "cc8eb8ef-80bc-4419-80b9-2c4c0e800b3f": ["665ae071-719b-4b42-a1ca-708ecca22ef7"], "72433b8b-1aef-4dbe-a4e4-c5771965c57f": ["0ecfcdbd-f0e0-417a-897f-7098577c7222"], "15425181-5e35-420f-b576-84602307fa54": ["0ecfcdbd-f0e0-417a-897f-7098577c7222"], "8a1dee58-1c97-43cf-a2b2-cb723b106c3b": ["4b858696-3210-478d-9363-ff239405062a"], "bcd56f3b-e57a-4e66-ae4a-255256a26c94": ["4b858696-3210-478d-9363-ff239405062a"], "ec059047-1084-43ee-b0ca-b790f9a63f85": ["c5f3f8ca-f14e-48d0-a857-95c06aa5a59b"], "6f325aeb-f5a7-4154-b238-6e98f5f03d61": ["c5f3f8ca-f14e-48d0-a857-95c06aa5a59b"], "2fc84559-a4c0-4a15-acdb-8467471aa439": ["c620282d-3a29-44e6-a805-b06d3c598453"], "526eaab7-8b79-4adf-8e91-c8a5c413411b": ["c620282d-3a29-44e6-a805-b06d3c598453"], "14e6599f-fbba-483f-a1b0-9aeb3be3d38c": ["d3f75fb8-50d6-49bb-b055-cebd1aae8486"], "f8c9a5ab-8157-49d8-a992-f567207b3eda": ["d3f75fb8-50d6-49bb-b055-cebd1aae8486"], "02fc96b2-8e70-4d73-ab71-d32de8b8aa60": ["0dbc9c68-0788-4491-a0d0-afcb8ee2b6a2"], "63d6c057-4093-4e1b-ad63-814f66e4b145": ["0dbc9c68-0788-4491-a0d0-afcb8ee2b6a2"], "24e9270d-329d-4d85-8b6a-d5fd7bbe12ce": ["777a10bb-f608-4bbb-af08-7d03a64075ee"], "57db431d-f943-4bd7-a517-528a7cfbe1c8": ["777a10bb-f608-4bbb-af08-7d03a64075ee"], "93db1398-3b91-4443-97ea-59285b92d625": ["a162f44c-25c8-4d66-bc8a-150ed86079b4"], "11258c5a-d0f6-458c-b0eb-0dfea56e0f28": ["a162f44c-25c8-4d66-bc8a-150ed86079b4"], "f240ab76-9352-40ad-914d-e9f0fc77008a": ["13040126-23d8-4d11-a7fc-6c90cf61c745"], "1c7b2708-16e1-4516-8e70-49f4bc2445e1": ["13040126-23d8-4d11-a7fc-6c90cf61c745"], "f2e2f690-1f74-4215-abfe-4ce2189ccbee": ["b5c22c81-8085-4a54-9c7a-74eae65ad870"], "f8ee13ce-de22-4486-afd9-9981fbeaebbd": ["b5c22c81-8085-4a54-9c7a-74eae65ad870"], "4f9e5858-e192-42b5-aeb1-ead4734620ec": ["63fe73e1-be67-43b1-9df9-efada6c60819"], "1e4dc283-1cd3-4ccf-b04e-d1d6d46a0616": ["63fe73e1-be67-43b1-9df9-efada6c60819"], "5bded1b1-f8b6-42eb-87c7-ee7707dbfd07": ["559da222-4baa-47b5-b46b-313d111febae"], "53748806-5803-41cf-8d2d-41f04fbc0cab": ["559da222-4baa-47b5-b46b-313d111febae"], "d9ab6799-40d9-4ebf-a90e-e8ce6c516392": ["f5c62551-37e8-429b-a82b-98dddf9316c2"], "18f57e1c-be4f-4443-b553-0bf12d3bfe45": ["f5c62551-37e8-429b-a82b-98dddf9316c2"], "5f647aff-dba4-4a06-8a9f-a5d0ff5ae062": ["94cc7ca5-3852-4772-920d-f0f44fdfbf3a"], "65955264-6a20-4528-a054-5e86603866a8": ["94cc7ca5-3852-4772-920d-f0f44fdfbf3a"], "d8f6746a-4e57-437a-a605-3b3bb8e0d76e": ["2825cf1b-852a-4f78-8610-3c07f772450d"], "4a55b659-8800-4c0e-bc5a-fee5c7d365c7": ["2825cf1b-852a-4f78-8610-3c07f772450d"], "09ff3795-c6f0-4673-acba-315f0996e697": ["9b04ca99-2f02-47cb-8bab-3dcc245a5ff7"], "5d7172e7-a02e-49b3-9f1c-6e0eaf4d7fab": ["9b04ca99-2f02-47cb-8bab-3dcc245a5ff7"], "86514d23-b3a3-4aa1-b2db-f401c1d421ee": ["411dac80-e8f5-4602-944e-3833ec8b25e4"], "e4a435fa-569c-4324-8bc8-ffab34821f18": ["411dac80-e8f5-4602-944e-3833ec8b25e4"], "cccd1498-8af8-48f2-824c-617dae955a76": ["5e6d720b-fe4e-4954-a1d3-dbef9f2f34ba"], "c2adfede-b901-4f59-b5f4-d276540393c3": ["5e6d720b-fe4e-4954-a1d3-dbef9f2f34ba"], "09f01393-367a-493c-82e8-083d525a9dc0": ["ff548cd8-9376-4e6e-869e-bd1f16de9b74"], "744a8ea0-bf94-4c2b-9b2d-4edc60a4ceb2": ["ff548cd8-9376-4e6e-869e-bd1f16de9b74"], "8fb00557-bf63-4c30-831e-3d109f5f1996": ["29348fbf-e578-4ca2-81fa-8036ce57c17f"], "46334081-aeeb-4c0f-a76d-7d0f118412c8": ["29348fbf-e578-4ca2-81fa-8036ce57c17f"], "99e88de6-a7d7-4774-94bf-a0f0c66e9338": ["70e73003-16d0-4f10-8797-14c8c3da4519"], "b93739db-81d6-462a-b18a-99ab6b2e92c5": ["70e73003-16d0-4f10-8797-14c8c3da4519"], "731726ed-1384-4885-9872-7cc5c4b62586": ["cae85576-2272-4ebd-87f2-fd959e4a7ff3"], "b9aae9cf-981b-4cde-92cd-2988a4ab9e5d": ["cae85576-2272-4ebd-87f2-fd959e4a7ff3"], "a67947f8-0a66-4290-9b63-816d75a5369c": ["015ec0fb-9137-4c2e-8b37-f6b91ecd3a8c"], "449dc11c-9e07-4f3f-bb08-55b10e8c9cf8": ["015ec0fb-9137-4c2e-8b37-f6b91ecd3a8c"], "d41c817f-ddb7-46ed-b547-258138a885c7": ["6feef133-3890-4f2f-b3fa-6ea27b9c3c4f"], "3f0648d3-8021-4c3b-b6c3-384ae596525c": ["6feef133-3890-4f2f-b3fa-6ea27b9c3c4f"], "ebf12bdc-8e81-4099-9120-51637db79ef7": ["c2cae030-50b0-4dee-b653-52627f0add18"], "5a47b49f-d495-45e1-8abb-8110a86ea3f2": ["c2cae030-50b0-4dee-b653-52627f0add18"], "15713dbb-b100-4bed-aed2-12b4d7cb1307": ["db98fcd2-6682-4549-a5ca-d42f3558622c"], "a80e6b76-9ab4-49ad-b3f4-a59e17162f92": ["db98fcd2-6682-4549-a5ca-d42f3558622c"], "8f5a0f44-808c-4f9f-abc4-9f82434f42e4": ["ef0a2737-25f6-4f88-87ac-9bdf68d40eb5"], "fc49f5bb-3886-4279-8ece-883be24b7b10": ["ef0a2737-25f6-4f88-87ac-9bdf68d40eb5"], "cc57a43a-8002-40db-8d30-c4870889855d": ["bd5ee137-f838-417c-ba32-0c5a08664d1a"], "1270243a-b658-4e7a-b9ad-ff5a2e39738e": ["bd5ee137-f838-417c-ba32-0c5a08664d1a"], "c9d0e42d-91c7-4d3e-9bad-ab2bb141df2a": ["06a4cb61-aac4-4a92-9d89-1c3e795022a7"], "f944fb43-a92e-46c2-ae48-117d7d14a5f7": ["06a4cb61-aac4-4a92-9d89-1c3e795022a7"], "9838d201-e798-4bde-89ad-c76634d4ee6f": ["fd2b93ef-86d6-4769-b47c-583cfd4ddb2e"], "66b43651-d86b-49f6-99a7-d8db5a2710e6": ["fd2b93ef-86d6-4769-b47c-583cfd4ddb2e"], "a1579016-b897-496a-b12c-f3f3f5fd9243": ["ede22497-7f88-492d-8075-d348594e3234"], "cdd58363-c9cd-4b4f-9764-c37260c4cafd": ["ede22497-7f88-492d-8075-d348594e3234"], "a1132e72-2b71-4491-b77c-cac660935be7": ["799d6f35-5486-4138-a9b3-3493176ed2c3"], "782bcc8c-943a-459b-8ef5-9db998b461ab": ["799d6f35-5486-4138-a9b3-3493176ed2c3"], "c16c793f-5e60-4cd0-b943-c2b3e9a4a47f": ["103b8c17-9774-4389-a23b-d84a8d468f61"], "9277e3ee-6b61-48dd-83c1-efbbcc4351fd": ["103b8c17-9774-4389-a23b-d84a8d468f61"], "214a76e3-cdb0-46b9-9185-443186938a3c": ["422b20c2-32ee-4861-be6a-6eab65856b66"], "5582ad26-6f6b-44a9-b5d5-fd848da9a700": ["422b20c2-32ee-4861-be6a-6eab65856b66"], "b9b7f9b9-8d46-4cdd-a413-8094f3a93c6f": ["3fa7d98f-af21-4d94-b686-f8341ff150a2"], "56bb7fcd-fca9-43e2-aaba-f4aa4b68898c": ["3fa7d98f-af21-4d94-b686-f8341ff150a2"], "19484be7-46ad-4bbd-85af-13c18c0b8b78": ["a0a7c40d-a51f-4766-807d-1e94e0b84a77"], "57993c1a-e8c0-45f0-afab-8737c76373fc": ["a0a7c40d-a51f-4766-807d-1e94e0b84a77"], "b79f7499-8b49-4c67-8393-2172e7606c7f": ["41407440-e4f6-464f-855e-b0c8c28ab852"], "0b4b43e6-10b5-403b-9536-ba479dbe9e12": ["41407440-e4f6-464f-855e-b0c8c28ab852"], "816d80a1-0772-485a-b1ae-f1a7384e1407": ["03b3a7de-febe-462f-bf4e-e3019d623bd9"], "a673faee-29db-4860-aba5-d7635415fa02": ["03b3a7de-febe-462f-bf4e-e3019d623bd9"], "bc491efb-0ab2-4733-a9e3-7f2085082402": ["7b1e072b-efeb-4f44-9cb0-5e2b2e047270"], "5964db43-850c-4ca2-8da5-cb2ebbd9df07": ["7b1e072b-efeb-4f44-9cb0-5e2b2e047270"], "25fc7d12-5dd1-4331-beeb-3a0abe234dc8": ["e223f5f2-1f0b-47c3-be9b-79704929f714"], "2d79f1ad-ca53-4aaa-9f6d-fba2e9241abf": ["e223f5f2-1f0b-47c3-be9b-79704929f714"], "8b380630-208a-4c55-966d-062a5e9a9011": ["11231f37-55a1-4c07-86b9-b26328869379"], "8468373b-2238-4dfa-bf03-7b39957896ce": ["11231f37-55a1-4c07-86b9-b26328869379"], "d41f3d7e-ccbb-4f6f-ae1b-84d1de865478": ["a21e26a6-2ebb-487c-8d55-0f0208a03238"], "89d9c052-49a7-43a5-8c7a-a3c85710eb0b": ["a21e26a6-2ebb-487c-8d55-0f0208a03238"], "2c8fa2c5-eaf6-4a67-801c-8c1dc6ce8952": ["b6a830dc-e14b-4a1a-94f3-219094067815"], "0f2fc869-a4ec-4d91-a223-58ad6dc4f398": ["b6a830dc-e14b-4a1a-94f3-219094067815"], "b53ff3e7-9c7a-4ce7-9b11-b0fe224f0a3a": ["318ef638-2789-4e83-83f7-5a5786dab2cb"], "1655aa5a-1ad2-42f7-866e-17aa2ab82839": ["318ef638-2789-4e83-83f7-5a5786dab2cb"], "214d7243-3fd2-42c2-acbc-8cb4bb577349": ["74cd7fde-9e18-43f2-8b77-99dbf2f4eea7"], "3537b252-2811-42c0-bbbf-439364d72015": ["74cd7fde-9e18-43f2-8b77-99dbf2f4eea7"], "227009f5-73b5-4982-8167-674f67fd430c": ["82ad00f2-e31e-4101-a5cb-0893dd78ed65"], "523b4958-6783-40d0-ac83-9f107027d950": ["82ad00f2-e31e-4101-a5cb-0893dd78ed65"], "d1120818-6ca3-443a-a2a7-b37a37d564d9": ["a695a967-93aa-47ea-be00-37580a0adb14"], "d9e7f269-d35c-423d-b36d-7ee5f314d24d": ["a695a967-93aa-47ea-be00-37580a0adb14"], "0c3c7fcf-cdd0-4df7-994a-8e4321981ed2": ["410cb57b-a26d-4bec-98d3-5b935884bcc6"], "11ac3348-096c-4523-9eef-b88cfab259e6": ["410cb57b-a26d-4bec-98d3-5b935884bcc6"], "08b064d7-d0db-4bba-ad77-28aaa5f58d3c": ["fdf6912d-f988-433b-9231-3fbf6364725f"], "ab1bd086-2354-4ed7-96cc-0f550ae05a98": ["fdf6912d-f988-433b-9231-3fbf6364725f"], "4f8822e6-da81-4446-83c1-e69ceb47852f": ["fd7306d0-c925-4f10-8749-a7b5c4f63c47"], "67f06504-bf89-45cf-86e6-c6716d60990c": ["fd7306d0-c925-4f10-8749-a7b5c4f63c47"], "5753d99f-826d-4052-b526-d8e76c24eead": ["28c62c74-a723-402d-bd1c-a3956f871bd1"], "6c9c1fd0-a1b9-4afb-aa5a-a59fdfaeed25": ["28c62c74-a723-402d-bd1c-a3956f871bd1"], "4fcb16bc-e618-4d2d-a74f-b11b83d1c8b3": ["64a2f22c-c3ca-43fb-9f8c-450dbe50a276"], "321f3d69-1c79-47b9-b597-55f9ff1936c2": ["64a2f22c-c3ca-43fb-9f8c-450dbe50a276"], "85305491-3146-4832-9c4b-4ba64eddbbb7": ["135b45e2-ccf1-4747-90fc-79a245039430"], "45505d03-3864-4838-b03b-b0323b492b3c": ["135b45e2-ccf1-4747-90fc-79a245039430"], "8cea9dd3-2a0c-4dbf-8917-a237ab2779d8": ["3674534d-fa75-4343-8c4e-ca172de56870"], "a33fcd18-3083-4a37-ae9e-584f58f19626": ["3674534d-fa75-4343-8c4e-ca172de56870"], "c04c3ef5-fc22-485b-b837-d0022ca05dba": ["6a10cc6c-3e2a-4d1c-935b-bf08bbf5997e"], "e86f13e1-c0b7-4ee9-90dd-6d4420591789": ["6a10cc6c-3e2a-4d1c-935b-bf08bbf5997e"], "725035af-ce84-41e8-a51a-2ff9ee7b3038": ["90681c8b-f805-4730-a21e-df9b835317d1"], "29f7e13b-4e48-4502-aa77-65ab9da6f304": ["90681c8b-f805-4730-a21e-df9b835317d1"], "9d897557-b011-4e1f-ac9f-b07cb471f683": ["43216f70-fa39-49f0-a909-c61fc6c2abca"], "007c1095-b237-4cf8-9186-1911d363b072": ["43216f70-fa39-49f0-a909-c61fc6c2abca"], "c52783a7-cbe8-4efc-a470-f4ac8250a737": ["220b6c91-144c-4c5a-a454-cdf813a7b8a0"], "1a8ada12-c96f-4b7e-a0ed-077023394efc": ["220b6c91-144c-4c5a-a454-cdf813a7b8a0"], "de34dd81-1c67-41da-a981-89f79dc2d0aa": ["dd02b536-3fb1-4c17-b6ff-30fc35655c74"], "0fa06655-c9c0-4704-a952-f17dc84a4960": ["dd02b536-3fb1-4c17-b6ff-30fc35655c74"]}, "corpus": {"267aeb76-7161-4873-8649-16b83839ebdd": "BLUEPRINT FOR AN \nAI BILL OF \nRIGHTS \nMAKING AUTOMATED \nSYSTEMS WORK FOR \nTHE AMERICAN PEOPLE \nOCTOBER 2022", "69de2498-4a88-4163-8cb4-ececf4f74a24": "About this Document \nThe Blueprint for an AI Bill of Rights: Making Automated Systems Work for the American People was \npublished by the White House Office of Science and Technology Policy in October 2022. This framework was \nreleased one year after OSTP announced the launch of a process to develop \u201ca bill of rights for an AI-powered \nworld.\u201d Its release follows a year of public engagement to inform this initiative. The framework is available \nonline at: https://www.whitehouse.gov/ostp/ai-bill-of-rights \nAbout the Office of Science and Technology Policy \nThe Office of Science and Technology Policy (OSTP) was established by the National Science and Technology", "0ecfcdbd-f0e0-417a-897f-7098577c7222": "Policy, Organization, and Priorities Act of 1976 to provide the President and others within the Executive Office \nof the President with advice on the scientific, engineering, and technological aspects of the economy, national \nsecurity, health, foreign relations, the environment, and the technological recovery and use of resources, among \nother topics. OSTP leads interagency science and technology policy coordination efforts, assists the Office of \nManagement and Budget (OMB) with an annual review and analysis of Federal research and development in \nbudgets, and serves as a source of scientific and technological analysis and judgment for the President with \nrespect to major policies, plans, and programs of the Federal Government.", "422b20c2-32ee-4861-be6a-6eab65856b66": "Legal Disclaimer \nThe Blueprint for an AI Bill of Rights: Making Automated Systems Work for the American People is a white paper \npublished by the White House Office of Science and Technology Policy. It is intended to support the \ndevelopment of policies and practices that protect civil rights and promote democratic values in the building, \ndeployment, and governance of automated systems. \nThe Blueprint for an AI Bill of Rights is non-binding and does not constitute U.S. government policy. It \ndoes not supersede, modify, or direct an interpretation of any existing statute, regulation, policy, or \ninternational instrument. It does not constitute binding guidance for the public or Federal agencies and", "5b404c31-8999-4e9b-bb47-d4ea6cc8b3e8": "therefore does not require compliance with the principles described herein. It also is not determinative of what \nthe U.S. government\u2019s position will be in any international negotiation. Adoption of these principles may not \nmeet the requirements of existing statutes, regulations, policies, or international instruments, or the \nrequirements of the Federal agencies that enforce them. These principles are not intended to, and do not, \nprohibit or limit any lawful activity of a government agency, including law enforcement, national security, or \nintelligence activities. \nThe appropriate application of the principles set forth in this white paper depends significantly on the", "14b7715e-bd7d-48c3-a332-434d3ee4c402": "context in which automated systems are being utilized. In some circumstances, application of these principles \nin whole or in part may not be appropriate given the intended use of automated systems to achieve government \nagency missions. Future sector-specific guidance will likely be necessary and important for guiding the use of \nautomated systems in certain settings such as AI systems used as part of school building security or automated \nhealth diagnostic systems. \nThe Blueprint for an AI Bill of Rights recognizes that law enforcement activities require a balancing of \nequities, for example, between the protection of sensitive law enforcement information and the principle of", "7bbb4e26-9509-4777-ac17-764dec27516f": "notice; as such, notice may not be appropriate, or may need to be adjusted to protect sources, methods, and \nother law enforcement equities. Even in contexts where these principles may not apply in whole or in part, \nfederal departments and agencies remain subject to judicial, privacy, and civil liberties oversight as well as \nexisting policies and safeguards that govern automated systems, including, for example, Executive Order 13960, \nPromoting the Use of Trustworthy Artificial Intelligence in the Federal Government (December 2020). \nThis white paper recognizes that national security (which includes certain law enforcement and \nhomeland security activities) and defense activities are of increased sensitivity and interest to our nation\u2019s", "b2ee1df2-173d-4a98-8589-7831652e7dc7": "adversaries and are often subject to special requirements, such as those governing classified information and \nother protected data. Such activities require alternative, compatible safeguards through existing policies that \ngovern automated systems and AI, such as the Department of Defense (DOD) AI Ethical Principles and \nResponsible AI Implementation Pathway and the Intelligence Community (IC) AI Ethics Principles and \nFramework. The implementation of these policies to national security and defense activities can be informed by \nthe Blueprint for an AI Bill of Rights where feasible. \nThe Blueprint for an AI Bill of Rights is not intended to, and does not, create any legal right, benefit, or", "bd013e69-90b6-43c3-9c37-99443d5eb795": "defense, substantive or procedural, enforceable at law or in equity by any party against the United States, its \ndepartments, agencies, or entities, its officers, employees, or agents, or any other person, nor does it constitute a \nwaiver of sovereign immunity. \nCopyright Information \nThis document is a work of the United States Government and is in the public domain (see 17 U.S.C. \u00a7105). \n2", "215df9f8-01b9-4fc2-bff1-0146f000950a": "SECTION TITLE\u00ad\nFOREWORD\nAmong the great challenges posed to democracy today is the use of technology, data, and automated systems in \nways that threaten the rights of the American public. Too often, these tools are used to limit our opportunities and \nprevent our access to critical resources or services. These problems are well documented. In America and around \nthe world, systems supposed to help with patient care have proven unsafe, ineffective, or biased. Algorithms used \nin hiring and credit decisions have been found to reflect and reproduce existing unwanted inequities or embed \nnew harmful bias and discrimination. Unchecked social media data collection has been used to threaten people\u2019s", "f0d8a48c-79b2-4109-831e-044c35f0dba6": "opportunities, undermine their privacy, or pervasively track their activity\u2014often without their knowledge or \nconsent. \nThese outcomes are deeply harmful\u2014but they are not inevitable. Automated systems have brought about extraor-\ndinary benefits, from technology that helps farmers grow food more efficiently and computers that predict storm \npaths, to algorithms that can identify diseases in patients. These tools now drive important decisions across \nsectors, while data is helping to revolutionize global industries. Fueled by the power of American innovation, \nthese tools hold the potential to redefine every part of our society and make life better for everyone.", "41014a29-ff68-4181-80ae-32faa6fe7a4e": "This important progress must not come at the price of civil rights or democratic values, foundational American \nprinciples that President Biden has affirmed as a cornerstone of his Administration. On his first day in office, the \nPresident ordered the full Federal government to work to root out inequity, embed fairness in decision-\nmaking processes, and affirmatively advance civil rights, equal opportunity, and racial justice in America.1 The \nPresident has spoken forcefully about the urgent challenges posed to democracy today and has regularly called \non people of conscience to act to preserve civil rights\u2014including the right to privacy, which he has called \u201cthe", "f98d24fc-7104-4613-9a3d-d799566cae2a": "basis for so many more rights that we have come to take for granted that are ingrained in the fabric of this \ncountry.\u201d2\nTo advance President Biden\u2019s vision, the White House Office of Science and Technology Policy has identified \nfive principles that should guide the design, use, and deployment of automated systems to protect the American \npublic in the age of artificial intelligence. The Blueprint for an AI Bill of Rights is a guide for a society that \nprotects all people from these threats\u2014and uses technologies in ways that reinforce our highest values. \nResponding to the experiences of the American public, and informed by insights from researchers,", "ae371cc6-2614-4057-95f6-cdae9fa3b08a": "technologists, advocates, journalists, and policymakers, this framework is accompanied by a technical \ncompanion\u2014a handbook for anyone seeking to incorporate these protections into policy and practice, including \ndetailed steps toward actualizing these principles in the technological design process. These principles help \nprovide guidance whenever automated systems can meaningfully impact the public\u2019s rights, opportunities, \nor access to critical needs. \n3", "bd5ee137-f838-417c-ba32-0c5a08664d1a": "ABOUT THIS FRAMEWORK\u00ad\u00ad\u00ad\u00ad\u00ad\nThe Blueprint for an AI Bill of Rights is a set of five principles and associated practices to help guide the \ndesign, use, and deployment of automated systems to protect the rights of the American public in the age of \nartificial intel-ligence. Developed through extensive consultation with the American public, these principles are \na blueprint for building and deploying automated systems that are aligned with democratic values and protect \ncivil rights, civil liberties, and privacy. The Blueprint for an AI Bill of Rights includes this Foreword, the five \nprinciples, notes on Applying the The Blueprint for an AI Bill of Rights, and a Technical Companion that gives", "665ae071-719b-4b42-a1ca-708ecca22ef7": "concrete steps that can be taken by many kinds of organizations\u2014from governments at all levels to companies of \nall sizes\u2014to uphold these values. Experts from across the private sector, governments, and international \nconsortia have published principles and frameworks to guide the responsible use of automated systems; this \nframework provides a national values statement and toolkit that is sector-agnostic to inform building these \nprotections into policy, practice, or the technological design process.  Where existing law or policy\u2014such as \nsector-specific privacy laws and oversight requirements\u2014do not already provide guidance, the Blueprint for an \nAI Bill of Rights should be used to inform policy decisions.", "c95efec3-ea28-4dfa-9ec2-2da460b84bd0": "LISTENING TO THE AMERICAN PUBLIC\nThe White House Office of Science and Technology Policy has led a year-long process to seek and distill input \nfrom people across the country\u2014from impacted communities and industry stakeholders to technology develop-\ners and other experts across fields and sectors, as well as policymakers throughout the Federal government\u2014on \nthe issue of algorithmic and data-driven harms and potential remedies. Through panel discussions, public listen-\ning sessions, meetings, a formal request for information, and input to a publicly accessible and widely-publicized \nemail address, people throughout the United States, public servants across Federal agencies, and members of the", "d3cb4069-9e89-4ae1-9279-6c84a317223e": "international community spoke up about both the promises and potential harms of these technologies, and \nplayed a central role in shaping the Blueprint for an AI Bill of Rights. The core messages gleaned from these \ndiscussions include that AI has transformative potential to improve Americans\u2019 lives, and that preventing the \nharms of these technologies is both necessary and achievable. The Appendix includes a full list of public engage-\nments. \n4", "a05de235-758e-48b1-a8b0-a0f0bd7c040b": "AI BILL OF RIGHTS\nFFECTIVE SYSTEMS\nineffective systems. Automated systems should be \ncommunities, stakeholders, and domain experts to identify \nSystems should undergo pre-deployment testing, risk \nthat demonstrate they are safe and effective based on \nincluding those beyond the intended use, and adherence to \nprotective measures should include the possibility of not \nAutomated systems should not be designed with an intent \nreasonably foreseeable possibility of endangering your safety or the safety of your community. They should \nstemming from unintended, yet foreseeable, uses or \n \n \n \n \n  \n \n \nSECTION TITLE\nBLUEPRINT FOR AN\nSAFE AND E \nYou should be protected from unsafe or \ndeveloped with consultation from diverse", "0eb0daa8-88da-4c0f-b273-950ddddcde34": "concerns, risks, and potential impacts of the system. \nidentification and mitigation, and ongoing monitoring \ntheir intended use, mitigation of unsafe outcomes \ndomain-specific standards. Outcomes of these \ndeploying the system or removing a system from use. \nor \nbe designed to proactively protect you from harms \nimpacts of automated systems. You should be protected from inappropriate or irrelevant data use in the \ndesign, development, and deployment of automated systems, and from the compounded harm of its reuse. \nIndependent evaluation and reporting that confirms that the system is safe and effective, including reporting of \nsteps taken to mitigate potential harms, should be performed and the results made public whenever possible.", "4352a2e3-16b8-4abe-a151-e5a16fe76f7e": "ALGORITHMIC DISCRIMINATION PROTECTIONS\nYou should not face discrimination by algorithms and systems should be used and designed in \nan equitable way. Algorithmic discrimination occurs when automated systems contribute to unjustified \ndifferent treatment or impacts disfavoring people based on their race, color, ethnicity, sex (including \npregnancy, childbirth, and related medical conditions, gender identity, intersex status, and sexual \norientation), religion, age, national origin, disability, veteran status, genetic information, or any other \nclassification protected by law. Depending on the specific circumstances, such algorithmic discrimination", "ba7bf32a-73e7-4d13-a237-6f125aaa9baf": "may violate legal protections. Designers, developers, and deployers of automated systems should take \nproactive \nand \ncontinuous \nmeasures \nto \nprotect \nindividuals \nand \ncommunities \nfrom algorithmic \ndiscrimination and to use and design systems in an equitable way. This protection should include proactive \nequity assessments as part of the system design, use of representative data and protection against proxies \nfor demographic features, ensuring accessibility for people with disabilities in design and development, \npre-deployment and ongoing disparity testing and mitigation, and clear organizational oversight. Independent \nevaluation and plain language reporting in the form of an algorithmic impact assessment, including", "ee260027-c2db-4f31-8bad-80cc728184a6": "disparity testing results and mitigation information, should be performed and made public whenever \npossible to confirm these protections. \n5", "ee4a53b4-3703-463b-b267-bfa5a27926fa": "SECTION TITLE\nDATA PRIVACY\nYou should be protected from abusive data practices via built-in protections and you \nshould have agency over how data about you is used. You should be protected from violations of \nprivacy through design choices that ensure such protections are included by default, including ensuring that \ndata collection conforms to reasonable expectations and that only data strictly necessary for the specific \ncontext is collected. Designers, developers, and deployers of automated systems should seek your permission \nand respect your decisions regarding collection, use, access, transfer, and deletion of your data in appropriate", "c7851f7b-26db-4f5f-b8fb-cb67492e6907": "ways and to the greatest extent possible; where not possible, alternative privacy by design safeguards should be \nused. Systems should not employ user experience and design decisions that obfuscate user choice or burden \nusers with defaults that are privacy invasive. Consent should only be used to justify collection of data in cases \nwhere it can be appropriately and meaningfully given. Any consent requests should be brief, be understandable \nin plain language, and give you agency over data collection and the specific context of use; current hard-to\u00ad\nunderstand notice-and-choice practices for broad uses of data should be changed. Enhanced protections and", "0199d822-3ee7-40a4-b3e9-5ca1d70440ca": "restrictions for data and inferences related to sensitive domains, including health, work, education, criminal \njustice, and finance, and for data pertaining to youth should put you first. In sensitive domains, your data and \nrelated inferences should only be used for necessary functions, and you should be protected by ethical review \nand use prohibitions. You and your communities should be free from unchecked surveillance; surveillance \ntechnologies should be subject to heightened oversight that includes at least pre-deployment assessment of their \npotential harms and scope limits to protect privacy and civil liberties. Continuous surveillance and monitoring", "563ec54e-cdb1-4365-9e82-445211d2045e": "should not be used in education, work, housing, or in other contexts where the use of such surveillance \ntechnologies is likely to limit rights, opportunities, or access. Whenever possible, you should have access to \nreporting that confirms your data decisions have been respected and provides an assessment of the \npotential impact of surveillance technologies on your rights, opportunities, or access. \nNOTICE AND EXPLANATION\nYou should know that an automated system is being used and understand how and why it \ncontributes to outcomes that impact you. Designers, developers, and deployers of automated systems \nshould provide generally accessible plain language documentation including clear descriptions of the overall", "59afe854-c372-434e-8ac4-5d9c3b9825e8": "system functioning and the role automation plays, notice that such systems are in use, the individual or organiza\u00ad\ntion responsible for the system, and explanations of outcomes that are clear, timely, and accessible. Such notice \nshould be kept up-to-date and people impacted by the system should be notified of significant use case or key \nfunctionality changes. You should know how and why an outcome impacting you was determined by an \nautomated system, including when the automated system is not the sole input determining the outcome. \nAutomated systems should provide explanations that are technically valid, meaningful and useful to you and to", "10b78654-7b44-4cb3-b6b7-4e449b5e322b": "any operators or others who need to understand the system, and calibrated to the level of risk based on the \ncontext. Reporting that includes summary information about these automated systems in plain language and \nassessments of the clarity and quality of the notice and explanations should be made public whenever possible. \n6", "6a10cc6c-3e2a-4d1c-935b-bf08bbf5997e": "SECTION TITLE\nHUMAN ALTERNATIVES, CONSIDERATION, AND FALLBACK\nYou should be able to opt out, where appropriate, and have access to a person who can quickly \nconsider and remedy problems you encounter. You should be able to opt out from automated systems in \nfavor of a human alternative, where appropriate. Appropriateness should be determined based on reasonable \nexpectations in a given context and with a focus on ensuring broad accessibility and protecting the public from \nespecially harmful impacts. In some cases, a human or other alternative may be required by law. You should have \naccess to timely human consideration and remedy by a fallback and escalation process if an automated system", "ea311268-962f-4326-b89b-5e2f9e9614d3": "fails, it produces an error, or you would like to appeal or contest its impacts on you. Human consideration and \nfallback should be accessible, equitable, effective, maintained, accompanied by appropriate operator training, and \nshould not impose an unreasonable burden on the public. Automated systems with an intended use within sensi\u00ad\ntive domains, including, but not limited to, criminal justice, employment, education, and health, should additional\u00ad\nly be tailored to the purpose, provide meaningful access for oversight, include training for any people interacting \nwith the system, and incorporate human consideration for adverse or high-risk decisions. Reporting that includes", "b1758ac6-9e80-43a0-86f5-03411a33ebc9": "a description of these human governance processes and assessment of their timeliness, accessibility, outcomes, \nand effectiveness should be made public whenever possible. \nDefinitions for key terms in The Blueprint for an AI Bill of Rights can be found in Applying the Blueprint for an AI Bill of Rights. \nAccompanying analysis and tools for actualizing each principle can be found in the Technical Companion. \n7", "53d65668-ddd2-4e44-9769-3f0cc77534a5": "SECTION TITLE\nApplying The Blueprint for an AI Bill of Rights \nWhile many of the concerns addressed in this framework derive from the use of AI, the technical \ncapabilities and specific definitions of such systems change with the speed of innovation, and the potential \nharms of their use occur even with less technologically sophisticated tools. Thus, this framework uses a two-\npart test to determine what systems are in scope. This framework applies to (1) automated systems that (2) \nhave the potential to meaningfully impact the American public\u2019s rights, opportunities, or access to \ncritical resources or services. These rights, opportunities, and access to critical resources of services should", "0f2e095b-28df-4700-97f6-df7b4adb2632": "be enjoyed equally and be fully protected, regardless of the changing role that automated systems may play in \nour lives. \nThis framework describes protections that should be applied with respect to all automated systems that \nhave the potential to meaningfully impact individuals' or communities' exercise of: \nRIGHTS, OPPORTUNITIES, OR ACCESS\nCivil rights, civil liberties, and privacy, including freedom of speech, voting, and protections from discrimi\u00ad\nnation, excessive punishment, unlawful surveillance, and violations of privacy and other freedoms in both \npublic and private sector contexts; \nEqual opportunities, including equitable access to education, housing, credit, employment, and other \nprograms; or,", "ca9147e1-84ff-4b61-8ad1-e9ede2855126": "programs; or, \nAccess to critical resources or services, such as healthcare, financial services, safety, social services, \nnon-deceptive information about goods and services, and government benefits. \nA list of examples of automated systems for which these principles should be considered is provided in the \nAppendix. The Technical Companion, which follows, offers supportive guidance for any person or entity that \ncreates, deploys, or oversees automated systems. \nConsidered together, the five principles and associated practices of the Blueprint for an AI Bill of \nRights form an overlapping set of backstops against potential harms. This purposefully overlapping", "bffcaec0-d2bd-4800-8d40-3c3a8c11a875": "framework, when taken as a whole, forms a blueprint to help protect the public from harm. \nThe measures taken to realize the vision set forward in this framework should be proportionate \nwith the extent and nature of the harm, or risk of harm, to people's rights, opportunities, and \naccess. \nRELATIONSHIP TO EXISTING LAW AND POLICY\nThe Blueprint for an AI Bill of Rights is an exercise in envisioning a future where the American public is \nprotected from the potential harms, and can fully enjoy the benefits, of automated systems. It describes princi\u00ad\nples that can help ensure these protections. Some of these protections are already required by the U.S. Constitu\u00ad", "a162f44c-25c8-4d66-bc8a-150ed86079b4": "tion or implemented under existing U.S. laws. For example, government surveillance, and data search and \nseizure are subject to legal requirements and judicial oversight. There are Constitutional requirements for \nhuman review of criminal investigative matters and statutory requirements for judicial review. Civil rights laws \nprotect the American people against discrimination. \n8", "38ce99d5-4ae5-4d33-ae53-836ab54588a0": "SECTION TITLE\n \n \n \n \n \n \nApplying The Blueprint for an AI Bill of Rights \nRELATIONSHIP TO EXISTING LAW AND POLICY\nThere are regulatory safety requirements for medical devices, as well as sector-, population-, or technology-spe\u00ad\ncific privacy and security protections. Ensuring some of the additional protections proposed in this framework \nwould require new laws to be enacted or new policies and practices to be adopted. In some cases, exceptions to \nthe principles described in the Blueprint for an AI Bill of Rights may be necessary to comply with existing law, \nconform to the practicalities of a specific use case, or balance competing public interests. In particular, law", "ff4fc6a3-79b8-46a6-908a-5825d5636f99": "enforcement, and other regulatory contexts may require government actors to protect civil rights, civil liberties, \nand privacy in a manner consistent with, but using alternate mechanisms to, the specific principles discussed in \nthis framework. The Blueprint for an AI Bill of Rights is meant to assist governments and the private sector in \nmoving principles into practice. \nThe expectations given in the Technical Companion are meant to serve as a blueprint for the development of \nadditional technical standards and practices that should be tailored for particular sectors and contexts. While \nexisting laws informed the development of the Blueprint for an AI Bill of Rights, this framework does not detail", "b75b0701-dbd3-458e-a174-d1b59a580802": "those laws beyond providing them as examples, where appropriate, of existing protective measures. This \nframework instead shares a broad, forward-leaning vision of recommended principles for automated system \ndevelopment and use to inform private and public involvement with these systems where they have the poten\u00ad\ntial to meaningfully impact rights, opportunities, or access. Additionally, this framework does not analyze or \ntake a position on legislative and regulatory proposals in municipal, state, and federal government, or those in \nother countries. \nWe have seen modest progress in recent years, with some state and local governments responding to these prob\u00ad", "286f9b15-50c8-4579-803e-33a82492c45a": "lems with legislation, and some courts extending longstanding statutory protections to new and emerging tech\u00ad\nnologies. There are companies working to incorporate additional protections in their design and use of auto\u00ad\nmated systems, and researchers developing innovative guardrails. Advocates, researchers, and government \norganizations have proposed principles for the ethical use of AI and other automated systems. These include \nthe Organization for Economic Co-operation and Development\u2019s (OECD\u2019s) 2019 Recommendation on Artificial \nIntelligence, which includes principles for responsible stewardship of trustworthy AI and which the United", "5c41b57f-5e28-4896-a585-6756c2e76c63": "States adopted, and Executive Order 13960 on Promoting the Use of Trustworthy Artificial Intelligence in the \nFederal Government, which sets out principles that govern the federal government\u2019s use of AI. The Blueprint \nfor an AI Bill of Rights is fully consistent with these principles and with the direction in Executive Order 13985 \non Advancing Racial Equity and Support for Underserved Communities Through the Federal Government. \nThese principles find kinship in the Fair Information Practice Principles (FIPPs), derived from the 1973 report \nof an advisory committee to the U.S. Department of Health, Education, and Welfare, Records, Computers,", "b38fad9f-bf31-4780-b089-7b343c57208f": "and the Rights of Citizens.4 While there is no single, universal articulation of the FIPPs, these core \nprinciples for managing information about individuals have been incorporated into data privacy laws and \npolicies across the globe.5 The Blueprint for an AI Bill of Rights embraces elements of the FIPPs that are \nparticularly relevant to automated systems, without articulating a specific set of FIPPs or scoping \napplicability or the interests served to a single particular domain, like privacy, civil rights and civil liberties, \nethics, or risk management. The Technical Companion builds on this prior work to provide practical next \nsteps to move these principles into practice and promote common approaches that allow technological", "8fdab119-6819-4957-ae62-2cd19f5422af": "innovation to flourish while protecting people from harm. \n9", "c7a9b913-57c9-49ed-b3e4-6c0654a50993": "Applying The Blueprint for an AI Bill of Rights \nDEFINITIONS\nALGORITHMIC DISCRIMINATION: \u201cAlgorithmic discrimination\u201d occurs when automated systems \ncontribute to unjustified different treatment or impacts disfavoring people based on their race, color, ethnicity, \nsex (including pregnancy, childbirth, and related medical conditions, gender identity, intersex status, and sexual \norientation), religion, age, national origin, disability, veteran status, genetic information, or any other classifica-\ntion protected by law. Depending on the specific circumstances, such algorithmic discrimination may violate \nlegal protections. Throughout this framework the term \u201calgorithmic discrimination\u201d takes this meaning (and", "b8244a0f-64aa-4ccf-86c4-ee5fab04bd61": "not a technical understanding of discrimination as distinguishing between items). \nAUTOMATED SYSTEM: An \"automated system\" is any system, software, or process that uses computation as \nwhole or part of a system to determine outcomes, make or aid decisions, inform policy implementation, collect \ndata or observations, or otherwise interact with individuals and/or communities. Automated systems \ninclude, but are not limited to, systems derived from machine learning, statistics, or other data processing \nor artificial intelligence techniques, and exclude passive computing infrastructure. \u201cPassive computing \ninfrastructure\u201d is any intermediary technology that does not influence or determine the outcome of decision,", "7f96d90a-30fa-475a-8d3e-a9581fa02e56": "make or aid in decisions, inform policy implementation, or collect data or observations, including web \nhosting, domain registration, networking, caching, data storage, or cybersecurity. Throughout this \nframework, automated systems that are considered in scope are only those that have the potential to \nmeaningfully impact individuals\u2019 or communi-ties\u2019 rights, opportunities, or access. \nCOMMUNITIES: \u201cCommunities\u201d include: neighborhoods; social network connections (both online and \noffline); families (construed broadly); people connected by affinity, identity, or shared traits; and formal organi-\nzational ties. This includes Tribes, Clans, Bands, Rancherias, Villages, and other Indigenous communities. AI", "74cd7fde-9e18-43f2-8b77-99dbf2f4eea7": "and other data-driven automated systems most directly collect data on, make inferences about, and may cause \nharm to individuals. But the overall magnitude of their impacts may be most readily visible at the level of com-\nmunities. Accordingly, the concept of community is integral to the scope of the Blueprint for an AI Bill of Rights. \nUnited States law and policy have long employed approaches for protecting the rights of individuals, but exist-\ning frameworks have sometimes struggled to provide protections when effects manifest most clearly at a com-\nmunity level. For these reasons, the Blueprint for an AI Bill of Rights asserts that the harms of automated", "9ea3314d-c0b7-4724-96bd-c98e3628f269": "systems should be evaluated, protected against, and redressed at both the individual and community levels. \nEQUITY: \u201cEquity\u201d means the consistent and systematic fair, just, and impartial treatment of all individuals. \nSystemic, fair, and just treatment must take into account the status of individuals who belong to underserved \ncommunities that have been denied such treatment, such as Black, Latino, and Indigenous and Native American \npersons, Asian Americans and Pacific Islanders and other persons of color; members of religious minorities; \nwomen, girls, and non-binary people; lesbian, gay, bisexual, transgender, queer, and intersex (LGBTQI+)", "7340a371-67a8-4489-9fcc-0e0a88639ed2": "persons; older adults; persons with disabilities; persons who live in rural areas; and persons otherwise adversely \naffected by persistent poverty or inequality. \nRIGHTS, OPPORTUNITIES, OR ACCESS: \u201cRights, opportunities, or access\u201d is used to indicate the scoping \nof this framework. It describes the set of: civil rights, civil liberties, and privacy, including freedom of speech, \nvoting, and protections from discrimination, excessive punishment, unlawful surveillance, and violations of \nprivacy and other freedoms in both public and private sector contexts; equal opportunities, including equitable \naccess to education, housing, credit, employment, and other programs; or, access to critical resources or", "60ed1fa9-ab5c-4f1f-9936-246f7d980b34": "services, such as healthcare, financial services, safety, social services, non-deceptive information about goods \nand services, and government benefits. \n10", "9cf9a362-96b8-42c4-b213-09e8aa52b4c6": "Applying The Blueprint for an AI Bill of Rights \nSENSITIVE DATA: Data and metadata are sensitive if they pertain to an individual in a sensitive domain \n(defined below); are generated by technologies used in a sensitive domain; can be used to infer data from a \nsensitive domain or sensitive data about an individual (such as disability-related data, genomic data, biometric \ndata, behavioral data, geolocation data, data related to interaction with the criminal justice system, relationship \nhistory and legal status such as custody and divorce information, and home, work, or school environmental \ndata); or have the reasonable potential to be used in ways that are likely to expose individuals to meaningful", "086351cb-446f-4324-ad7b-08319e7d6f8f": "harm, such as a loss of privacy or financial harm due to identity theft. Data and metadata generated by or about \nthose who are not yet legal adults is also sensitive, even if not related to a sensitive domain. Such data includes, \nbut is not limited to, numerical, text, image, audio, or video data. \nSENSITIVE DOMAINS: \u201cSensitive domains\u201d are those in which activities being conducted can cause material \nharms, including significant adverse effects on human rights such as autonomy and dignity, as well as civil liber\u00ad\nties and civil rights. Domains that have historically been singled out as deserving of enhanced data protections \nor where such enhanced protections are reasonably expected by the public include, but are not limited to,", "041cfb59-f366-4e91-beba-b871d79d5398": "health, family planning and care, employment, education, criminal justice, and personal finance. In the context \nof this framework, such domains are considered sensitive whether or not the specifics of a system context \nwould necessitate coverage under existing law, and domains and data that are considered sensitive are under\u00ad\nstood to change over time based on societal norms and context. \nSURVEILLANCE TECHNOLOGY: \u201cSurveillance technology\u201d refers to products or services marketed for \nor that can be lawfully used to detect, monitor, intercept, collect, exploit, preserve, protect, transmit, and/or \nretain data, identifying information, or communications concerning individuals or groups. This framework", "83c8e55b-82f5-4122-9833-7aafb1753ac2": "limits its focus to both government and commercial use of surveillance technologies when juxtaposed with \nreal-time or subsequent automated analysis and when such systems have a potential for meaningful impact \non individuals\u2019 or communities\u2019 rights, opportunities, or access. \nUNDERSERVED COMMUNITIES: The term \u201cunderserved communities\u201d refers to communities that have \nbeen systematically denied a full opportunity to participate in aspects of economic, social, and civic life, as \nexemplified by the list in the preceding definition of \u201cequity.\u201d \n11", "79ee0771-c7c3-404c-a347-ac22684f44bd": "FROM \nPRINCIPLES \nTO PRACTICE \nA TECHINCAL COMPANION TO\nTHE Blueprint for an \nAI BILL OF RIGHTS\n12", "1d158095-1a03-4e45-9a4c-ca965c847edc": "TABLE OF CONTENTS\nFROM PRINCIPLES TO PRACTICE: A TECHNICAL COMPANION TO THE BLUEPRINT \nFOR AN AI BILL OF RIGHTS \n \nUSING THIS TECHNICAL COMPANION\n \nSAFE AND EFFECTIVE SYSTEMS\n \nALGORITHMIC DISCRIMINATION PROTECTIONS\n \nDATA PRIVACY\n \nNOTICE AND EXPLANATION\n \nHUMAN ALTERNATIVES, CONSIDERATION, AND FALLBACK\nAPPENDIX\n \nEXAMPLES OF AUTOMATED SYSTEMS\n \nLISTENING TO THE AMERICAN PEOPLE\nENDNOTES \n12\n14\n15\n23\n30\n40\n46\n53\n53\n55\n63\n13", "2dddb78c-a2e8-4459-8024-5dfd638b3e9b": "-    \nUSING THIS TECHNICAL COMPANION\nThe Blueprint for an AI Bill of Rights is a set of five principles and associated practices to help guide the design, \nuse, and deployment of automated systems to protect the rights of the American public in the age of artificial \nintelligence. This technical companion considers each principle in the Blueprint for an AI Bill of Rights and \nprovides examples and concrete steps for communities, industry, governments, and others to take in order to \nbuild these protections into policy, practice, or the technological design process. \nTaken together, the technical protections and practices laid out in the Blueprint for an AI Bill of Rights can help", "7b2946e4-8724-41bc-ae7d-ff2996cda535": "guard the American public against many of the potential and actual harms identified by researchers, technolo\u00ad\ngists, advocates, journalists, policymakers, and communities in the United States and around the world. This \ntechnical companion is intended to be used as a reference by people across many circumstances \u2013 anyone \nimpacted by automated systems, and anyone developing, designing, deploying, evaluating, or making policy to \ngovern the use of an automated system. \nEach principle is accompanied by three supplemental sections: \n1\n2\nWHY THIS PRINCIPLE IS IMPORTANT: \nThis section provides a brief summary of the problems that the principle seeks to address and protect against, including \nillustrative examples.", "752eb996-0113-447f-848f-fbf6b774fd54": "WHAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS: \n\u2022 The expectations for automated systems are meant to serve as a blueprint for the development of additional technical\nstandards and practices that should be tailored for particular sectors and contexts.\n\u2022 This section outlines practical steps that can be implemented to realize the vision of the Blueprint for an AI Bill of Rights. The \nexpectations laid out often mirror existing practices for technology development, including pre-deployment testing, ongoing \nmonitoring, and governance structures for automated systems, but also go further to address unmet needs for change and offer \nconcrete directions for how those changes can be made.", "02820321-bc0e-4f3b-8bcc-e6bb6a63470b": "\u2022 Expectations about reporting are intended for the entity developing or using the automated system. The resulting reports can \nbe provided to the public, regulators, auditors, industry standards groups, or others engaged in independent review, and should \nbe made public as much as possible consistent with law, regulation, and policy, and noting that intellectual property, law \nenforcement, or national security considerations may prevent public release. Where public reports are not possible, the \ninformation should be provided to oversight bodies and privacy, civil liberties, or other ethics officers charged with safeguard \ning individuals\u2019 rights. These reporting expectations are important for transparency, so the American people can have", "8de89375-ee6f-4deb-8f6f-20c3a1a18022": "confidence that their rights, opportunities, and access as well as their expectations about technologies are respected. \n3\nHOW THESE PRINCIPLES CAN MOVE INTO PRACTICE: \nThis section provides real-life examples of how these guiding principles can become reality, through laws, policies, and practices. \nIt describes practical technical and sociotechnical approaches to protecting rights, opportunities, and access. \nThe examples provided are not critiques or endorsements, but rather are offered as illustrative cases to help \nprovide a concrete vision for actualizing the Blueprint for an AI Bill of Rights. Effectively implementing these", "0216ed9f-c5ea-43f6-afb7-c0fb4ff44223": "processes require the cooperation of and collaboration among industry, civil society, researchers, policymakers, \ntechnologists, and the public. \n14", "001f9013-d806-44c7-a09a-88f5705e3c95": "SAFE AND EFFECTIVE SYSTEMS \nYou should be protected from unsafe or ineffective sys\u00ad\ntems. Automated systems should be developed with consultation \nfrom diverse communities, stakeholders, and domain experts to iden\u00ad\ntify concerns, risks, and potential impacts of the system. Systems \nshould undergo pre-deployment testing, risk identification and miti\u00ad\ngation, and ongoing monitoring that demonstrate they are safe and \neffective based on their intended use, mitigation of unsafe outcomes \nincluding those beyond the intended use, and adherence to do\u00ad\nmain-specific standards. Outcomes of these protective measures \nshould include the possibility of not deploying the system or remov\u00ad", "83e0fe65-3c07-4a7c-a265-67f78a7baed0": "ing a system from use. Automated systems should not be designed \nwith an intent or reasonably foreseeable possibility of endangering \nyour safety or the safety of your community. They should be designed \nto proactively protect you from harms stemming from unintended, \nyet foreseeable, uses or impacts of automated systems. You should be \nprotected from inappropriate or irrelevant data use in the design, de\u00ad\nvelopment, and deployment of automated systems, and from the \ncompounded harm of its reuse. Independent evaluation and report\u00ad\ning that confirms that the system is safe and effective, including re\u00ad\nporting of steps taken to mitigate potential harms, should be per\u00ad\nformed and the results made public whenever possible. \n15", "8521c116-063f-4dc9-ab60-8d337afe6acf": "SAFE AND EFFECTIVE \nSYSTEMS \nWHY THIS PRINCIPLE IS IMPORTANT\nThis section provides a brief summary of the problems which the principle seeks to address and protect \nagainst, including illustrative examples. \nWhile technologies are being deployed to solve problems across a wide array of issues, our reliance on technology can \nalso lead to its use in situations where it has not yet been proven to work\u2014either at all or within an acceptable range \nof error. In other cases, technologies do not work as intended or as promised, causing substantial and unjustified harm. \nAutomated systems sometimes rely on data from other systems, including historical data, allowing irrelevant informa\u00ad", "c7302d34-43e6-4627-8887-144b91086503": "tion from past decisions to infect decision-making in unrelated situations.  In some cases, technologies are purposeful\u00ad\nly designed to violate the safety of others, such as technologies designed to facilitate stalking; in other cases, intended \nor unintended uses lead to unintended harms. \nMany of the harms resulting from these technologies are preventable, and actions are already being taken to protect \nthe public. Some companies have put in place safeguards that have prevented harm from occurring by ensuring that \nkey development decisions are vetted by an ethics review; others have identified and mitigated harms found through", "ab42b592-7c0a-4539-8627-ef4474c8da16": "pre-deployment testing and ongoing monitoring processes. Governments at all levels have existing public consulta\u00ad\ntion processes that may be applied when considering the use of new automated systems, and existing product develop\u00ad\nment and testing practices already protect the American public from many potential harms. \nStill, these kinds of practices are deployed too rarely and unevenly. Expanded, proactive protections could build on \nthese existing practices, increase confidence in the use of automated systems, and protect the American public. Inno\u00ad\nvators deserve clear rules of the road that allow new ideas to flourish, and the American public deserves protections", "c4adab40-585b-44f3-8b2a-51d4fd84a550": "from unsafe outcomes. All can benefit from assurances that automated systems will be designed, tested, and consis\u00ad\ntently confirmed to work as intended, and that they will be proactively protected from foreseeable unintended harm\u00ad\nful outcomes. \n\u2022\nA proprietary model was developed to predict the likelihood of sepsis in hospitalized patients and was imple\u00ad\nmented at hundreds of hospitals around the country. An independent study showed that the model predictions\nunderperformed relative to the designer\u2019s claims while also causing \u2018alert fatigue\u2019 by falsely alerting\nlikelihood of sepsis.6\n\u2022\nOn social media, Black people who quote and criticize racist messages have had their own speech silenced when", "97818157-8e95-47ac-8996-1d7de467522e": "a platform\u2019s automated moderation system failed to distinguish this \u201ccounter speech\u201d (or other critique\nand journalism) from the original hateful messages to which such speech responded.7\n\u2022\nA device originally developed to help people track and find lost items has been used as a tool by stalkers to track\nvictims\u2019 locations in violation of their privacy and safety. The device manufacturer took steps after release to\nprotect people from unwanted tracking by alerting people on their phones when a device is found to be moving\nwith them over time and also by having the device make an occasional noise, but not all phones are able\nto receive the notification and the devices remain a safety concern due to their misuse.8 \n\u2022", "9c02759b-f473-4941-aa64-8607897a0c4f": "\u2022\nAn algorithm used to deploy police was found to repeatedly send police to neighborhoods they regularly visit,\neven if those neighborhoods were not the ones with the highest crime rates. These incorrect crime predictions\nwere the result of a feedback loop generated from the reuse of data from previous arrests and algorithm\npredictions.9\n16", "18342763-e7bf-4866-9622-35cc0c82e105": "SAFE AND EFFECTIVE \nSYSTEMS \nWHY THIS PRINCIPLE IS IMPORTANT\nThis section provides a brief summary of the problems which the principle seeks to address and protect \nagainst, including illustrative examples. \n\u2022\nAI-enabled \u201cnudification\u201d technology that creates images where people appear to be nude\u2014including apps that\nenable non-technical users to create or alter images of individuals without their consent\u2014has proliferated at an\nalarming rate. Such technology is becoming a common form of image-based abuse that disproportionately\nimpacts women. As these tools become more sophisticated, they are producing altered images that are increasing\u00ad", "c9157761-f523-4ba8-82c2-f2eec26e39ba": "ly realistic and are difficult for both humans and AI to detect as inauthentic. Regardless of authenticity, the expe\u00ad\nrience of harm to victims of non-consensual intimate images can be devastatingly real\u2014affecting their personal\nand professional lives, and impacting their mental and physical health.10\n\u2022\nA company installed AI-powered cameras in its delivery vans in order to evaluate the road safety habits of its driv\u00ad\ners, but the system incorrectly penalized drivers when other cars cut them off or when other events beyond\ntheir control took place on the road. As a result, drivers were incorrectly ineligible to receive a bonus.11\n17", "36d92bd5-e77c-4d6a-985b-db9cec746655": "SAFE AND EFFECTIVE \nSYSTEMS \nWHAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\nThe expectations for automated systems are meant to serve as a blueprint for the development of additional \ntechnical standards and practices that are tailored for particular sectors and contexts. \nIn order to ensure that an automated system is safe and effective, it should include safeguards to protect the \npublic from harm in a proactive and ongoing manner; avoid use of data inappropriate for or irrelevant to the task \nat hand, including reuse that could cause compounded harm; and demonstrate the safety and effectiveness of \nthe system. These expectations are explained below. \nProtect the public from harm in a proactive and ongoing manner", "bdcad5c1-2f9f-4d89-bd79-88fa9ce5ca07": "Consultation. The public should be consulted in the design, implementation, deployment, acquisition, and \nmaintenance phases of automated system development, with emphasis on early-stage consultation before a \nsystem is introduced or a large change implemented. This consultation should directly engage diverse impact\u00ad\ned communities to consider concerns and risks that may be unique to those communities, or disproportionate\u00ad\nly prevalent or severe for them. The extent of this engagement and the form of outreach to relevant stakehold\u00ad\ners may differ depending on the specific automated system and development phase, but should include \nsubject matter, sector-specific, and context-specific experts as well as experts on potential impacts such as", "d713c31f-bccf-47a9-871a-a00e96ec8246": "civil rights, civil liberties, and privacy experts. For private sector applications, consultations before product \nlaunch may need to be confidential. Government applications, particularly law enforcement applications or \napplications that raise national security considerations, may require confidential or limited engagement based \non system sensitivities and preexisting oversight laws and structures. Concerns raised in this consultation \nshould be documented, and the automated system developers were proposing to create, use, or deploy should \nbe reconsidered based on this feedback. \nTesting. Systems should undergo extensive testing before deployment. This testing should follow", "8c0e6004-6152-4a40-a251-4eb0222379bf": "domain-specific best practices, when available, for ensuring the technology will work in its real-world \ncontext. Such testing should take into account both the specific technology used and the roles of any human \noperators or reviewers who impact system outcomes or effectiveness; testing should include both automated \nsystems testing and human-led (manual) testing. Testing conditions should mirror as closely as possible the \nconditions in which the system will be deployed, and new testing may be required for each deployment to \naccount for material differences in conditions from one deployment to another. Following testing, system \nperformance should be compared with the in-place, potentially human-driven, status quo procedures, with", "c1ef358b-6aa8-43e7-b19e-3e4da5fb3de5": "existing human performance considered as a performance baseline for the algorithm to meet pre-deployment, \nand as a lifecycle minimum performance standard. Decision possibilities resulting from performance testing \nshould include the possibility of not deploying the system. \nRisk identification and mitigation. Before deployment, and in a proactive and ongoing manner, poten\u00ad\ntial risks of the automated system should be identified and mitigated. Identified risks should focus on the \npotential for meaningful impact on people\u2019s rights, opportunities, or access and include those to impacted \ncommunities that may not be direct users of the automated system, risks resulting from purposeful misuse of", "e94037b4-b43b-437a-aedc-6d11d3b8d3da": "the system, and other concerns identified via the consultation process. Assessment and, where possible, mea\u00ad\nsurement of the impact of risks should be included and balanced such that high impact risks receive attention \nand mitigation proportionate with those impacts. Automated systems with the intended purpose of violating \nthe safety of others should not be developed or used; systems with such safety violations as identified unin\u00ad\ntended consequences should not be used until the risk can be mitigated. Ongoing risk mitigation may necessi\u00ad\ntate rollback or significant modification to a launched automated system. \n18", "9796f896-a283-4e02-ad1c-d8b665f7e361": "SAFE AND EFFECTIVE \nSYSTEMS \nWHAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\nThe expectations for automated systems are meant to serve as a blueprint for the development of additional \ntechnical standards and practices that are tailored for particular sectors and contexts. \nOngoing monitoring. Automated systems should have ongoing monitoring procedures, including recalibra\u00ad\ntion procedures, in place to ensure that their performance does not fall below an acceptable level over time, \nbased on changing real-world conditions or deployment contexts, post-deployment modification, or unexpect\u00ad\ned conditions. This ongoing monitoring should include continuous evaluation of performance metrics and", "32f73e05-b05b-4f35-8eed-8b316d048ef8": "harm assessments, updates of any systems, and retraining of any machine learning models as necessary, as well \nas ensuring that fallback mechanisms are in place to allow reversion to a previously working system. Monitor\u00ad\ning should take into account the performance of both technical system components (the algorithm as well as \nany hardware components, data inputs, etc.) and human operators. It should include mechanisms for testing \nthe actual accuracy of any predictions or recommendations generated by a system, not just a human operator\u2019s \ndetermination of their accuracy. Ongoing monitoring procedures should include manual, human-led monitor\u00ad", "059d3c70-5315-477c-8bdb-406f2ec09817": "ing as a check in the event there are shortcomings in automated monitoring systems. These monitoring proce\u00ad\ndures should be in place for the lifespan of the deployed automated system. \nClear organizational oversight. Entities responsible for the development or use of automated systems \nshould lay out clear governance structures and procedures.  This includes clearly-stated governance proce\u00ad\ndures before deploying the system, as well as responsibility of specific individuals or entities to oversee ongoing \nassessment and mitigation. Organizational stakeholders including those with oversight of the business process \nor operation being automated, as well as other organizational divisions that may be affected due to the use of", "234c07c8-8baa-4f07-9267-04ddec10d3e9": "the system, should be involved in establishing governance procedures. Responsibility should rest high enough \nin the organization that decisions about resources, mitigation, incident response, and potential rollback can be \nmade promptly, with sufficient weight given to risk mitigation objectives against competing concerns. Those \nholding this responsibility should be made aware of any use cases with the potential for meaningful impact on \npeople\u2019s rights, opportunities, or access as determined based on risk identification procedures.  In some cases, \nit may be appropriate for an independent ethics review to be conducted before deployment. \nAvoid inappropriate, low-quality, or irrelevant data use and the compounded harm of its \nreuse", "9a0b4f76-1cad-470d-b14f-aa094811e7d9": "reuse \nRelevant and high-quality data. Data used as part of any automated system\u2019s creation, evaluation, or \ndeployment should be relevant, of high quality, and tailored to the task at hand. Relevancy should be \nestablished based on research-backed demonstration of the causal influence of the data to the specific use case \nor justified more generally based on a reasonable expectation of usefulness in the domain and/or for the \nsystem design or ongoing development. Relevance of data should not be established solely by appealing to \nits historical connection to the outcome. High quality and tailored data should be representative of the task at", "6787b150-12d1-4559-bc54-1c5847f73b1f": "hand and errors from data entry or other sources should be measured and limited. Any data used as the target \nof a prediction process should receive particular attention to the quality and validity of the predicted outcome \nor label to ensure the goal of the automated system is appropriately identified and measured. Additionally, \njustification should be documented for each data attribute and source to explain why it is appropriate to use \nthat data to inform the results of the automated system and why such use will not violate any applicable laws. \nIn cases of high-dimensional and/or derived attributes, such justifications can be provided as overall \ndescriptions of the attribute generation process and appropriateness. \n19", "80b9c020-5bfd-4cc3-8448-2f44fe03d67b": "SAFE AND EFFECTIVE \nSYSTEMS \nWHAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\nThe expectations for automated systems are meant to serve as a blueprint for the development of additional \ntechnical standards and practices that are tailored for particular sectors and contexts. \nDerived data sources tracked and reviewed carefully. Data that is derived from other data through \nthe use of algorithms, such as data derived or inferred from prior model outputs, should be identified and \ntracked, e.g., via a specialized type in a data schema. Derived data should be viewed as potentially high-risk \ninputs that may lead to feedback loops, compounded harm, or inaccurate results. Such sources should be care\u00ad", "4d4a9f01-eaef-40fa-a282-c152d07b6c2a": "fully validated against the risk of collateral consequences. \nData reuse limits in sensitive domains. Data reuse, and especially data reuse in a new context, can result \nin the spreading and scaling of harms. Data from some domains, including criminal justice data and data indi\u00ad\ncating adverse outcomes in domains such as finance, employment, and housing, is especially sensitive, and in \nsome cases its reuse is limited by law. Accordingly, such data should be subject to extra oversight to ensure \nsafety and efficacy. Data reuse of sensitive domain data in other contexts (e.g., criminal data reuse for civil legal \nmatters or private sector use) should only occur where use of such data is legally authorized and, after examina\u00ad", "8331588d-d14c-4a5d-8eb9-ac71dc9599b8": "tion, has benefits for those impacted by the system that outweigh identified risks and, as appropriate, reason\u00ad\nable measures have been implemented to mitigate the identified risks. Such data should be clearly labeled to \nidentify contexts for limited reuse based on sensitivity. Where possible, aggregated datasets may be useful for \nreplacing individual-level sensitive data. \nDemonstrate the safety and effectiveness of the system \nIndependent evaluation. Automated systems should be designed to allow for independent evaluation (e.g., \nvia application programming interfaces). Independent evaluators, such as researchers, journalists, ethics", "c81f26d2-a52c-415b-9348-a100446838cf": "review boards, inspectors general, and third-party auditors, should be given access to the system and samples \nof associated data, in a manner consistent with privacy, security, law, or regulation (including, e.g., intellectual \nproperty law), in order to perform such evaluations. Mechanisms should be included to ensure that system \naccess for evaluation is: provided in a timely manner to the deployment-ready version of the system; trusted to \nprovide genuine, unfiltered access to the full system; and truly independent such that evaluator access cannot \nbe revoked without reasonable and verified justification. \nReporting.12 Entities responsible for the development or use of automated systems should provide", "69b0bf44-5ca3-4a5e-a296-3f98016fa43d": "regularly-updated reports that include: an overview of the system, including how it is embedded in the \norganization\u2019s business processes or other activities, system goals, any human-run procedures that form a \npart of the system, and specific performance expectations; a description of any data used to train machine \nlearning models or for other purposes, including how data sources were processed and interpreted, a \nsummary of what data might be missing, incomplete, or erroneous, and data relevancy justifications; the \nresults of public consultation such as concerns raised and any decisions made due to these concerns; risk \nidentification and management assessments and any steps taken to mitigate potential harms; the results of", "cf84cf61-b70d-4e80-8edb-51a7986b90d5": "performance testing including, but not limited to, accuracy, differential demographic impact, resulting \nerror rates (overall and per demographic group), and comparisons to previously deployed systems; \nongoing monitoring procedures and regular performance testing reports, including monitoring frequency, \nresults, and actions taken; and the procedures for and results from independent evaluations. Reporting \nshould be provided in a plain language and machine-readable manner. \n20", "a9d93246-3fcf-4b3b-b3cd-2d61f11a4de8": "SAFE AND EFFECTIVE \nSYSTEMS \nHOW THESE PRINCIPLES CAN MOVE INTO PRACTICE\nReal-life examples of how these principles can become reality, through laws, policies, and practical \ntechnical and sociotechnical approaches to protecting rights, opportunities, and access. \u00ad\u00ad\nExecutive Order 13960 on Promoting the Use of Trustworthy Artificial Intelligence in the \nFederal Government requires that certain federal agencies adhere to nine principles when \ndesigning, developing, acquiring, or using AI for purposes other than national security or \ndefense. These principles\u2014while taking into account the sensitive law enforcement and other contexts in which", "9768118e-cf92-40c4-88d7-bc37592a721b": "the federal government may use AI, as opposed to private sector use of AI\u2014require that AI is: (a) lawful and \nrespectful of our Nation\u2019s values; (b) purposeful and performance-driven; (c) accurate, reliable, and effective; (d) \nsafe, secure, and resilient; (e) understandable; (f ) responsible and traceable; (g) regularly monitored; (h) transpar-\nent; and, (i) accountable. The Blueprint for an AI Bill of Rights is consistent with the Executive Order. \nAffected agencies across the federal government have released AI use case inventories13 and are implementing \nplans to bring those AI systems into compliance with the Executive Order or retire them. \nThe law and policy landscape for motor vehicles shows that strong safety regulations\u2014and", "77e7e5a7-e286-481f-8375-3aaeed4fe8be": "measures to address harms when they occur\u2014can enhance innovation in the context of com-\nplex technologies. Cars, like automated digital systems, comprise a complex collection of components. \nThe National Highway Traffic Safety Administration,14 through its rigorous standards and independent \nevaluation, helps make sure vehicles on our roads are safe without limiting manufacturers\u2019 ability to \ninnovate.15 At the same time, rules of the road are implemented locally to impose contextually appropriate \nrequirements on drivers, such as slowing down near schools or playgrounds.16\nFrom large companies to start-ups, industry is providing innovative solutions that allow", "cfc2824e-fc30-414f-8a83-8990e776981d": "organizations to mitigate risks to the safety and efficacy of AI systems, both before \ndeployment and through monitoring over time.17 These innovative solutions include risk \nassessments, auditing mechanisms, assessment of organizational procedures, dashboards to allow for ongoing \nmonitoring, documentation procedures specific to model assessments, and many other strategies that aim to \nmitigate risks posed by the use of AI to companies\u2019 reputation, legal responsibilities, and other product safety \nand effectiveness concerns. \nThe Office of Management and Budget (OMB) has called for an expansion of opportunities \nfor meaningful stakeholder engagement in the design of programs and services. OMB also", "c95375c2-2f67-4a96-89b5-58ed18eee638": "points to numerous examples of effective and proactive stakeholder engagement, including the Community-\nBased Participatory Research Program developed by the National Institutes of Health and the participatory \ntechnology assessments developed by the National Oceanic and Atmospheric Administration.18\nThe National Institute of Standards and Technology (NIST) is developing a risk \nmanagement framework to better manage risks posed to individuals, organizations, and \nsociety by AI.19 The NIST AI Risk Management Framework, as mandated by Congress, is intended for \nvoluntary use to help incorporate trustworthiness considerations into the design, development, use, and", "ad2fdff1-2d80-4fab-a668-a069b3d3580b": "evaluation of AI products, services, and systems. The NIST framework is being developed through a consensus-\ndriven, open, transparent, and collaborative process that includes workshops and other opportunities to provide \ninput. The NIST framework aims to foster the development of innovative approaches to address \ncharacteristics of trustworthiness including accuracy, explainability and interpretability, reliability, privacy, \nrobustness, safety, security (resilience), and mitigation of unintended and/or harmful bias, as well as of \nharmful \nuses. \nThe \nNIST \nframework \nwill \nconsider \nand \nencompass \nprinciples \nsuch \nas \ntransparency, accountability, and fairness during pre-design, design and development, deployment, use,", "337d986a-3c9f-406e-bc0f-57c9e46332ce": "and testing and evaluation of AI technologies and systems. It is expected to be released in the winter of 2022-23. \n21", "5bef627a-6954-468c-94ed-e4c913852659": "SAFE AND EFFECTIVE \nSYSTEMS \nHOW THESE PRINCIPLES CAN MOVE INTO PRACTICE\nReal-life examples of how these principles can become reality, through laws, policies, and practical \ntechnical and sociotechnical approaches to protecting rights, opportunities, and access. \u00ad\nSome U.S government agencies have developed specific frameworks for ethical use of AI \nsystems. The Department of Energy (DOE) has activated the AI Advancement Council that oversees coordina-\ntion and advises on implementation of the DOE AI Strategy and addresses issues and/or escalations on the \nethical use and development of AI systems.20 The Department of Defense has adopted Artificial Intelligence", "d04df1f3-70b4-43b7-804f-3d4bbd644072": "Ethical Principles, and tenets for Responsible Artificial Intelligence specifically tailored to its national \nsecurity and defense activities.21 Similarly, the U.S. Intelligence Community (IC) has developed the Principles \nof Artificial Intelligence Ethics for the Intelligence Community to guide personnel on whether and how to \ndevelop and use AI in furtherance of the IC's mission, as well as an AI Ethics Framework to help implement \nthese principles.22\nThe National Science Foundation (NSF) funds extensive research to help foster the \ndevelopment of automated systems that adhere to and advance their safety, security and \neffectiveness. Multiple NSF programs support research that directly addresses many of these principles:", "ab419f41-670d-4306-be20-e1c9a1051027": "the National AI Research Institutes23 support research on all aspects of safe, trustworthy, fair, and explainable \nAI algorithms and systems; the Cyber Physical Systems24 program supports research on developing safe \nautonomous and cyber physical systems with AI components; the Secure and Trustworthy Cyberspace25 \nprogram supports research on cybersecurity and privacy enhancing technologies in automated systems; the \nFormal Methods in the Field26 program supports research on rigorous formal verification and analysis of \nautomated systems and machine learning, and the Designing Accountable Software Systems27 program supports \nresearch on rigorous and reproducible methodologies for developing software systems with legal and regulatory", "93697f59-d0d1-44dd-9e79-da8afba99331": "compliance in mind. \nSome state legislatures have placed strong transparency and validity requirements on \nthe use of pretrial risk assessments. The use of algorithmic pretrial risk assessments has been a \ncause of concern for civil rights groups.28 Idaho Code Section 19-1910, enacted in 2019,29 requires that any \npretrial risk assessment, before use in the state, first be \"shown to be free of bias against any class of \nindividuals protected from discrimination by state or federal law\", that any locality using a pretrial risk \nassessment must first formally validate the claim of its being free of bias, that \"all documents, records, and", "d4dea87f-2617-4f1c-be46-51b91ffc2c7b": "information used to build or validate the risk assessment shall be open to public inspection,\" and that assertions \nof trade secrets cannot be used \"to quash discovery in a criminal matter by a party to a criminal case.\" \n22", "590cbbaf-ffbf-4aa0-96db-3ad50207c739": "\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\nALGORITHMIC DISCRIMINATION Protections\nYou should not face discrimination by algorithms \nand systems should be used and designed in an \nequitable \nway. \nAlgorithmic \ndiscrimination \noccurs when \nautomated systems contribute to unjustified different treatment or \nimpacts disfavoring people based on their race, color, ethnicity, \nsex \n(including \npregnancy, \nchildbirth, \nand \nrelated \nmedical \nconditions, \ngender \nidentity, \nintersex \nstatus, \nand \nsexual \norientation), religion, age, national origin, disability, veteran status, \ngenetic infor-mation, or any other classification protected by law. \nDepending on the specific circumstances, such algorithmic \ndiscrimination may violate legal protections. Designers, developers,", "79f4b807-456d-4a60-ab31-c22599bf60af": "and deployers of automated systems should take proactive and \ncontinuous measures to protect individuals and communities \nfrom algorithmic discrimination and to use and design systems in \nan equitable way.  This protection should include proactive equity \nassessments as part of the system design, use of representative data \nand protection against proxies for demographic features, ensuring \naccessibility for people with disabilities in design and development, \npre-deployment and ongoing disparity testing and mitigation, and \nclear organizational oversight. Independent evaluation and plain \nlanguage reporting in the form of an algorithmic impact assessment, \nincluding disparity testing results and mitigation information,", "1ed43c88-f1b9-4f7f-abd0-81cf06f444cd": "should be performed and made public whenever possible to confirm \nthese protections.\n23", "dbfd4eb3-0e22-426b-86bd-5a8f2a31d021": "Algorithmic \nDiscrimination \nProtections \nWHY THIS PRINCIPLE IS IMPORTANT\nThis section provides a brief summary of the problems which the principle seeks to address and protect \nagainst, including illustrative examples. \nThere is extensive evidence showing that automated systems can produce inequitable outcomes and amplify \nexisting inequity.30 Data that fails to account for existing systemic biases in American society can result in a range of \nconsequences. For example, facial recognition technology that can contribute to wrongful and discriminatory \narrests,31 hiring algorithms that inform discriminatory decisions, and healthcare algorithms that discount", "cec6da72-ff6c-4a2f-bb3a-19f9913f6531": "the severity of certain diseases in Black Americans. Instances of discriminatory practices built into and \nresulting from AI and other automated systems exist across many industries, areas, and contexts. While automated \nsystems have the capacity to drive extraordinary advances and innovations, algorithmic discrimination \nprotections should be built into their design, deployment, and ongoing use. \nMany companies, non-profits, and federal government agencies are already taking steps to ensure the public \nis protected from algorithmic discrimination. Some companies have instituted bias testing as part of their product \nquality assessment and launch procedures, and in some cases this testing has led products to be changed or not", "d5076212-a26f-465a-b67a-c1cf3fb2b844": "launched, preventing harm to the public. Federal government agencies have been developing standards and guidance \nfor the use of automated systems in order to help prevent bias. Non-profits and companies have developed best \npractices for audits and impact assessments to help identify potential algorithmic discrimination and provide \ntransparency to the public in the mitigation of such biases. \nBut there is much more work to do to protect the public from algorithmic discrimination to use and design \nautomated systems in an equitable way. The guardrails protecting the public from discrimination in their daily \nlives should include their digital lives and impacts\u2014basic safeguards against abuse, bias, and discrimination to", "2ee4282d-942e-40cd-bdea-4fb3e6e68afc": "ensure that all people are treated fairly when automated systems are used. This includes all dimensions of their \nlives, from hiring to loan approvals, from medical treatment and payment to encounters with the criminal \njustice system. Ensuring equity should also go beyond existing guardrails to consider the holistic impact that \nautomated systems make on underserved communities and to institute proactive protections that support these \ncommunities. \n\u2022\nAn automated system using nontraditional factors such as educational attainment and employment history as\npart of its loan underwriting and pricing model was found to be much more likely to charge an applicant who", "a4ac73a1-0d42-4c6e-bdb4-b7cca071f9bf": "attended a Historically Black College or University (HBCU) higher loan prices for refinancing a student loan\nthan an applicant who did not attend an HBCU. This was found to be true even when controlling for\nother credit-related factors.32\n\u2022\nA hiring tool that learned the features of a company's employees (predominantly men) rejected women appli\u00ad\ncants for spurious and discriminatory reasons; resumes with the word \u201cwomen\u2019s,\u201d such as \u201cwomen\u2019s\nchess club captain,\u201d were penalized in the candidate ranking.33\n\u2022\nA predictive model marketed as being able to predict whether students are likely to drop out of school was\nused by more than 500 universities across the country. The model was found to use race directly as a predictor,", "e3fc9d0d-cf94-40ad-acf2-dbdad4a97188": "and also shown to have large disparities by race; Black students were as many as four times as likely as their\notherwise similar white peers to be deemed at high risk of dropping out. These risk scores are used by advisors \nto guide students towards or away from majors, and some worry that they are being used to guide\nBlack students away from math and science subjects.34\n\u2022\nA risk assessment tool designed to predict the risk of recidivism for individuals in federal custody showed\nevidence of disparity in prediction. The tool overpredicts the risk of recidivism for some groups of color on the\ngeneral recidivism tools, and underpredicts the risk of recidivism for some groups of color on some of the", "7745fce1-3274-44b2-a933-08919b3d4408": "violent recidivism tools. The Department of Justice is working to reduce these disparities and has\npublicly released a report detailing its review of the tool.35 \n24", "c4c1c089-0de8-42d5-92b0-c3a3cd99b15f": "WHY THIS PRINCIPLE IS IMPORTANT\nThis section provides a brief summary of the problems which the principle seeks to address and protect \nagainst, including illustrative examples. \u00ad\u00ad\u00ad\n\u2022\nAn automated sentiment analyzer, a tool often used by technology platforms to determine whether a state-\nment posted online expresses a positive or negative sentiment, was found to be biased against Jews and gay\npeople. For example, the analyzer marked the statement \u201cI\u2019m a Jew\u201d as representing a negative sentiment,\nwhile \u201cI\u2019m a Christian\u201d was identified as expressing a positive sentiment.36 This could lead to the\npreemptive blocking of social media comments such as: \u201cI\u2019m gay.\u201d A related company with this bias concern", "4b858696-3210-478d-9363-ff239405062a": "has made their data public to encourage researchers to help address the issue37 and has released reports\nidentifying and measuring this problem as well as detailing attempts to address it.38\n\u2022\nSearches for \u201cBlack girls,\u201d \u201cAsian girls,\u201d or \u201cLatina girls\u201d return predominantly39 sexualized content, rather\nthan role models, toys, or activities.40 Some search engines have been working to reduce the prevalence of\nthese results, but the problem remains.41\n\u2022\nAdvertisement delivery systems that predict who is most likely to click on a job advertisement end up deliv-\nering ads in ways that reinforce racial and gender stereotypes, such as overwhelmingly directing supermar-", "410cb57b-a26d-4bec-98d3-5b935884bcc6": "ket cashier ads to women and jobs with taxi companies to primarily Black people.42\u00ad\n\u2022\nBody scanners, used by TSA at airport checkpoints, require the operator to select a \u201cmale\u201d or \u201cfemale\u201d\nscanning setting based on the passenger\u2019s sex, but the setting is chosen based on the operator\u2019s perception of\nthe passenger\u2019s gender identity. These scanners are more likely to flag transgender travelers as requiring\nextra screening done by a person. Transgender travelers have described degrading experiences associated\nwith these extra screenings.43 TSA has recently announced plans to implement a gender-neutral algorithm44 \nwhile simultaneously enhancing the security effectiveness capabilities of the existing technology. \n\u2022", "ff82ffa4-3918-4f06-a912-85f6752dd699": "\u2022\nThe National Disabled Law Students Association expressed concerns that individuals with disabilities were\nmore likely to be flagged as potentially suspicious by remote proctoring AI systems because of their disabili-\nty-specific access needs such as needing longer breaks or using screen readers or dictation software.45 \n\u2022\nAn algorithm designed to identify patients with high needs for healthcare systematically assigned lower\nscores (indicating that they were not as high need) to Black patients than to those of white patients, even\nwhen those patients had similar numbers of chronic conditions and other markers of health.46 In addition,\nhealthcare clinical algorithms that are used by physicians to guide clinical decisions may include", "55c46a0a-cd5b-405b-8184-0b2b78de329d": "sociodemographic variables that adjust or \u201ccorrect\u201d the algorithm\u2019s output on the basis of a patient\u2019s race or\nethnicity, which can lead to race-based health inequities.47\n25\nAlgorithmic \nDiscrimination \nProtections", "1d3805cb-82e3-4af0-8528-dd63feb37ea7": "WHAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\nThe expectations for automated systems are meant to serve as a blueprint for the development of additional \ntechnical standards and practices that are tailored for particular sectors and contexts. \nAny automated system should be tested to help ensure it is free from algorithmic discrimination before it can be \nsold or used. Protection against algorithmic discrimination should include designing to ensure equity, broadly \nconstrued.  Some algorithmic discrimination is already prohibited under existing anti-discrimination law. The \nexpectations set out below describe proactive technical and policy steps that can be taken to not only", "6feef133-3890-4f2f-b3fa-6ea27b9c3c4f": "reinforce those legal protections but extend beyond them to ensure equity for underserved communities48 \neven in circumstances where a specific legal protection may not be clearly established. These protections \nshould be instituted throughout the design, development, and deployment process and are described below \nroughly in the order in which they would be instituted. \nProtect the public from algorithmic discrimination in a proactive and ongoing manner \nProactive assessment of equity in design. Those responsible for the development, use, or oversight of \nautomated systems should conduct proactive equity assessments in the design phase of the technology", "5fb124ad-891e-41e8-9837-0086804787d4": "research and development or during its acquisition to review potential input data, associated historical \ncontext, accessibility for people with disabilities, and societal goals to identify potential discrimination and \neffects on equity resulting from the introduction of the technology. The assessed groups should be as inclusive \nas possible of the underserved communities mentioned in the equity definition:  Black, Latino, and Indigenous \nand Native American persons, Asian Americans and Pacific Islanders and other persons of color; members of \nreligious minorities; women, girls, and non-binary people; lesbian, gay, bisexual, transgender, queer, and inter-", "0914db46-283a-4964-8f45-4b535be988a1": "sex (LGBTQI+) persons; older adults; persons with disabilities; persons who live in rural areas; and persons \notherwise adversely affected by persistent poverty or inequality. Assessment could include both qualitative \nand quantitative evaluations of the system. This equity assessment should also be considered a core part of the \ngoals of the consultation conducted as part of the safety and efficacy review. \nRepresentative and robust data. Any data used as part of system development or assessment should be \nrepresentative of local communities based on the planned deployment setting and should be reviewed for bias \nbased on the historical and societal context of the data. Such data should be sufficiently robust to identify and", "e43f9a2a-d5b4-49f5-835f-4493bf2e8f8c": "help to mitigate biases and potential harms. \nGuarding against proxies.  Directly using demographic information in the design, development, or \ndeployment of an automated system (for purposes other than evaluating a system for discrimination or using \na system to counter discrimination) runs a high risk of leading to algorithmic discrimination and should be \navoided. In many cases, attributes that are highly correlated with demographic features, known as proxies, can \ncontribute to algorithmic discrimination. In cases where use of the demographic features themselves would \nlead to illegal algorithmic discrimination, reliance on such proxies in decision-making (such as that facilitated", "31c13214-e2dd-4095-b3d8-219a57b89c63": "by an algorithm) may also be prohibited by law. Proactive testing should be performed to identify proxies by \ntesting for correlation between demographic information and attributes in any data used as part of system \ndesign, development, or use. If a proxy is identified, designers, developers, and deployers should remove the \nproxy; if needed, it may be possible to identify alternative attributes that can be used instead. At a minimum, \norganizations should ensure a proxy feature is not given undue weight and should monitor the system closely \nfor any resulting algorithmic discrimination.   \n26\nAlgorithmic \nDiscrimination \nProtections", "56a1abef-1f38-4dd2-89e8-90b8290e239f": "WHAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\nThe expectations for automated systems are meant to serve as a blueprint for the development of additional \ntechnical standards and practices that are tailored for particular sectors and contexts. \nEnsuring accessibility during design, development, and deployment. Systems should be \ndesigned, developed, and deployed by organizations in ways that ensure accessibility to people with disabili\u00ad\nties. This should include consideration of a wide variety of disabilities, adherence to relevant accessibility \nstandards, and user experience research both before and after deployment to identify and address any accessi\u00ad\nbility barriers to the use or effectiveness of the automated system.", "e7612c5e-57db-4ad8-82cb-6e41468106f6": "Disparity assessment. Automated systems should be tested using a broad set of measures to assess wheth\u00ad\ner the system components, both in pre-deployment testing and in-context deployment, produce disparities. \nThe demographics of the assessed groups should be as inclusive as possible of race, color, ethnicity, sex \n(including pregnancy, childbirth, and related medical conditions, gender identity, intersex status, and sexual \norientation), religion, age, national origin, disability, veteran status, genetic information, or any other classifi\u00ad\ncation protected by law. The broad set of measures assessed should include demographic performance mea\u00ad", "f5b6dd7a-e3d9-4b83-aaf7-a286f9c48f94": "sures, overall and subgroup parity assessment, and calibration. Demographic data collected for disparity \nassessment should be separated from data used for the automated system and privacy protections should be \ninstituted; in some cases it may make sense to perform such assessment using a data sample. For every \ninstance where the deployed automated system leads to different treatment or impacts disfavoring the identi\u00ad\nfied groups, the entity governing, implementing, or using the system should document the disparity and a \njustification for any continued use of the system. \nDisparity mitigation. When a disparity assessment identifies a disparity against an assessed group, it may", "0d1c8a5e-859a-426e-a900-6b4a12e3a5aa": "be appropriate to take steps to mitigate or eliminate the disparity. In some cases, mitigation or elimination of \nthe disparity may be required by law. \nDisparities that have the potential to lead to algorithmic \ndiscrimination, cause meaningful harm, or violate equity49 goals should be mitigated. When designing and \nevaluating an automated system, steps should be taken to evaluate multiple models and select the one that \nhas the least adverse impact, modify data input choices, or otherwise identify a system with fewer \ndisparities. If adequate mitigation of the disparity is not possible, then the use of the automated system \nshould be reconsidered. One of the considerations in whether to use the system should be the validity of any", "920b0e65-0035-4571-a147-437b2e5763e9": "target measure; unobservable targets may result in the inappropriate use of proxies. Meeting these \nstandards may require instituting mitigation procedures and other protective measures to address \nalgorithmic discrimination, avoid meaningful harm, and achieve equity goals. \nOngoing monitoring and mitigation. Automated systems should be regularly monitored to assess algo\u00ad\nrithmic discrimination that might arise from unforeseen interactions of the system with inequities not \naccounted for during the pre-deployment testing, changes to the system after deployment, or changes to the \ncontext of use or associated data. Monitoring and disparity assessment should be performed by the entity", "986c754b-5c39-4c6d-aaea-b9288bdb4a78": "deploying or using the automated system to examine whether the system has led to algorithmic discrimina\u00ad\ntion when deployed. This assessment should be performed regularly and whenever a pattern of unusual \nresults is occurring. It can be performed using a variety of approaches, taking into account whether and how \ndemographic information of impacted people is available, for example via testing with a sample of users or via \nqualitative user experience research. Riskier and higher-impact systems should be monitored and assessed \nmore frequently. Outcomes of this assessment should include additional disparity mitigation, if needed, or", "e2cba6a6-c66b-47bc-bdae-c624f0de5945": "fallback to earlier procedures in the case that equity standards are no longer met and can't be mitigated, and \nprior mechanisms provide better adherence to equity standards. \n27\nAlgorithmic \nDiscrimination \nProtections", "35afcf44-8f0a-407a-a58f-dc0312d0b348": "WHAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\nThe expectations for automated systems are meant to serve as a blueprint for the development of additional \ntechnical standards and practices that are tailored for particular sectors and contexts. \nDemonstrate that the system protects against algorithmic discrimination \nIndependent evaluation. As described in the section on Safe and Effective Systems, entities should allow \nindependent evaluation of potential algorithmic discrimination caused by automated systems they use or \noversee. In the case of public sector uses, these independent evaluations should be made public unless law", "59ebe40e-5539-403c-9b78-30577dd0b34e": "enforcement or national security restrictions prevent doing so. Care should be taken to balance individual \nprivacy with evaluation data access needs; in many cases, policy-based and/or technological innovations and \ncontrols allow access to such data without compromising privacy. \nReporting. Entities responsible for the development or use of automated systems should provide \nreporting of an appropriately designed algorithmic impact assessment,50 with clear specification of who \nperforms the assessment, who evaluates the system, and how corrective actions are taken (if necessary) in \nresponse to the assessment. This algorithmic impact assessment should include at least: the results of any", "8fd4b88f-c25d-4eda-80be-ccc18bece0b3": "consultation, design stage equity assessments (potentially including qualitative analysis), accessibility \ndesigns and testing, disparity testing, document any remaining disparities, and detail any mitigation \nimplementation and assessments. This algorithmic impact assessment should be made public whenever \npossible. Reporting should be provided in a clear and machine-readable manner using plain language to \nallow for more straightforward public accountability. \n28\nAlgorithmic \nDiscrimination \nProtections", "a603000c-bd1f-4908-b059-dae05e69517c": "HOW THESE PRINCIPLES CAN MOVE INTO PRACTICE\nReal-life examples of how these principles can become reality, through laws, policies, and practical \ntechnical and sociotechnical approaches to protecting rights, opportunities, and access. \nThe federal government is working to combat discrimination in mortgage lending. The Depart\u00ad\nment of Justice has launched a nationwide initiative to combat redlining, which includes reviewing how \nlenders who may be avoiding serving communities of color are conducting targeted marketing and advertising.51 \nThis initiative will draw upon strong partnerships across federal agencies, including the Consumer Financial", "3f1efb65-b141-4a49-b0af-e749cc7deeb8": "Protection Bureau and prudential regulators. The Action Plan to Advance Property Appraisal and Valuation \nEquity includes a commitment from the agencies that oversee mortgage lending to include a \nnondiscrimination standard in the proposed rules for Automated Valuation Models.52\nThe Equal Employment Opportunity Commission and the Department of Justice have clearly \nlaid out how employers\u2019 use of AI and other automated systems can result in \ndiscrimination against job applicants and employees with disabilities.53 The documents explain \nhow employers\u2019 use of software that relies on algorithmic decision-making may violate existing requirements", "0f491396-bcae-4aca-9116-870c5d13f11a": "under Title I of the Americans with Disabilities Act (\u201cADA\u201d). This technical assistance also provides practical \ntips to employers on how to comply with the ADA, and to job applicants and employees who think that their \nrights may have been violated. \nDisparity assessments identified harms to Black patients' healthcare access. A widely \nused healthcare algorithm relied on the cost of each patient\u2019s past medical care to predict future medical needs, \nrecommending early interventions for the patients deemed most at risk. This process discriminated \nagainst Black patients, who generally have less access to medical care and therefore have generated less cost", "eb36cac9-04e9-4472-8597-8ac22bf41230": "than white patients with similar illness and need. A landmark study documented this pattern and proposed \npractical ways that were shown to reduce this bias, such as focusing specifically on active chronic health \nconditions or avoidable future costs related to emergency visits and hospitalization.54 \nLarge employers have developed best practices to scrutinize the data and models used \nfor hiring. An industry initiative has developed Algorithmic Bias Safeguards for the Workforce, a structured \nquestionnaire that businesses can use proactively when procuring software to evaluate workers. It covers \nspecific technical questions such as the training data used, model training process, biases identified, and \nmitigation steps employed.55", "372b2dc6-2b14-4f6d-ab01-c3906b2e0a5c": "Standards organizations have developed guidelines to incorporate accessibility criteria \ninto technology design processes. The most prevalent in the United States is the Access Board\u2019s Section \n508 regulations,56 which are the technical standards for federal information communication technology (software, \nhardware, and web). Other standards include those issued by the International Organization for \nStandardization,57 and the World Wide Web Consortium Web Content Accessibility Guidelines,58 a globally \nrecognized voluntary consensus standard for web content and other information and communications \ntechnology. \nNIST has released Special Publication 1270, Towards a Standard for Identifying and Managing Bias", "26c92b6e-9190-4def-b8b6-59672b25fb2c": "in Artificial Intelligence.59 The special publication: describes the stakes and challenges of bias in artificial \nintelligence and provides examples of how and why it can chip away at public trust; identifies three categories \nof bias in AI \u2013 systemic, statistical, and human \u2013 and describes how and where they contribute to harms; and \ndescribes three broad challenges for mitigating bias \u2013 datasets, testing and evaluation, and human factors \u2013 and \nintroduces preliminary guidance for addressing them. Throughout, the special publication takes a socio-\ntechnical perspective to identifying and managing AI bias. \n29\nAlgorithmic \nDiscrimination \nProtections", "ea8c772e-89ad-4be7-b827-8dca78cd1166": "You should be protected from abusive data practices via built-in \nprotections and you should have agency over how data about \nyou is used. You should be protected from violations of privacy through \ndesign choices that ensure such protections are included by default, including \nensuring that data collection conforms to reasonable expectations and that \nonly data strictly necessary for the specific context is collected. Designers, de\u00ad\nvelopers, and deployers of automated systems should seek your permission \nand respect your decisions regarding collection, use, access, transfer, and de\u00ad\nletion of your data in appropriate ways and to the greatest extent possible; \nwhere not possible, alternative privacy by design safeguards should be used.", "3d7dc9d0-e3e1-4ac2-b7dc-cd94adbd2cda": "Systems should not employ user experience and design decisions that obfus\u00ad\ncate user choice or burden users with defaults that are privacy invasive. Con\u00ad\nsent should only be used to justify collection of data in cases where it can be \nappropriately and meaningfully given. Any consent requests should be brief, \nbe understandable in plain language, and give you agency over data collection \nand the specific context of use; current hard-to-understand no\u00ad\ntice-and-choice practices for broad uses of data should be changed. Enhanced \nprotections and restrictions for data and inferences related to sensitive do\u00ad\nmains, including health, work, education, criminal justice, and finance, and", "a613cdb0-6297-4ba6-a54f-5b9a452786da": "for data pertaining to youth should put you first. In sensitive domains, your \ndata and related inferences should only be used for necessary functions, and \nyou should be protected by ethical review and use prohibitions. You and your \ncommunities should be free from unchecked surveillance; surveillance tech\u00ad\nnologies should be subject to heightened oversight that includes at least \npre-deployment assessment of their potential harms and scope limits to pro\u00ad\ntect privacy and civil liberties. Continuous surveillance and monitoring \nshould not be used in education, work, housing, or in other contexts where the \nuse of such surveillance technologies is likely to limit rights, opportunities, or", "e01ab0b9-52a3-45f3-a7b7-a2070b1c8461": "access. Whenever possible, you should have access to reporting that confirms \nyour data decisions have been respected and provides an assessment of the \npotential impact of surveillance technologies on your rights, opportunities, or \naccess. \nDATA PRIVACY\n30", "7be6686a-8dd3-42d2-9549-40212f4f405f": "DATA PRIVACY \nWHY THIS PRINCIPLE IS IMPORTANT\nThis section provides a brief summary of the problems which the principle seeks to address and protect \nagainst, including illustrative examples. \nData privacy is a foundational and cross-cutting principle required for achieving all others in this framework. Surveil\u00ad\nlance and data collection, sharing, use, and reuse now sit at the foundation of business models across many industries, \nwith more and more companies tracking the behavior of the American public, building individual profiles based on \nthis data, and using this granular-level information as input into automated systems that further track, profile, and", "f00bc4ea-f8ab-4620-bef3-9b302bf389ff": "impact the American public. Government agencies, particularly law enforcement agencies, also use and help develop \na variety of technologies that enhance and expand surveillance capabilities, which similarly collect data used as input \ninto other automated systems that directly impact people\u2019s lives. Federal law has not grown to address the expanding \nscale of private data collection, or of the ability of governments at all levels to access that data and leverage the means \nof private collection.  \nMeanwhile, members of the American public are often unable to access their personal data or make critical decisions \nabout its collection and use. Data brokers frequently collect consumer data from numerous sources without", "52c7f939-1c50-47dc-9b47-30df7891e3c4": "consumers\u2019 permission or knowledge.60 Moreover, there is a risk that inaccurate and faulty data can be used to \nmake decisions about their lives, such as whether they will qualify for a loan or get a job. Use of surveillance \ntechnologies has increased in schools and workplaces, and, when coupled with consequential management and \nevaluation decisions, it is leading to mental health harms such as lowered self-confidence, anxiety, depression, and \na reduced ability to use analytical reasoning.61 Documented patterns show that personal data is being aggregated by \ndata brokers to profile communities in harmful ways.62 The impact of all this data harvesting is corrosive,", "b9eb35ce-4997-45d9-b48f-fc75941bf099": "breeding distrust, anxiety, and other mental health problems; chilling speech, protest, and worker organizing; and \nthreatening our democratic process.63 The American public should be protected from these growing risks. \nIncreasingly, some companies are taking these concerns seriously and integrating mechanisms to protect consumer \nprivacy into their products by design and by default, including by minimizing the data they collect, communicating \ncollection and use clearly, and improving security practices. Federal government surveillance and other collection and \nuse of data is governed by legal protections that help to protect civil liberties and provide for limits on data retention", "e16ad710-4cb1-49ff-9d9c-4b03b88bba3a": "in some cases. Many states have also enacted consumer data privacy protection regimes to address some of these \nharms. \nHowever, these are not yet standard practices, and the United States lacks a comprehensive statutory or regulatory \nframework governing the rights of the public when it comes to personal data. While a patchwork of laws exists to \nguide the collection and use of personal data in specific contexts, including health, employment, education, and credit, \nit can be unclear how these laws apply in other contexts and in an increasingly automated society. Additional protec\u00ad\ntions would assure the American public that the automated systems they use are not monitoring their activities,", "90914ac7-9d35-4f7a-a05a-587565f14f9a": "collecting information on their lives, or otherwise surveilling them without context-specific consent or legal authori\u00ad\nty. \n31", "0aac1368-f7e6-41fd-b4ca-d265075f454d": "DATA PRIVACY \nWHY THIS PRINCIPLE IS IMPORTANT\nThis section provides a brief summary of the problems which the principle seeks to address and protect \nagainst, including illustrative examples. \n\u2022\nAn insurer might collect data from a person's social media presence as part of deciding what life\ninsurance rates they should be offered.64\n\u2022\nA data broker harvested large amounts of personal data and then suffered a breach, exposing hundreds of\nthousands of people to potential identity theft. 65\n\u2022\nA local public housing authority installed a facial recognition system at the entrance to housing complexes to\nassist law enforcement with identifying individuals viewed via camera when police reports are filed, leading", "06a4cb61-aac4-4a92-9d89-1c3e795022a7": "the community, both those living in the housing complex and not, to have videos of them sent to the local\npolice department and made available for scanning by its facial recognition software.66\n\u2022\nCompanies use surveillance software to track employee discussions about union activity and use the\nresulting data to surveil individual employees and surreptitiously intervene in discussions.67\n32", "dfe53d04-704d-432c-8aba-f9f222876af2": "DATA PRIVACY \nWHAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\nThe expectations for automated systems are meant to serve as a blueprint for the development of additional \ntechnical standards and practices that are tailored for particular sectors and contexts. \nTraditional terms of service\u2014the block of text that the public is accustomed to clicking through when using a web\u00ad\nsite or digital app\u2014are not an adequate mechanism for protecting privacy. The American public should be protect\u00ad\ned via built-in privacy protections, data minimization, use and collection limitations, and transparency, in addition \nto being entitled to clear mechanisms to control access to and use of their data\u2014including their metadata\u2014in a", "10da020f-62e8-4c10-8b97-c5400d5a4bc1": "proactive, informed, and ongoing way. Any automated system collecting, using, sharing, or storing personal data \nshould meet these expectations. \nProtect privacy by design and by default \nPrivacy by design and by default. Automated systems should be designed and built with privacy protect\u00ad\ned by default. Privacy risks should be assessed throughout the development life cycle, including privacy risks \nfrom reidentification, and appropriate technical and policy mitigation measures should be implemented. This \nincludes potential harms to those who are not users of the automated system, but who may be harmed by \ninferred data, purposeful privacy violations, or community surveillance or other community harms. Data", "b5c22c81-8085-4a54-9c7a-74eae65ad870": "collection should be minimized and clearly communicated to the people whose data is collected. Data should \nonly be collected or used for the purposes of training or testing machine learning models if such collection and \nuse is legal and consistent with the expectations of the people whose data is collected. User experience \nresearch should be conducted to confirm that people understand what data is being collected about them and \nhow it will be used, and that this collection matches their expectations and desires. \nData collection and use-case scope limits. Data collection should be limited in scope, with specific, \nnarrow identified goals, to avoid \"mission creep.\"  Anticipated data collection should be determined to be", "625f39db-871c-4e42-871d-aaa88cda9a3b": "strictly necessary to the identified goals and should be minimized as much as possible. Data collected based on \nthese identified goals and for a specific context should not be used in a different context without assessing for \nnew privacy risks and implementing appropriate mitigation measures, which may include express consent. \nClear timelines for data retention should be established, with data deleted as soon as possible in accordance \nwith legal or policy-based limitations. Determined data retention timelines should be documented and justi\u00ad\nfied. \nRisk identification and mitigation. Entities that collect, use, share, or store sensitive data should", "a3e5969e-ed80-4405-93ea-e5e7db7bba05": "attempt to proactively identify harms and seek to manage them so as to avoid, mitigate, and respond appropri\u00ad\nately to identified risks. Appropriate responses include determining not to process data when the privacy risks \noutweigh the benefits or implementing measures to mitigate acceptable risks. Appropriate responses do not \ninclude sharing or transferring the privacy risks to users via notice or consent requests where users could not \nreasonably be expected to understand the risks without further support. \nPrivacy-preserving security. Entities creating, using, or governing automated systems should follow \nprivacy and security best practices designed to ensure data and metadata do not leak beyond the specific", "792ad7e2-0e9e-4d81-9940-ff85e9f9a665": "consented use case. Best practices could include using privacy-enhancing cryptography or other types of \nprivacy-enhancing technologies or fine-grained permissions and access control mechanisms, along with \nconventional system security protocols. \n33", "85987bca-6e6b-4595-be00-b9edbf67257b": "DATA PRIVACY \nWHAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\nThe expectations for automated systems are meant to serve as a blueprint for the development of additional \ntechnical standards and practices that are tailored for particular sectors and contexts. \nProtect the public from unchecked surveillance \nHeightened oversight of surveillance. Surveillance or monitoring systems should be subject to \nheightened oversight that includes at a minimum assessment of potential harms during design (before deploy\u00ad\nment) and in an ongoing manner, to ensure that the American public\u2019s rights, opportunities, and access are \nprotected. This assessment should be done before deployment and should give special attention to ensure", "00fc56ad-0e7b-4629-933e-20c4b7fd5dac": "there is not algorithmic discrimination, especially based on community membership, when deployed in a \nspecific real-world context. Such assessment should then be reaffirmed in an ongoing manner as long as the \nsystem is in use. \nLimited and proportionate surveillance. Surveillance should be avoided unless it is strictly necessary \nto achieve a legitimate purpose and it is proportionate to the need. Designers, developers, and deployers of \nsurveillance systems should use the least invasive means of monitoring available and restrict monitoring to the \nminimum number of subjects possible. To the greatest extent possible consistent with law enforcement and", "1331130e-af6d-4a86-95ce-a674da04e4c5": "national security needs, individuals subject to monitoring should be provided with clear and specific notice \nbefore it occurs and be informed about how the data gathered through surveillance will be used. \nScope limits on surveillance to protect rights and democratic values. Civil liberties and civil \nrights must not be limited by the threat of surveillance or harassment facilitated or aided by an automated \nsystem. Surveillance systems should not be used to monitor the exercise of democratic rights, such as voting, \nprivacy, peaceful assembly, speech, or association, in a way that limits the exercise of civil rights or civil liber\u00ad\nties. Information about or algorithmically-determined assumptions related to identity should be carefully", "1de19176-c31c-4b39-9666-47f59eed9d8e": "limited if used to target or guide surveillance systems in order to avoid algorithmic discrimination; such iden\u00ad\ntity-related information includes group characteristics or affiliations, geographic designations, location-based \nand association-based inferences, social networks, and biometrics. Continuous surveillance and monitoring \nsystems should not be used in physical or digital workplaces (regardless of employment status), public educa\u00ad\ntional institutions, and public accommodations. Continuous surveillance and monitoring systems should not \nbe used in a way that has the effect of limiting access to critical resources or services or suppressing the exer\u00ad", "e38bfb8a-e780-4538-b23f-a17d867c4941": "cise of rights, even where the organization is not under a particular duty to protect those rights. \nProvide the public with mechanisms for appropriate and meaningful consent, access, and \ncontrol over their data \nUse-specific consent. Consent practices should not allow for abusive surveillance practices. Where data \ncollectors or automated systems seek consent, they should seek it for specific, narrow use contexts, for specif\u00ad\nic time durations, and for use by specific entities. Consent should not extend if any of these conditions change; \nconsent should be re-acquired before using data if the use case changes, a time limit elapses, or data is trans\u00ad", "cf5a5e6f-af78-4259-a2df-3c80a47aa27c": "ferred to another entity (including being shared or sold). Consent requested should be limited in scope and \nshould not request consent beyond what is required. Refusal to provide consent should be allowed, without \nadverse effects, to the greatest extent possible based on the needs of the use case. \nBrief and direct consent requests. When seeking consent from users short, plain language consent \nrequests should be used so that users understand for what use contexts, time span, and entities they are \nproviding data and metadata consent. User experience research should be performed to ensure these consent \nrequests meet performance standards for readability and comprehension. This includes ensuring that consent", "9ed070c1-b3c0-4887-84ca-17423b7cb855": "requests are accessible to users with disabilities and are available in the language(s) and reading level appro\u00ad\npriate for the audience.  User experience design choices that intentionally obfuscate or manipulate user \nchoice (i.e., \u201cdark patterns\u201d) should be not be used. \n34", "ead11afb-d87b-4194-bee7-bfee7ae265cb": "DATA PRIVACY \nWHAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\nThe expectations for automated systems are meant to serve as a blueprint for the development of additional \ntechnical standards and practices that are tailored for particular sectors and contexts. \nData access and correction. People whose data is collected, used, shared, or stored by automated \nsystems should be able to access data and metadata about themselves, know who has access to this data, and \nbe able to correct it if necessary. Entities should receive consent before sharing data with other entities and \nshould keep records of what data is shared and with whom. \nConsent withdrawal and data deletion. Entities should allow (to the extent legally permissible) with\u00ad", "fd2b93ef-86d6-4769-b47c-583cfd4ddb2e": "drawal of data access consent, resulting in the deletion of user data, metadata, and the timely removal of \ntheir data from any systems (e.g., machine learning models) derived from that data.68\nAutomated system support. Entities designing, developing, and deploying automated systems should \nestablish and maintain the capabilities that will allow individuals to use their own automated systems to help \nthem make consent, access, and control decisions in a complex data ecosystem. Capabilities include machine \nreadable data, standardized data formats, metadata or tags for expressing data processing permissions and \npreferences and data provenance and lineage, context of use and access-specific tags, and training models for", "9f5ab3e0-638a-49d1-a730-c7af7382c643": "assessing privacy risk. \nDemonstrate that data privacy and user control are protected \nIndependent evaluation. As described in the section on Safe and Effective Systems, entities should allow \nindependent evaluation of the claims made regarding data policies. These independent evaluations should be \nmade public whenever possible. Care will need to be taken to balance individual privacy with evaluation data \naccess needs. \nReporting. When members of the public wish to know what data about them is being used in a system, the \nentity responsible for the development of the system should respond quickly with a report on the data it has \ncollected or stored about them. Such a report should be machine-readable, understandable by most users, and", "c76a613f-61c3-47f3-8c59-a224323ff10c": "include, to the greatest extent allowable under law, any data and metadata about them or collected from them, \nwhen and how their data and metadata were collected, the specific ways that data or metadata are being used, \nwho has access to their data and metadata, and what time limitations apply to these data. In cases where a user \nlogin is not available, identity verification may need to be performed before providing such a report to ensure \nuser privacy. Additionally, summary reporting should be proactively made public with general information \nabout how peoples\u2019 data and metadata is used, accessed, and stored. Summary reporting should include the", "0bf2cc65-f78a-429b-9cb3-5745f3b7bb32": "results of any surveillance pre-deployment assessment, including disparity assessment in the real-world \ndeployment context, the specific identified goals of any data collection, and the assessment done to ensure \nonly the minimum required data is collected. It should also include documentation about the scope limit \nassessments, including data retention timelines and associated justification, and an assessment of the \nimpact of surveillance or data collection on rights, opportunities, and access. Where possible, this \nassessment of the impact of surveillance should be done by an independent party. Reporting should be \nprovided in a clear and machine-readable manner.  \n35", "f5c62551-37e8-429b-a82b-98dddf9316c2": "DATA PRIVACY \nEXTRA PROTECTIONS FOR DATA RELATED TO SENSITIVE\nDOMAINS\nSome domains, including health, employment, education, criminal justice, and personal finance, have long been \nsingled out as sensitive domains deserving of enhanced data protections. This is due to the intimate nature of these \ndomains as well as the inability of individuals to opt out of these domains in any meaningful way, and the \nhistorical discrimination that has often accompanied data knowledge.69 Domains understood by the public to be \nsensitive also change over time, including because of technological developments. Tracking and monitoring \ntechnologies, personal tracking devices, and our extensive data footprints are used and misused more than ever", "cae85576-2272-4ebd-87f2-fd959e4a7ff3": "before; as such, the protections afforded by current legal guidelines may be inadequate. The American public \ndeserves assurances that data related to such sensitive domains is protected and used appropriately and only in \nnarrowly defined contexts with clear benefits to the individual and/or society. \nTo this end, automated systems that collect, use, share, or store data related to these sensitive domains should meet \nadditional expectations. Data and metadata are sensitive if they pertain to an individual in a sensitive domain (defined \nbelow); are generated by technologies used in a sensitive domain; can be used to infer data from a sensitive domain or", "2169af4a-7958-4396-99d1-90752f1cabfb": "sensitive data about an individual (such as disability-related data, genomic data, biometric data, behavioral data, \ngeolocation data, data related to interaction with the criminal justice system, relationship history and legal status such \nas custody and divorce information, and home, work, or school environmental data); or have the reasonable potential \nto be used in ways that are likely to expose individuals to meaningful harm, such as a loss of privacy or financial harm \ndue to identity theft. Data and metadata generated by or about those who are not yet legal adults is also sensitive, even \nif not related to a sensitive domain. Such data includes, but is not limited to, numerical, text, image, audio, or video", "d9ad80ec-df7a-42ed-95fc-3744c0586e1d": "data. \u201cSensitive domains\u201d are those in which activities being conducted can cause material harms, including signifi\u00ad\ncant adverse effects on human rights such as autonomy and dignity, as well as civil liberties and civil rights. Domains \nthat have historically been singled out as deserving of enhanced data protections or where such enhanced protections \nare reasonably expected by the public include, but are not limited to, health, family planning and care, employment, \neducation, criminal justice, and personal finance. In the context of this framework, such domains are considered \nsensitive whether or not the specifics of a system context would necessitate coverage under existing law, and domains", "e1b85e76-978a-4443-a07f-9e442df26866": "and data that are considered sensitive are understood to change over time based on societal norms and context. \n36", "ee5f82a4-f4b6-4470-927d-22a650a1c0cb": "DATA PRIVACY \nEXTRA PROTECTIONS FOR DATA RELATED TO SENSITIVE\nDOMAINS\n\u2022\nContinuous positive airway pressure machines gather data for medical purposes, such as diagnosing sleep\napnea, and send usage data to a patient\u2019s insurance company, which may subsequently deny coverage for the\ndevice based on usage data. Patients were not aware that the data would be used in this way or monitored\nby anyone other than their doctor.70 \n\u2022\nA department store company used predictive analytics applied to collected consumer data to determine that a\nteenage girl was pregnant, and sent maternity clothing ads and other baby-related advertisements to her\nhouse, revealing to her father that she was pregnant.71\n\u2022", "5c12d028-da33-40a0-93ec-ea3142dcbf30": "\u2022\nSchool audio surveillance systems monitor student conversations to detect potential \"stress indicators\" as\na warning of potential violence.72 Online proctoring systems claim to detect if a student is cheating on an\nexam using biometric markers.73 These systems have the potential to limit student freedom to express a range\nof emotions at school and may inappropriately flag students with disabilities who need accommodations or\nuse screen readers or dictation software as cheating.74\n\u2022\nLocation data, acquired from a data broker, can be used to identify people who visit abortion clinics.75\n\u2022\nCompanies collect student data such as demographic information, free or reduced lunch status, whether", "4450f029-08e2-44b3-8227-62489008a644": "they've used drugs, or whether they've expressed interest in LGBTQI+ groups, and then use that data to \nforecast student success.76 Parents and education experts have expressed concern about collection of such\nsensitive data without express parental consent, the lack of transparency in how such data is being used, and\nthe potential for resulting discriminatory impacts.\n\u2022 Many employers transfer employee data to third party job verification services. This information is then used\nby potential future employers, banks, or landlords. In one case, a former employee alleged that a\ncompany supplied false data about her job title which resulted in a job offer being revoked.77\n37", "29b09b0e-310f-47d8-b4ce-115ce99fc486": "DATA PRIVACY \nWHAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\nThe expectations for automated systems are meant to serve as a blueprint for the development of additional \ntechnical standards and practices that are tailored for particular sectors and contexts. \u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\nIn addition to the privacy expectations above for general non-sensitive data, any system collecting, using, shar-\ning, or storing sensitive data should meet the expectations below. Depending on the technological use case and \nbased on an ethical assessment, consent for sensitive data may need to be acquired from a guardian and/or child. \nProvide enhanced protections for data related to sensitive domains", "aaf2987a-4038-4689-94d7-96c61252854b": "Necessary functions only. Sensitive data should only be used for functions strictly necessary for that \ndomain or for functions that are required for administrative reasons (e.g., school attendance records), unless \nconsent is acquired, if appropriate, and the additional expectations in this section are met. Consent for non-\nnecessary functions should be optional, i.e., should not be required, incentivized, or coerced in order to \nreceive opportunities or access to services. In cases where data is provided to an entity (e.g., health insurance \ncompany) in order to facilitate payment for such a need, that data should only be used for that purpose.", "af90afb8-299c-4847-9a7e-f34152c8edb6": "Ethical review and use prohibitions. Any use of sensitive data or decision process based in part on sensi-\ntive data that might limit rights, opportunities, or access, whether the decision is automated or not, should go \nthrough a thorough ethical review and monitoring, both in advance and by periodic review (e.g., via an indepen-\ndent ethics committee or similarly robust process). In some cases, this ethical review may determine that data \nshould not be used or shared for specific uses even with consent. Some novel uses of automated systems in this \ncontext, where the algorithm is dynamically developing and where the science behind the use case is not well", "48c2e593-2f9c-40bd-b0b1-b92ad3a985f7": "established, may also count as human subject experimentation, and require special review under organizational \ncompliance bodies applying medical, scientific, and academic human subject experimentation ethics rules and \ngovernance procedures. \nData quality. In sensitive domains, entities should be especially careful to maintain the quality of data to \navoid adverse consequences arising from decision-making based on flawed or inaccurate data. Such care is \nnecessary in a fragmented, complex data ecosystem and for datasets that have limited access such as for fraud \nprevention and law enforcement. It should be not left solely to individuals to carry the burden of reviewing and", "304c5367-d311-45bc-aa5b-dc3c4dd31bd6": "correcting data. Entities should conduct regular, independent audits and take prompt corrective measures to \nmaintain accurate, timely, and complete data. \nLimit access to sensitive data and derived data. Sensitive data and derived data should not be sold, \nshared, or made public as part of data brokerage or other agreements. Sensitive data includes data that can be \nused to infer sensitive information; even systems that are not directly marketed as sensitive domain technologies \nare expected to keep sensitive data private. Access to such data should be limited based on necessity and based \non a principle of local control, such that those individuals closest to the data subject have more access while", "ec8f80da-39e8-47a8-b840-b95d5b47792a": "those who are less proximate do not (e.g., a teacher has access to their students\u2019 daily progress data while a \nsuperintendent does not). \nReporting. In addition to the reporting on data privacy (as listed above for non-sensitive data), entities devel-\noping technologies related to a sensitive domain and those collecting, using, storing, or sharing sensitive data \nshould, whenever appropriate, regularly provide public reports describing: any data security lapses or breaches \nthat resulted in sensitive data leaks; the number, type, and outcomes of ethical pre-reviews undertaken; a \ndescription of any data sold, shared, or made public, and how that data was assessed to determine it did not pres-", "38d0d82c-afaf-4c18-b21d-26a1a5762e5d": "ent a sensitive data risk; and ongoing risk identification and management procedures, and any mitigation added \nbased on these procedures. Reporting should be provided in a clear and machine-readable manner. \n38", "94cc7ca5-3852-4772-920d-f0f44fdfbf3a": "DATA PRIVACY \nHOW THESE PRINCIPLES CAN MOVE INTO PRACTICE\nReal-life examples of how these principles can become reality, through laws, policies, and practical \ntechnical and sociotechnical approaches to protecting rights, opportunities, and access. \nThe Privacy Act of 1974 requires privacy protections for personal information in federal \nrecords systems, including limits on data retention, and also provides individuals a general \nright to access and correct their data. Among other things, the Privacy Act limits the storage of individual \ninformation in federal systems of records, illustrating the principle of limiting the scope of data retention. Under", "ff548cd8-9376-4e6e-869e-bd1f16de9b74": "the Privacy Act, federal agencies may only retain data about an individual that is \u201crelevant and necessary\u201d to \naccomplish an agency\u2019s statutory purpose or to comply with an Executive Order of the President. The law allows \nfor individuals to be able to access any of their individual information stored in a federal system of records, if not \nincluded under one of the systems of records exempted pursuant to the Privacy Act. In these cases, federal agen\u00ad\ncies must provide a method for an individual to determine if their personal information is stored in a particular \nsystem of records, and must provide procedures for an individual to contest the contents of a record about them.", "b6f6feb3-a411-4def-89b7-f9201f0ea078": "Further, the Privacy Act allows for a cause of action for an individual to seek legal relief if a federal agency does not \ncomply with the Privacy Act\u2019s requirements. Among other things, a court may order a federal agency to amend or \ncorrect an individual\u2019s information in its records or award monetary damages if an inaccurate, irrelevant, untimely, \nor incomplete record results in an adverse determination about an individual\u2019s \u201cqualifications, character, rights, \u2026 \nopportunities\u2026, or benefits.\u201d \nNIST\u2019s Privacy Framework provides a comprehensive, detailed and actionable approach for \norganizations to manage privacy risks. The NIST Framework gives organizations ways to identify and", "9b04ca99-2f02-47cb-8bab-3dcc245a5ff7": "communicate their privacy risks and goals to support ethical decision-making in system, product, and service \ndesign or deployment, as well as the measures they are taking to demonstrate compliance with applicable laws \nor regulations. It has been voluntarily adopted by organizations across many different sectors around the world.78\nA school board\u2019s attempt to surveil public school students\u2014undertaken without \nadequate community input\u2014sparked a state-wide biometrics moratorium.79 Reacting to a plan in \nthe city of Lockport, New York, the state\u2019s legislature banned the use of facial recognition systems and other \n\u201cbiometric identifying technology\u201d in schools until July 1, 2022.80 The law additionally requires that a report on", "aeb526e3-d1d9-4a8a-a556-9bfa0bd08772": "the privacy, civil rights, and civil liberties implications of the use of such technologies be issued before \nbiometric identification technologies can be used in New York schools. \nFederal law requires employers, and any consultants they may retain, to report the costs \nof surveilling employees in the context of a labor dispute, providing a transparency \nmechanism to help protect worker organizing. Employers engaging in workplace surveillance \"where \nan object there-of, directly or indirectly, is [\u2026] to obtain information concerning the activities of employees or a \nlabor organization in connection with a labor dispute\" must report expenditures relating to this surveillance to", "fcde6347-d612-463a-93d3-a718a01f89cb": "the Department of Labor Office of Labor-Management Standards, and consultants who employers retain for \nthese purposes must also file reports regarding their activities.81\nPrivacy choices on smartphones show that when technologies are well designed, privacy \nand data agency can be meaningful and not overwhelming. These choices\u2014such as contextual, timely \nalerts about location tracking\u2014are brief, direct, and use-specific. Many of the expectations listed here for \nprivacy by design and use-specific consent mirror those distributed to developers as best practices when \ndeveloping for smart phone devices,82 such as being transparent about how user data will be used, asking for app", "de4b379b-b4ca-4b19-ab3e-135025517ade": "permissions during their use so that the use-context will be clear to users, and ensuring that the app will still \nwork if users deny (or later revoke) some permissions. \n39", "29348fbf-e578-4ca2-81fa-8036ce57c17f": "You should know that an automated system is being used, \nand understand how and why it contributes to outcomes \nthat impact you. Designers, developers, and deployers of automat\u00ad\ned systems should provide generally accessible plain language docu\u00ad\nmentation including clear descriptions of the overall system func\u00ad\ntioning and the role automation plays, notice that such systems are in \nuse, the individual or organization responsible for the system, and ex\u00ad\nplanations of outcomes that are clear, timely, and accessible. Such \nnotice should be kept up-to-date and people impacted by the system \nshould be notified of significant use case or key functionality chang\u00ad\nes. You should know how and why an outcome impacting you was de\u00ad", "20d20479-5a78-466b-9f25-332166b274dc": "termined by an automated system, including when the automated \nsystem is not the sole input determining the outcome. Automated \nsystems should provide explanations that are technically valid, \nmeaningful and useful to you and to any operators or others who \nneed to understand the system, and calibrated to the level of risk \nbased on the context. Reporting that includes summary information \nabout these automated systems in plain language and assessments of \nthe clarity and quality of the notice and explanations should be made \npublic whenever possible.   \nNOTICE AND EXPLANATION\n40", "356f6ea7-7e69-40f3-9a47-d11182b510d0": "NOTICE & \nEXPLANATION \nWHY THIS PRINCIPLE IS IMPORTANT\nThis section provides a brief summary of the problems which the principle seeks to address and protect \nagainst, including illustrative examples. \nAutomated systems now determine opportunities, from employment to credit, and directly shape the American \npublic\u2019s experiences, from the courtroom to online classrooms, in ways that profoundly impact people\u2019s lives. But this \nexpansive impact is not always visible. An applicant might not know whether a person rejected their resume or a \nhiring algorithm moved them to the bottom of the list. A defendant in the courtroom might not know if a judge deny\u00ad", "6e707030-f501-44b1-965a-69fbf71fb914": "ing their bail is informed by an automated system that labeled them \u201chigh risk.\u201d From correcting errors to contesting \ndecisions, people are often denied the knowledge they need to address the impact of automated systems on their lives. \nNotice and explanations also serve an important safety and efficacy purpose, allowing experts to verify the reasonable\u00ad\nness of a recommendation before enacting it. \nIn order to guard against potential harms, the American public needs to know if an automated system is being used. \nClear, brief, and understandable notice is a prerequisite for achieving the other protections in this framework. Like\u00ad", "ef41c2cd-8dc9-4af0-a821-ba39d4872b6e": "wise, the public is often unable to ascertain how or why an automated system has made a decision or contributed to a \nparticular outcome. The decision-making processes of automated systems tend to be opaque, complex, and, therefore, \nunaccountable, whether by design or by omission. These factors can make explanations both more challenging and \nmore important, and should not be used as a pretext to avoid explaining important decisions to the people impacted \nby those choices. In the context of automated systems, clear and valid explanations should be recognized as a baseline \nrequirement. \nProviding notice has long been a standard practice, and in many cases is a legal requirement, when, for example,", "12256f0c-0d5c-4586-b73e-fe5633cbd2d4": "making a video recording of someone (outside of a law enforcement or national security context). In some cases, such \nas credit, lenders are required to provide notice and explanation to consumers. Techniques used to automate the \nprocess of explaining such systems are under active research and improvement and such explanations can take many \nforms. Innovative companies and researchers are rising to the challenge and creating and deploying explanatory \nsystems that can help the public better understand decisions that impact them. \nWhile notice and explanation requirements are already in place in some sectors or situations, the American public", "0c2ef4d2-a416-465f-bc9e-74907e92ff8e": "deserve to know consistently and across sectors if an automated system is being used in a way that impacts their rights, \nopportunities, or access. This knowledge should provide confidence in how the public is being treated, and trust in the \nvalidity and reasonable use of automated systems. \n\u2022\nA lawyer representing an older client with disabilities who had been cut off from Medicaid-funded home\nhealth-care assistance couldn't determine why, especially since the decision went against historical access\npractices. In a court hearing, the lawyer learned from a witness that the state in which the older client\nlived had recently adopted a new algorithm to determine eligibility.83 The lack of a timely explanation made it", "8ffcd263-22ff-4150-9545-1a0c0e01607b": "harder to understand and contest the decision.\n\u2022\nA formal child welfare investigation is opened against a parent based on an algorithm and without the parent\never being notified that data was being collected and used as part of an algorithmic child maltreatment\nrisk assessment.84 The lack of notice or an explanation makes it harder for those performing child\nmaltreatment assessments to validate the risk assessment and denies parents knowledge that could help them\ncontest a decision.\n41", "e85a488e-91bb-4f4c-b7e1-0643b40d8735": "NOTICE & \nEXPLANATION \nWHY THIS PRINCIPLE IS IMPORTANT\nThis section provides a brief summary of the problems which the principle seeks to address and protect \nagainst, including illustrative examples. \n\u2022\nA predictive policing system claimed to identify individuals at greatest risk to commit or become the victim of\ngun violence (based on automated analysis of social ties to gang members, criminal histories, previous experi\u00ad\nences of gun violence, and other factors) and led to individuals being placed on a watch list with no\nexplanation or public transparency regarding how the system came to its conclusions.85 Both police and\nthe public deserve to understand why and how such a system is making these determinations.\n\u2022", "41407440-e4f6-464f-855e-b0c8c28ab852": "\u2022\nA system awarding benefits changed its criteria invisibly. Individuals were denied benefits due to data entry\nerrors and other system flaws. These flaws were only revealed when an explanation of the system\nwas demanded and produced.86 The lack of an explanation made it harder for errors to be corrected in a\ntimely manner.\n42", "0e576866-a682-48f1-8c0f-1b8059e50b3b": "NOTICE & \nEXPLANATION \nWHAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\nThe expectations for automated systems are meant to serve as a blueprint for the development of additional \ntechnical standards and practices that are tailored for particular sectors and contexts. \nAn automated system should provide demonstrably clear, timely, understandable, and accessible notice of use, and \nexplanations as to how and why a decision was made or an action was taken by the system. These expectations are \nexplained below. \nProvide clear, timely, understandable, and accessible notice of use and explanations \u00ad\nGenerally accessible plain language documentation. The entity responsible for using the automated", "2905a7c8-4736-4dc8-8d54-ece22d6fe05c": "system should ensure that documentation describing the overall system (including any human components) is \npublic and easy to find. The documentation should describe, in plain language, how the system works and how \nany automated component is used to determine an action or decision. It should also include expectations about \nreporting described throughout this framework, such as the algorithmic impact assessments described as \npart of Algorithmic Discrimination Protections. \nAccountable. Notices should clearly identify the entity responsible for designing each component of the \nsystem and the entity using it. \nTimely and up-to-date. Users should receive notice of the use of automated systems in advance of using or", "7323fc41-ba10-4412-9020-094e3284bf0e": "while being impacted by the technology. An explanation should be available with the decision itself, or soon \nthereafter. Notice should be kept up-to-date and people impacted by the system should be notified of use case \nor key functionality changes. \nBrief and clear. Notices and explanations should be assessed, such as by research on users\u2019 experiences, \nincluding user testing, to ensure that the people using or impacted by the automated system are able to easily \nfind notices and explanations, read them quickly, and understand and act on them. This includes ensuring that \nnotices and explanations are accessible to users with disabilities and are available in the language(s) and read-", "c84c8ed5-4a22-4b7e-b05b-27cc36ec8d1c": "ing level appropriate for the audience. Notices and explanations may need to be available in multiple forms, \n(e.g., on paper, on a physical sign, or online), in order to meet these expectations and to be accessible to the \nAmerican public. \nProvide explanations as to how and why a decision was made or an action was taken by an \nautomated system \nTailored to the purpose. Explanations should be tailored to the specific purpose for which the user is \nexpected to use the explanation, and should clearly state that purpose. An informational explanation might \ndiffer from an explanation provided to allow for the possibility of recourse, an appeal, or one provided in the", "fd7306d0-c925-4f10-8749-a7b5c4f63c47": "context of a dispute or contestation process. For the purposes of this framework, 'explanation' should be \nconstrued broadly. An explanation need not be a plain-language statement about causality but could consist of \nany mechanism that allows the recipient to build the necessary understanding and intuitions to achieve the \nstated purpose. Tailoring should be assessed (e.g., via user experience research). \nTailored to the target of the explanation. Explanations should be targeted to specific audiences and \nclearly state that audience. An explanation provided to the subject of a decision might differ from one provided \nto an advocate, or to a domain expert or decision maker. Tailoring should be assessed (e.g., via user experience", "288c87c7-a613-4eef-a141-c2a1da271858": "research). \n43", "b5ea21ae-0edf-4e38-bce2-5032ee1f05a5": "NOTICE & \nEXPLANATION \nWHAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\nThe expectations for automated systems are meant to serve as a blueprint for the development of additional \ntechnical standards and practices that are tailored for particular sectors and contexts. \nTailored to the level of risk. An assessment should be done to determine the level of risk of the auto\u00ad\nmated system. In settings where the consequences are high as determined by a risk assessment, or extensive \noversight is expected (e.g., in criminal justice or some public sector settings), explanatory mechanisms should \nbe built into the system design so that the system\u2019s full behavior can be explained in advance (i.e., only fully", "4c5deccc-9af4-4749-8d48-daaa87787534": "transparent models should be used), rather than as an after-the-decision interpretation. In other settings, the \nextent of explanation provided should be tailored to the risk level. \nValid. The explanation provided by a system should accurately reflect the factors and the influences that led \nto a particular decision, and should be meaningful for the particular customization based on purpose, target, \nand level of risk. While approximation and simplification may be necessary for the system to succeed based on \nthe explanatory purpose and target of the explanation, or to account for the risk of fraud or other concerns \nrelated to revealing decision-making information, such simplifications should be done in a scientifically", "6c17a241-76ef-4acd-87f3-509ee676aaa2": "supportable way. Where appropriate based on the explanatory system, error ranges for the explanation should \nbe calculated and included in the explanation, with the choice of presentation of such information balanced \nwith usability and overall interface complexity concerns. \nDemonstrate protections for notice and explanation \nReporting. Summary reporting should document the determinations made based on the above consider\u00ad\nations, including: the responsible entities for accountability purposes; the goal and use cases for the system, \nidentified users, and impacted populations; the assessment of notice clarity and timeliness; the assessment of", "dae6e160-6075-4060-beb9-ddde2378ce90": "the explanation's validity and accessibility; the assessment of the level of risk; and the account and assessment \nof how explanations are tailored, including to the purpose, the recipient of the explanation, and the level of \nrisk. Individualized profile information should be made readily available to the greatest extent possible that \nincludes explanations for any system impacts or inferences. Reporting should be provided in a clear plain \nlanguage and machine-readable manner. \n44", "5ea1e077-4a45-42a1-b70e-9cfabac90b2c": "NOTICE & \nEXPLANATION \nHOW THESE PRINCIPLES CAN MOVE INTO PRACTICE\nReal-life examples of how these principles can become reality, through laws, policies, and practical \ntechnical and sociotechnical approaches to protecting rights, opportunities, and access. \u00ad\u00ad\u00ad\u00ad\u00ad\nPeople in Illinois are given written notice by the private sector if their biometric informa-\ntion is used. The Biometric Information Privacy Act enacted by the state contains a number of provisions \nconcerning the use of individual biometric data and identifiers. Included among them is a provision that no private \nentity may \"collect, capture, purchase, receive through trade, or otherwise obtain\" such information about an", "e995116a-5145-450f-8430-b72c872aa61f": "individual, unless written notice is provided to that individual or their legally appointed representative. 87\nMajor technology companies are piloting new ways to communicate with the public about \ntheir automated technologies. For example, a collection of non-profit organizations and companies have \nworked together to develop a framework that defines operational approaches to transparency for machine \nlearning systems.88 This framework, and others like it,89 inform the public about the use of these tools, going \nbeyond simple notice to include reporting elements such as safety evaluations, disparity assessments, and \nexplanations of how the systems work.", "7b1e072b-efeb-4f44-9cb0-5e2b2e047270": "Lenders are required by federal law to notify consumers about certain decisions made about \nthem. Both the Fair Credit Reporting Act and the Equal Credit Opportunity Act require in certain circumstances \nthat consumers who are denied credit receive \"adverse action\" notices. Anyone who relies on the information in a \ncredit report to deny a consumer credit must, under the Fair Credit Reporting Act, provide an \"adverse action\" \nnotice to the consumer, which includes \"notice of the reasons a creditor took adverse action on the application \nor on an existing credit account.\"90 In addition, under the risk-based pricing rule,91 lenders must either inform", "790cf8b4-5b08-4c54-99ed-c7ed45df0e35": "borrowers of their credit score, or else tell consumers when \"they are getting worse terms because of \ninformation in their credit report.\" The CFPB has also asserted that \"[t]he law gives every applicant the right to \na specific explanation if their application for credit was denied, and that right is not diminished simply because \na company uses a complex algorithm that it doesn't understand.\"92 Such explanations illustrate a shared value \nthat certain decisions need to be explained. \nA California law requires that warehouse employees are provided with notice and explana-\ntion about quotas, potentially facilitated by automated systems, that apply to them. Warehous-", "a21e26a6-2ebb-487c-8d55-0f0208a03238": "ing employers in California that use quota systems (often facilitated by algorithmic monitoring systems) are \nrequired to provide employees with a written description of each quota that applies to the employee, including \n\u201cquantified number of tasks to be performed or materials to be produced or handled, within the defined \ntime period, and any potential adverse employment action that could result from failure to meet the quota.\u201d93\nAcross the federal government, agencies are conducting and supporting research on explain-\nable AI systems. The NIST is conducting fundamental research on the explainability of AI systems. A multidis-\nciplinary team of researchers aims to develop measurement methods and best practices to support the", "7690f94a-9a0a-4bb3-8ff2-8a52c5a89e86": "implementation of core tenets of explainable AI.94 The Defense Advanced Research Projects Agency has a \nprogram on Explainable Artificial Intelligence that aims to create a suite of machine learning techniques that \nproduce more explainable models, while maintaining a high level of learning performance (prediction \naccuracy), and enable human users to understand, appropriately trust, and effectively manage the emerging \ngeneration of artificially intelligent partners.95 The National Science Foundation\u2019s program on Fairness in \nArtificial Intelligence also includes a specific interest in research foundations for explainable AI.96\n45", "9a11f646-9b8e-4ea8-ba7d-95edaba99003": "You should be able to opt out, where appropriate, and \nhave access to a person who can quickly consider and \nremedy problems you encounter. You should be able to opt \nout from automated systems in favor of a human alternative, where \nappropriate. Appropriateness should be determined based on rea\u00ad\nsonable expectations in a given context and with a focus on ensuring \nbroad accessibility and protecting the public from especially harm\u00ad\nful impacts. In some cases, a human or other alternative may be re\u00ad\nquired by law. You should have access to timely human consider\u00ad\nation and remedy by a fallback and escalation process if an automat\u00ad\ned system fails, it produces an error, or you would like to appeal or", "29fa1dfd-359d-4b98-861a-29fce118ebb0": "contest its impacts on you. Human consideration and fallback \nshould be accessible, equitable, effective, maintained, accompanied \nby appropriate operator training, and should not impose an unrea\u00ad\nsonable burden on the public. Automated systems with an intended \nuse within sensitive domains, including, but not limited to, criminal \njustice, employment, education, and health, should additionally be \ntailored to the purpose, provide meaningful access for oversight, \ninclude training for any people interacting with the system, and in\u00ad\ncorporate human consideration for adverse or high-risk decisions. \nReporting that includes a description of these human governance \nprocesses and assessment of their timeliness, accessibility, out\u00ad", "c5d4f8d5-7941-4fe6-a0b4-51320a3d1b76": "comes, and effectiveness should be made public whenever possible. \nHUMAN ALTERNATIVES, CONSIDERATION\nALLBACK\nF\nAND\n, \n46", "102af882-748a-4418-97ee-e1a5f711174e": "HUMAN ALTERNATIVES, \nCONSIDERATION, AND \nFALLBACK \nWHY THIS PRINCIPLE IS IMPORTANT\nThis section provides a brief summary of the problems which the principle seeks to address and protect \nagainst, including illustrative examples. \nThere are many reasons people may prefer not to use an automated system: the system can be flawed and can lead to \nunintended outcomes; it may reinforce bias or be inaccessible; it may simply be inconvenient or unavailable; or it may \nreplace a paper or manual process to which people had grown accustomed. Yet members of the public are often \npresented with no alternative, or are forced to endure a cumbersome process to reach a human decision-maker once", "7956110c-3b63-4976-96a1-d3882ab30c87": "they decide they no longer want to deal exclusively with the automated system or be impacted by its results. As a result \nof this lack of human reconsideration, many receive delayed access, or lose access, to rights, opportunities, benefits, \nand critical services. The American public deserves the assurance that, when rights, opportunities, or access are \nmeaningfully at stake and there is a reasonable expectation of an alternative to an automated system, they can conve\u00ad\nniently opt out of an automated system and will not be disadvantaged for that choice. In some cases, such a human or \nother alternative may be required by law, for example it could be required as \u201creasonable accommodations\u201d for people \nwith disabilities.", "2825cf1b-852a-4f78-8610-3c07f772450d": "with disabilities. \nIn addition to being able to opt out and use a human alternative, the American public deserves a human fallback \nsystem in the event that an automated system fails or causes harm. No matter how rigorously an automated system is \ntested, there will always be situations for which the system fails. The American public deserves protection via human \nreview against these outlying or unexpected scenarios. In the case of time-critical systems, the public should not have \nto wait\u2014immediate human consideration and fallback should be available. In many time-critical systems, such a \nremedy is already immediately available, such as a building manager who can open a door in the case an automated \ncard access system fails.", "15a7bb79-e9a5-477b-8d9b-cc6e0dbc4ede": "In the criminal justice system, employment, education, healthcare, and other sensitive domains, automated systems \nare used for many purposes, from pre-trial risk assessments and parole decisions to technologies that help doctors \ndiagnose disease. Absent appropriate safeguards, these technologies can lead to unfair, inaccurate, or dangerous \noutcomes. These sensitive domains require extra protections. It is critically important that there is extensive human \noversight in such settings. \nThese critical protections have been adopted in some scenarios. Where automated systems have been introduced to \nprovide the public access to government benefits, existing human paper and phone-based processes are generally still", "a957d342-1c58-4485-9eea-3afc4d587c20": "in place, providing an important alternative to ensure access. Companies that have introduced automated call centers \noften retain the option of dialing zero to reach an operator. When automated identity controls are in place to board an \nairplane or enter the country, there is a person supervising the systems who can be turned to for help or to appeal a \nmisidentification. \nThe American people deserve the reassurance that such procedures are in place to protect their rights, opportunities, \nand access. People make mistakes, and a human alternative or fallback mechanism will not always have the right \nanswer, but they serve as an important check on the power and validity of automated systems.", "b8570e39-cab5-4bfb-9219-0cbc3a1117e9": "\u2022 An automated signature matching system is used as part of the voting process in many parts of the country to\ndetermine whether the signature on a mail-in ballot matches the signature on file. These signature matching\nsystems are less likely to work correctly for some voters, including voters with mental or physical\ndisabilities, voters with shorter or hyphenated names, and voters who have changed their name.97 A human\ncuring process,98 which helps voters to confirm their signatures and correct other voting mistakes, is\nimportant to ensure all votes are counted,99 and it is already standard practice in much of the country for\nboth an election official and the voter to have the opportunity to review and correct any such issues.100 \n47", "7485aae5-8016-4dd3-9316-d65c8157f253": "HUMAN ALTERNATIVES, \nCONSIDERATION, AND \nFALLBACK \nWHY THIS PRINCIPLE IS IMPORTANT\nThis section provides a brief summary of the problems which the principle seeks to address and protect \nagainst, including illustrative examples. \n\u2022\nAn unemployment benefits system in Colorado required, as a condition of accessing benefits, that applicants\nhave a smartphone in order to verify their identity. No alternative human option was readily available,\nwhich denied many people access to benefits.101\n\u2022\nA fraud detection system for unemployment insurance distribution incorrectly flagged entries as fraudulent,\nleading to people with slight discrepancies or complexities in their files having their wages withheld and tax", "40f5ad98-a346-4f21-811e-01114345f147": "returns seized without any chance to explain themselves or receive a review by a person.102\n\u2022 A patient was wrongly denied access to pain medication when the hospital\u2019s software confused her medica\u00ad\ntion history with that of her dog\u2019s. Even after she tracked down an explanation for the problem, doctors\nwere afraid to override the system, and she was forced to go without pain relief due to the system\u2019s error.103\n\u2022 A large corporation automated performance evaluation and other HR functions, leading to workers being\nfired by an automated system without the possibility of human review, appeal or other form of recourse.104 \n48", "53be903c-00f8-4fd7-b364-6beaf119f0d3": "HUMAN ALTERNATIVES, \nCONSIDERATION, AND \nFALLBACK \nWHAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\nThe expectations for automated systems are meant to serve as a blueprint for the development of additional \ntechnical standards and practices that are tailored for particular sectors and contexts. \nAn automated system should provide demonstrably effective mechanisms to opt out in favor of a human alterna\u00ad\ntive, where appropriate, as well as timely human consideration and remedy by a fallback system, with additional \nhuman oversight and safeguards for systems used in sensitive domains, and with training and assessment for any \nhuman-based portions of the system to ensure effectiveness.", "ec686833-94f1-4d56-bea9-71ec9609cf02": "Provide a mechanism to conveniently opt out from automated systems in favor of a human \nalternative, where appropriate \nBrief, clear, accessible notice and instructions. Those impacted by an automated system should be \ngiven a brief, clear notice that they are entitled to opt-out, along with clear instructions for how to opt-out. \nInstructions should be provided in an accessible form and should be easily findable by those impacted by the \nautomated system. The brevity, clarity, and accessibility of the notice and instructions should be assessed (e.g., \nvia user experience research). \nHuman alternatives provided when appropriate. In many scenarios, there is a reasonable expectation", "ba1769e7-8097-4eb3-ba39-0cf687648ac0": "of human involvement in attaining rights, opportunities, or access. When automated systems make up part of \nthe attainment process, alternative timely human-driven processes should be provided. The use of a human \nalternative should be triggered by an opt-out process. \nTimely and not burdensome human alternative. Opting out should be timely and not unreasonably \nburdensome in both the process of requesting to opt-out and the human-driven alternative provided. \nProvide timely human consideration and remedy by a fallback and escalation system in the \nevent that an automated system fails, produces error, or you would like to appeal or con\u00ad\ntest its impacts on you", "1474222d-3bc7-4acf-bada-82cb1712250a": "Proportionate. The availability of human consideration and fallback, along with associated training and \nsafeguards against human bias, should be proportionate to the potential of the automated system to meaning\u00ad\nfully impact rights, opportunities, or access. Automated systems that have greater control over outcomes, \nprovide input to high-stakes decisions, relate to sensitive domains, or otherwise have a greater potential to \nmeaningfully impact rights, opportunities, or access should have greater availability (e.g., staffing) and over\u00ad\nsight of human consideration and fallback mechanisms. \nAccessible. Mechanisms for human consideration and fallback, whether in-person, on paper, by phone, or", "dd02b536-3fb1-4c17-b6ff-30fc35655c74": "otherwise provided, should be easy to find and use. These mechanisms should be tested to ensure that users \nwho have trouble with the automated system are able to use human consideration and fallback, with the under\u00ad\nstanding that it may be these users who are most likely to need the human assistance. Similarly, it should be \ntested to ensure that users with disabilities are able to find and use human consideration and fallback and also \nrequest reasonable accommodations or modifications. \nConvenient. Mechanisms for human consideration and fallback should not be unreasonably burdensome as \ncompared to the automated system\u2019s equivalent. \n49", "e612e2cb-fcd5-4d4c-be6a-2065f5bdf802": "HUMAN ALTERNATIVES, \nCONSIDERATION, AND \nFALLBACK \nWHAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\nThe expectations for automated systems are meant to serve as a blueprint for the development of additional \ntechnical standards and practices that are tailored for particular sectors and contexts. \nEquitable. Consideration should be given to ensuring outcomes of the fallback and escalation system are \nequitable when compared to those of the automated system and such that the fallback and escalation \nsystem provides equitable access to underserved communities.105 \nTimely. Human consideration and fallback are only useful if they are conducted and concluded in a", "f2accb27-f20d-4396-a080-75175060f834": "timely manner. The determination of what is timely should be made relative to the specific automated \nsystem, and the review system should be staffed and regularly assessed to ensure it is providing timely \nconsideration and fallback. In time-critical systems, this mechanism should be immediately available or, \nwhere possible, available before the harm occurs. Time-critical systems include, but are not limited to, \nvoting-related systems, automated building access and other access systems, systems that form a critical \ncomponent of healthcare, and systems that have the ability to withhold wages or otherwise cause \nimmediate financial penalties.", "60a8208e-9df7-4421-a9ec-3c4297faf861": "Effective. The organizational structure surrounding processes for consideration and fallback should \nbe designed so that if the human decision-maker charged with reassessing a decision determines that it \nshould be overruled, the new decision will be effectively enacted. This includes ensuring that the new \ndecision is entered into the automated system throughout its components, any previous repercussions from \nthe old decision are also overturned, and safeguards are put in place to help ensure that future decisions do \nnot result in the same errors. \nMaintained. The human consideration and fallback process and any associated automated processes", "40f63228-9d88-4b07-92ce-1cf217d93ca2": "should be maintained and supported as long as the relevant automated system continues to be in use. \nInstitute training, assessment, and oversight to combat automation bias and ensure any \nhuman-based components of a system are effective. \nTraining and assessment. Anyone administering, interacting with, or interpreting the outputs of an auto\u00ad\nmated system should receive training in that system, including how to properly interpret outputs of a system \nin light of its intended purpose and in how to mitigate the effects of automation bias. The training should reoc\u00ad\ncur regularly to ensure it is up to date with the system and to ensure the system is used appropriately. Assess\u00ad", "4d0f658a-ac8a-49e2-9327-812db1e0e23b": "ment should be ongoing to ensure that the use of the system with human involvement provides for appropri\u00ad\nate results, i.e., that the involvement of people does not invalidate the system's assessment as safe and effective \nor lead to algorithmic discrimination. \nOversight. Human-based systems have the potential for bias, including automation bias, as well as other \nconcerns that may limit their effectiveness. The results of assessments of the efficacy and potential bias of \nsuch human-based systems should be overseen by governance structures that have the potential to update the \noperation of the human-based system in order to mitigate these effects. \n50", "c3076c66-7f63-4ac2-982f-e4eb99db2802": "HUMAN ALTERNATIVES, \nCONSIDERATION, AND \nFALLBACK \nWHAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\nThe expectations for automated systems are meant to serve as a blueprint for the development of additional \ntechnical standards and practices that are tailored for particular sectors and contexts. \nImplement additional human oversight and safeguards for automated systems related to \nsensitive domains \nAutomated systems used within sensitive domains, including criminal justice, employment, education, and \nhealth, should meet the expectations laid out throughout this framework, especially avoiding capricious, \ninappropriate, and discriminatory impacts of these technologies. Additionally, automated systems used within", "e257e1b1-536e-421b-83a1-6b9ae1db2a28": "sensitive domains should meet these expectations: \nNarrowly scoped data and inferences. Human oversight should ensure that automated systems in \nsensitive domains are narrowly scoped to address a defined goal, justifying each included data item or attri\u00ad\nbute as relevant to the specific use case. Data included should be carefully limited to avoid algorithmic \ndiscrimination resulting from, e.g., use of community characteristics, social network analysis, or group-based \ninferences. \nTailored to the situation. Human oversight should ensure that automated systems in sensitive domains \nare tailored to the specific use case and real-world deployment scenario, and evaluation testing should show", "80fa1877-4106-4d64-918c-815755213f1e": "that the system is safe and effective for that specific situation. Validation testing performed based on one loca\u00ad\ntion or use case should not be assumed to transfer to another. \nHuman consideration before any high-risk decision. Automated systems, where they are used in \nsensitive domains, may play a role in directly providing information or otherwise providing positive outcomes \nto impacted people. However, automated systems should not be allowed to directly intervene in high-risk \nsituations, such as sentencing decisions or medical care, without human consideration. \nMeaningful access to examine the system. Designers, developers, and deployers of automated", "417fa0f5-a350-4ad7-8f38-a5b2d925e2bd": "systems should consider limited waivers of confidentiality (including those related to trade secrets) where \nnecessary in order to provide meaningful oversight of systems used in sensitive domains, incorporating mea\u00ad\nsures to protect intellectual property and trade secrets from unwarranted disclosure as appropriate. This \nincludes (potentially private and protected) meaningful access to source code, documentation, and related \ndata during any associated legal discovery, subject to effective confidentiality or court orders. Such meaning\u00ad\nful access should include (but is not limited to) adhering to the principle on Notice and Explanation using the", "c141386f-2ea3-441d-9d7a-c7f039acd879": "highest level of risk so the system is designed with built-in explanations; such systems should use fully-trans\u00ad\nparent models where the model itself can be understood by people needing to directly examine it. \nDemonstrate access to human alternatives, consideration, and fallback \nReporting. Reporting should include an assessment of timeliness and the extent of additional burden for \nhuman alternatives, aggregate statistics about who chooses the human alternative, along with the results of \nthe assessment about brevity, clarity, and accessibility of notice and opt-out instructions. Reporting on the \naccessibility, timeliness, and effectiveness of human consideration and fallback should be made public at regu\u00ad", "6cce1e4f-eb93-4880-be58-b09aeb712cbb": "lar intervals for as long as the system is in use. This should include aggregated information about the number \nand type of requests for consideration, fallback employed, and any repeated requests; the timeliness of the \nhandling of these requests, including mean wait times for different types of requests as well as maximum wait \ntimes; and information about the procedures used to address requests for consideration along with the results \nof the evaluation of their accessibility. For systems used in sensitive domains, reporting should include infor\u00ad\nmation about training and governance procedures for these technologies. Reporting should also include docu\u00ad", "158ef2f4-a985-4568-8140-1c10a19a16ae": "mentation of goals and assessment of meeting those goals, consideration of data included, and documentation \nof the governance of reasonable access to the technology. Reporting should be provided in a clear and \nmachine-readable manner. \n51", "9c2d829a-3c53-42d0-bdcf-05e7a4905af3": "HUMAN ALTERNATIVES, \nCONSIDERATION, AND \nFALLBACK \nHOW THESE PRINCIPLES CAN MOVE INTO PRACTICE\nReal-life examples of how these principles can become reality, through laws, policies, and practical \ntechnical and sociotechnical approaches to protecting rights, opportunities, and access. \nHealthcare \u201cnavigators\u201d help people find their way through online signup forms to choose \nand obtain healthcare. A Navigator is \u201can individual or organization that's trained and able to help \nconsumers, small businesses, and their employees as they look for health coverage options through the \nMarketplace (a government web site), including completing eligibility and enrollment forms.\u201d106 For", "de0ff031-b2aa-4d3f-b605-b6ebe8d3146e": "the 2022 plan year, the Biden-Harris Administration increased funding so that grantee organizations could \n\u201ctrain and certify more than 1,500 Navigators to help uninsured consumers find affordable and comprehensive \nhealth coverage.\u201d107\nThe customer service industry has successfully integrated automated services such as \nchat-bots and AI-driven call response systems with escalation to a human support \nteam.108 Many businesses now use partially automated customer service platforms that help answer customer \nquestions and compile common problems for human agents to review. These integrated human-AI \nsystems allow companies to provide faster customer care while maintaining human agents to answer", "03f53429-159b-4268-9abb-60ff59e96c8d": "calls or otherwise respond to complicated requests. Using both AI and human agents is viewed as key to \nsuccessful customer service.109\nBallot curing laws in at least 24 states require a fallback system that allows voters to \ncorrect their ballot and have it counted in the case that a voter signature matching \nalgorithm incorrectly flags their ballot as invalid or there is another issue with their \nballot, and review by an election official does not rectify the problem. Some federal \ncourts have found that such cure procedures are constitutionally required.110 \nBallot \ncuring processes vary among states, and include direct phone calls, emails, or mail contact by election", "f291b814-691c-4171-8a1a-9afa5860f45d": "officials.111 Voters are asked to provide alternative information or a new signature to verify the validity of their \nballot. \n52", "ce6696a4-df9c-4628-aaad-5209a52bf428": "APPENDIX\nExamples of Automated Systems \nThe below examples are meant to illustrate the breadth of automated systems that, insofar as they have the \npotential to meaningfully impact rights, opportunities, or access to critical resources or services, should \nbe covered by the Blueprint for an AI Bill of Rights. These examples should not be construed to limit that \nscope, which includes automated systems that may not yet exist, but which fall under these criteria. \nExamples of automated systems for which the Blueprint for an AI Bill of Rights should be considered include \nthose that have the potential to meaningfully impact: \n\u2022 Civil rights, civil liberties, or privacy, including but not limited to:", "7100404b-f757-4491-a821-fcc66012136a": "Speech-related systems such as automated content moderation tools; \nSurveillance and criminal justice system algorithms such as risk assessments, predictive  \n    policing, automated license plate readers, real-time facial recognition systems (especially  \n    those used in public places or during protected activities like peaceful protests), social media  \n    monitoring, and ankle monitoring devices; \nVoting-related systems such as signature matching tools; \nSystems with a potential privacy impact such as smart home systems and associated data,  \n    systems that use or collect health-related data, systems that use or collect education-related", "9af40c8f-e645-46e0-ad2c-01aadb72e30e": "data, criminal justice system data, ad-targeting systems, and systems that perform big data  \n    analytics in order to build profiles or infer personal information about individuals; and \nAny system that has the meaningful potential to lead to algorithmic discrimination. \n\u2022 Equal opportunities, including but not limited to:\nEducation-related systems such as algorithms that purport to detect student cheating or  \n    plagiarism, admissions algorithms, online or virtual reality student monitoring systems,  \nprojections of student progress or outcomes, algorithms that determine access to resources or  \n    rograms, and surveillance of classes (whether online or in-person);", "26e03b9f-ebdd-4bfb-8df3-cca92cddb723": "Housing-related systems such as tenant screening algorithms, automated valuation systems that  \n    estimate the value of homes used in mortgage underwriting or home insurance, and automated  \n    valuations from online aggregator websites; and \nEmployment-related systems such as workplace algorithms that inform all aspects of the terms  \n    and conditions of employment including, but not limited to, pay or promotion, hiring or termina- \n   tion algorithms, virtual or augmented reality workplace training programs, and electronic work \nplace surveillance and management systems. \n\u2022 Access to critical resources and services, including but not limited to:", "9f104fa3-7067-4d07-b418-029a70b4b1a2": "Health  and health insurance technologies such as medical AI systems and devices, AI-assisted \n    diagnostic tools, algorithms or predictive models used to support clinical decision making, medical  \n    or insurance health risk assessments, drug addiction risk assessments and associated access alg \n-orithms, wearable technologies, wellness apps, insurance care allocation algorithms, and health\ninsurance cost and underwriting algorithms;\nFinancial system algorithms such as loan allocation algorithms, financial system access determi-\nnation algorithms, credit scoring systems, insurance algorithms including risk assessments, auto\n-mated interest rate determinations, and financial algorithms that apply penalties (e.g., that can", "ca9a2c0b-b3eb-486c-b23e-970ea26ca3dc": "garnish wages or withhold tax returns);\n53", "ff44fa0e-a029-4c23-8a2a-2292f7582c0f": "APPENDIX\nSystems that impact the safety of communities such as automated traffic control systems, elec \n-ctrical grid controls, smart city technologies, and industrial emissions and environmental\nimpact control algorithms; and\nSystems related to access to benefits or services or assignment of penalties such as systems that\nsupport decision-makers who adjudicate benefits such as collating or analyzing information or\nmatching records, systems which similarly assist in the adjudication of administrative or criminal\npenalties, fraud detection algorithms, services or benefits access control algorithms, biometric\nsystems used as access control, and systems which make benefits or services related decisions on a", "175ba1ef-d1df-4129-8936-5f0cc3218720": "fully or partially autonomous basis (such as a determination to revoke benefits).\n54", "74e127da-915d-42dc-9835-419d317fc3cd": "SECTION TITLE\nAPPENDIX\nListening to the American People \nThe White House Office of Science and Technology Policy (OSTP) led a yearlong process to seek and distill \ninput from people across the country \u2013 from impacted communities to industry stakeholders to \ntechnology developers to other experts across fields and sectors, as well as policymakers across the Federal \ngovernment \u2013 on the issue of algorithmic and data-driven harms and potential remedies. Through panel \ndiscussions, public listening sessions, private meetings, a formal request for information, and input to a \npublicly accessible and widely-publicized email address, people across the United States spoke up about", "33f5a150-f45e-4f15-b008-169f56c45a70": "both the promises and potential harms of these technologies, and played a central role in shaping the \nBlueprint for an AI Bill of Rights. \nPanel Discussions to Inform the Blueprint for An AI Bill of Rights \nOSTP co-hosted a series of six panel discussions in collaboration with the Center for American Progress, \nthe Joint Center for Political and Economic Studies, New America, the German Marshall Fund, the Electronic \nPrivacy Information Center, and the Mozilla Foundation. The purpose of these convenings \u2013 recordings of \nwhich are publicly available online112 \u2013 was to bring together a variety of experts, practitioners, advocates \nand federal government officials to offer insights and analysis on the risks, harms, benefits, and", "e52f6cee-5a14-4c5e-94f1-4cabbbe82979": "policy opportunities of automated systems. Each panel discussion was organized around a wide-ranging \ntheme, exploring current challenges and concerns and considering what an automated society that \nrespects democratic values should look like. These discussions focused on the topics of consumer \nrights and protections, the criminal justice system, equal opportunities and civil justice, artificial \nintelligence and democratic values, social welfare and development, and the healthcare system. \nSummaries of Panel Discussions: \nPanel 1: Consumer Rights and Protections. This event explored the opportunities and challenges for \nindividual consumers and communities in the context of a growing ecosystem of AI-enabled consumer", "0a673722-599c-4f86-bfb3-fa0d5124264c": "products, advanced platforms and services, \u201cInternet of Things\u201d (IoT) devices, and smart city products and \nservices. \nWelcome:\n\u2022\nRashida Richardson, Senior Policy Advisor for Data and Democracy, White House Office of Science and\nTechnology Policy\n\u2022\nKaren Kornbluh, Senior Fellow and Director of the Digital Innovation and Democracy Initiative, German\nMarshall Fund\nModerator: \nDevin E. Willis, Attorney, Division of Privacy and Identity Protection, Bureau of Consumer Protection, Federal \nTrade Commission \nPanelists: \n\u2022\nTamika L. Butler, Principal, Tamika L. Butler Consulting\n\u2022\nJennifer Clark, Professor and Head of City and Regional Planning, Knowlton School of Engineering, Ohio\nState University\n\u2022", "9743487e-5b7f-4e0a-a879-d7065bda1dc8": "State University\n\u2022\nCarl Holshouser, Senior Vice President for Operations and Strategic Initiatives, TechNet\n\u2022\nSurya Mattu, Senior Data Engineer and Investigative Data Journalist, The Markup\n\u2022\nMariah Montgomery, National Campaign Director, Partnership for Working Families\n55", "e3fd901e-357d-4b1f-af5a-ccb21232e3b3": "APPENDIX\nPanelists discussed the benefits of AI-enabled systems and their potential to build better and more \ninnovative infrastructure. They individually noted that while AI technologies may be new, the process of \ntechnological diffusion is not, and that it was critical to have thoughtful and responsible development and \nintegration of technology within communities. Some panelists suggested that the integration of technology \ncould benefit from examining how technological diffusion has worked in the realm of urban planning: \nlessons learned from successes and failures there include the importance of balancing ownership rights, use", "0d5e7229-6e8b-4da0-b2cc-511429f50f73": "rights, and community health, safety and welfare, as well ensuring better representation of all voices, \nespecially those traditionally marginalized by technological advances. Some panelists also raised the issue of \npower structures \u2013 providing examples of how strong transparency requirements in smart city projects \nhelped to reshape power and give more voice to those lacking the financial or political power to effect change. \nIn discussion of technical and governance interventions that that are needed to protect against the harms \nof these technologies, various panelists emphasized the need for transparency, data collection, and \nflexible and reactive policy development, analogous to how software is continuously updated and deployed.", "b6d388d3-e9b4-4331-8845-f20e189df1b5": "Some panelists pointed out that companies need clear guidelines to have a consistent environment for \ninnovation, with principles and guardrails being the key to fostering responsible innovation. \nPanel 2: The Criminal Justice System. This event explored current and emergent uses of technology in \nthe criminal justice system and considered how they advance or undermine public safety, justice, and \ndemocratic values. \nWelcome: \n\u2022\nSuresh Venkatasubramanian, Assistant Director for Science and Justice, White House Office of Science\nand Technology Policy\n\u2022\nBen Winters, Counsel, Electronic Privacy Information Center\nModerator: Chiraag Bains, Deputy Assistant to the President on Racial Justice & Equity \nPanelists: \n\u2022", "c150358b-4e94-459f-900f-9815e2d6ccb4": "Panelists: \n\u2022\nSean Malinowski, Director of Policing Innovation and Reform, University of Chicago Crime Lab\n\u2022\nKristian Lum, Researcher\n\u2022\nJumana Musa, Director, Fourth Amendment Center, National Association of Criminal Defense Lawyers\n\u2022\nStanley Andrisse, Executive Director, From Prison Cells to PHD; Assistant Professor, Howard University\nCollege of Medicine\n\u2022\nMyaisha Hayes, Campaign Strategies Director, MediaJustice\nPanelists discussed uses of technology within the criminal justice system, including the use of predictive \npolicing, pretrial risk assessments, automated license plate readers, and prison communication tools. The \ndiscussion emphasized that communities deserve safety, and strategies need to be identified that lead to safety;", "aad8bf96-00a0-4cd4-9733-51e92bc306fe": "such strategies might include data-driven approaches, but the focus on safety should be primary, and \ntechnology may or may not be part of an effective set of mechanisms to achieve safety. Various panelists raised \nconcerns about the validity of these systems, the tendency of adverse or irrelevant data to lead to a replication of \nunjust outcomes, and the confirmation bias and tendency of people to defer to potentially inaccurate automated \nsystems. Throughout, many of the panelists individually emphasized that the impact of these systems on \nindividuals and communities is potentially severe: the systems lack individualization and work against the", "220b6c91-144c-4c5a-a454-cdf813a7b8a0": "belief that people can change for the better, system use can lead to the loss of jobs and custody of children, and \nsurveillance can lead to chilling effects for communities and sends negative signals to community members \nabout how they're viewed. \nIn discussion of technical and governance interventions that that are needed to protect against the harms of \nthese technologies, various panelists emphasized that transparency is important but is not enough to achieve \naccountability. Some panelists discussed their individual views on additional system needs for validity, and \nagreed upon the importance of advisory boards and compensated community input early in the design process", "ec5b6e5d-5f21-45cc-b25a-ab89951ce9f8": "(before the technology is built and instituted). Various panelists also emphasized the importance of regulation \nthat includes limits to the type and cost of such technologies. \n56", "32fac763-65e3-4391-9ce9-90c2315fd9d4": "APPENDIX\nPanel 3: Equal Opportunities and Civil Justice. This event explored current and emerging uses of \ntechnology that impact equity of opportunity in employment, education, and housing. \nWelcome: \n\u2022\nRashida Richardson, Senior Policy Advisor for Data and Democracy, White House Office of Science and\nTechnology Policy\n\u2022\nDominique Harrison, Director for Technology Policy, The Joint Center for Political and Economic\nStudies\nModerator: Jenny Yang, Director, Office of Federal Contract Compliance Programs, Department of Labor \nPanelists: \n\u2022\nChristo Wilson, Associate Professor of Computer Science, Northeastern University\n\u2022\nFrida Polli, CEO, Pymetrics\n\u2022\nKaren Levy, Assistant Professor, Department of Information Science, Cornell University", "9c0416af-cd44-4efe-90eb-bb6732a2ca7a": "\u2022\nNatasha Duarte, Project Director, Upturn\n\u2022\nElana Zeide, Assistant Professor, University of Nebraska College of Law\n\u2022\nFabian Rogers, Constituent Advocate, Office of NY State Senator Jabari Brisport and Community\nAdvocate and Floor Captain, Atlantic Plaza Towers Tenants Association\nThe individual panelists described the ways in which AI systems and other technologies are increasingly being \nused to limit access to equal opportunities in education, housing, and employment. Education-related \nconcerning uses included the increased use of remote proctoring systems, student location and facial \nrecognition tracking, teacher evaluation systems, robot teachers, and more. Housing-related concerning uses", "bd772a34-6072-412f-87ba-034f08540e91": "including automated tenant background screening and facial recognition-based controls to enter or exit \nhousing complexes. Employment-related concerning uses included discrimination in automated hiring \nscreening and workplace surveillance. Various panelists raised the limitations of existing privacy law as a key \nconcern, pointing out that students should be able to reinvent themselves and require privacy of their student \nrecords and education-related data in order to do so. The overarching concerns of surveillance in these \ndomains included concerns about the chilling effects of surveillance on student expression, inappropriate", "191339c5-cc5b-4e71-94b1-d0c5c66e1188": "control of tenants via surveillance, and the way that surveillance of workers blurs the boundary between work \nand life and exerts extreme and potentially damaging control over workers' lives. Additionally, some panelists \npointed out ways that data from one situation was misapplied in another in a way that limited people's \nopportunities, for example data from criminal justice settings or previous evictions being used to block further \naccess to housing. Throughout, various panelists emphasized that these technologies are being used to shift the \nburden of oversight and efficiency from employers to workers, schools to students, and landlords to tenants, in", "02ce6c37-80e8-4097-9888-6168118c69b5": "ways that diminish and encroach on equality of opportunity; assessment of these technologies should include \nwhether they are genuinely helpful in solving an identified problem. \nIn discussion of technical and governance interventions that that are needed to protect against the harms of \nthese technologies, panelists individually described the importance of: receiving community input into the \ndesign and use of technologies, public reporting on crucial elements of these systems, better notice and consent \nprocedures that ensure privacy based on context and use case, ability to opt-out of using these systems and \nreceive a fallback to a human process, providing explanations of decisions and how these systems work, the", "ca254912-1583-4ffe-b9c1-294610eb5097": "need for governance including training in using these systems, ensuring the technological use cases are \ngenuinely related to the goal task and are locally validated to work, and the need for institution and protection \nof third party audits to ensure systems continue to be accountable and valid. \n57", "dd4c5874-9148-4745-9d48-5e4ca04474ce": "APPENDIX\nPanel 4: Artificial Intelligence and Democratic Values. This event examined challenges and opportunities in \nthe design of technology that can help support a democratic vision for AI. It included discussion of the \ntechnical aspects \nof \ndesigning \nnon-discriminatory \ntechnology, \nexplainable \nAI, \nhuman-computer \ninteraction with an emphasis on community participation, and privacy-aware design. \nWelcome:\n\u2022\nSorelle Friedler, Assistant Director for Data and Democracy, White House Office of Science and\nTechnology Policy\n\u2022\nJ. Bob Alotta, Vice President for Global Programs, Mozilla Foundation\n\u2022\nNavrina Singh, Board Member, Mozilla Foundation", "0c3a7c3a-92ca-465a-a06e-172351783856": "Moderator: Kathy Pham Evans, Deputy Chief Technology Officer for Product and Engineering, U.S \nFederal Trade Commission. \nPanelists: \n\u2022\nLiz O\u2019Sullivan, CEO, Parity AI\n\u2022\nTimnit Gebru, Independent Scholar\n\u2022\nJennifer Wortman Vaughan, Senior Principal Researcher, Microsoft Research, New York City\n\u2022\nPamela Wisniewski, Associate Professor of Computer Science, University of Central Florida; Director,\nSocio-technical Interaction Research (STIR) Lab\n\u2022\nSeny Kamara, Associate Professor of Computer Science, Brown University\nEach panelist individually emphasized the risks of using AI in high-stakes settings, including the potential for \nbiased data and discriminatory outcomes, opaque decision-making processes, and lack of public trust and", "b8938228-dfeb-43a4-95fb-fb5a1221ad8a": "understanding of the algorithmic systems. The interventions and key needs various panelists put forward as \nnecessary to the future design of critical AI systems included ongoing transparency, value sensitive and \nparticipatory design, explanations designed for relevant stakeholders, and public consultation. \nVarious \npanelists emphasized the importance of placing trust in people, not technologies, and in engaging with \nimpacted communities to understand the potential harms of technologies and build protection by design into \nfuture systems. \nPanel 5: Social Welfare and Development. This event explored current and emerging uses of technology to", "b44b4bce-f81d-41d1-8be0-b23f0f18666f": "implement or improve social welfare systems, social development programs, and other systems that can impact \nlife chances. \nWelcome:\n\u2022\nSuresh Venkatasubramanian, Assistant Director for Science and Justice, White House Office of Science\nand Technology Policy\n\u2022\nAnne-Marie Slaughter, CEO, New America\nModerator: Michele Evermore, Deputy Director for Policy, Office of Unemployment Insurance \nModernization, Office of the Secretary, Department of Labor \nPanelists:\n\u2022\nBlake Hall, CEO and Founder, ID.Me\n\u2022\nKarrie Karahalios, Professor of Computer Science, University of Illinois, Urbana-Champaign\n\u2022\nChristiaan van Veen, Director of Digital Welfare State and Human Rights Project, NYU School of Law's\nCenter for Human Rights and Global Justice\n58", "54e02784-dbf9-4e8f-a8a6-a83e79263bfe": "APPENDIX\n\u2022\nJulia Simon-Mishel, Supervising Attorney, Philadelphia Legal Assistance\n\u2022\nDr. Zachary Mahafza, Research & Data Analyst, Southern Poverty Law Center\n\u2022\nJ. Khadijah Abdurahman, Tech Impact Network Research Fellow, AI Now Institute, UCLA C2I1, and\nUWA Law School\nPanelists separately described the increasing scope of technology use in providing for social welfare, including \nin fraud detection, digital ID systems, and other methods focused on improving efficiency and reducing cost. \nHowever, various panelists individually cautioned that these systems may reduce burden for government \nagencies by increasing the burden and agency of people using and interacting with these technologies.", "f387aa5e-f051-412b-af3b-3731ab385a6d": "Additionally, these systems can produce feedback loops and compounded harm, collecting data from \ncommunities and using it to reinforce inequality. Various panelists suggested that these harms could be \nmitigated by ensuring community input at the beginning of the design process, providing ways to opt out of \nthese systems and use associated human-driven mechanisms instead, ensuring timeliness of benefit payments, \nand providing clear notice about the use of these systems and clear explanations of how and what the \ntechnologies are doing. Some panelists suggested that technology should be used to help people receive \nbenefits, e.g., by pushing benefits to those in need and ensuring automated decision-making systems are only", "ea0df4dc-3898-4aa4-8384-6c0d41db63a0": "used to provide a positive outcome; technology shouldn't be used to take supports away from people who need \nthem. \nPanel 6: The Healthcare System. This event explored current and emerging uses of technology in the \nhealthcare system and consumer products related to health. \nWelcome:\n\u2022\nAlondra Nelson, Deputy Director for Science and Society, White House Office of Science and Technology\nPolicy\n\u2022\nPatrick Gaspard, President and CEO, Center for American Progress\nModerator: Micky Tripathi, National Coordinator for Health Information Technology, U.S Department of \nHealth and Human Services. \nPanelists: \n\u2022\nMark Schneider, Health Innovation Advisor, ChristianaCare\n\u2022", "0611f2ed-3933-4781-8496-91f6a9e2c053": "\u2022\nZiad Obermeyer, Blue Cross of California Distinguished Associate Professor of Policy and Management,\nUniversity of California, Berkeley School of Public Health\n\u2022\nDorothy Roberts, George A. Weiss University Professor of Law and Sociology and the Raymond Pace and\nSadie Tanner Mossell Alexander Professor of Civil Rights, University of Pennsylvania\n\u2022\nDavid Jones, A. Bernard Ackerman Professor of the Culture of Medicine, Harvard University\n\u2022\nJamila Michener, Associate Professor of Government, Cornell University; Co-Director, Cornell Center for\nHealth Equity\u00ad\nPanelists discussed the impact of new technologies on health disparities; healthcare access, delivery, and", "98d2b378-962b-4db3-9198-029a2c73e6be": "outcomes; and areas ripe for research and policymaking. Panelists discussed the increasing importance of tech-\nnology as both a vehicle to deliver healthcare and a tool to enhance the quality of care. On the issue of \ndelivery, various panelists pointed to a number of concerns including access to and expense of broadband \nservice, the privacy concerns associated with telehealth systems, the expense associated with health \nmonitoring devices, and how this can exacerbate equity issues.  On the issue of technology enhanced care, \nsome panelists spoke extensively about the way in which racial biases and the use of race in medicine \nperpetuate harms and embed prior discrimination, and the importance of ensuring that the technologies used", "d4ee39d7-5357-4426-a2f0-e6a3cad8b039": "in medical care were accountable to the relevant stakeholders. Various panelists emphasized the importance \nof having the voices of those subjected to these technologies be heard.\n59", "72bd413f-eddb-4fda-a73a-d9cd18debd40": "APPENDIX\nSummaries of Additional Engagements: \n\u2022 OSTP created an email address (ai-equity@ostp.eop.gov) to solicit comments from the public on the use of\nartificial intelligence and other data-driven technologies in their lives.\n\u2022 OSTP issued a Request For Information (RFI) on the use and governance of biometric technologies.113 The\npurpose of this RFI was to understand the extent and variety of biometric technologies in past, current, or\nplanned use; the domains in which these technologies are being used; the entities making use of them; current\nprinciples, practices, or policies governing their use; and the stakeholders that are, or may be, impacted by their", "36dbb9c4-f30d-493e-8275-80ee701af8c6": "use or regulation. The 130 responses to this RFI are available in full online114 and were submitted by the below\nlisted organizations and individuals:\nAccenture \nAccess Now \nACT | The App Association \nAHIP \nAIethicist.org \nAirlines for America \nAlliance for Automotive Innovation \nAmelia Winger-Bearskin \nAmerican Civil Liberties Union \nAmerican Civil Liberties Union of \nMassachusetts \nAmerican Medical Association \nARTICLE19 \nAttorneys General of the District of \nColumbia, Illinois, Maryland, \nMichigan, Minnesota, New York, \nNorth Carolina, Oregon, Vermont, \nand Washington \nAvanade \nAware \nBarbara Evans \nBetter Identity Coalition \nBipartisan Policy Center \nBrandon L. Garrett and Cynthia \nRudin \nBrian Krupp \nBrooklyn Defender Services", "9b9c6e72-1784-4e5c-aa61-2a4cea8346a0": "BSA | The Software Alliance \nCarnegie Mellon University \nCenter for Democracy & \nTechnology \nCenter for New Democratic \nProcesses \nCenter for Research and Education \non Accessible Technology and \nExperiences at University of \nWashington, Devva Kasnitz, L Jean \nCamp, Jonathan Lazar, Harry \nHochheiser \nCenter on Privacy & Technology at \nGeorgetown Law \nCisco Systems \nCity of Portland Smart City PDX \nProgram \nCLEAR \nClearview AI \nCognoa \nColor of Change \nCommon Sense Media \nComputing Community Consortium \nat Computing Research Association \nConnected Health Initiative \nConsumer Technology Association \nCourtney Radsch \nCoworker \nCyber Farm Labs \nData & Society Research Institute \nData for Black Lives \nData to Actionable Knowledge Lab", "5a679e15-2cfb-45cd-8940-9d229c2de461": "at Harvard University \nDeloitte \nDev Technology Group \nDigital Therapeutics Alliance \nDigital Welfare State & Human \nRights Project and Center for \nHuman Rights and Global Justice at \nNew York University School of \nLaw, and Temple University \nInstitute for Law, Innovation & \nTechnology \nDignari \nDouglas Goddard \nEdgar Dworsky \nElectronic Frontier Foundation \nElectronic Privacy Information \nCenter, Center for Digital \nDemocracy, and Consumer \nFederation of America \nFaceTec \nFight for the Future \nGanesh Mani \nGeorgia Tech Research Institute \nGoogle \nHealth Information Technology \nResearch and Development \nInteragency Working Group \nHireVue \nHR Policy Association \nID.me \nIdentity and Data Sciences \nLaboratory at Science Applications", "19a8c5a2-0beb-4e75-8338-c40c1972fce2": "International Corporation \nInformation Technology and \nInnovation Foundation \nInformation Technology Industry \nCouncil \nInnocence Project \nInstitute for Human-Centered \nArtificial Intelligence at Stanford \nUniversity \nIntegrated Justice Information \nSystems Institute \nInternational Association of Chiefs \nof Police \nInternational Biometrics + Identity \nAssociation \nInternational Business Machines \nCorporation \nInternational Committee of the Red \nCross \nInventionphysics \niProov \nJacob Boudreau \nJennifer K. Wagner, Dan Berger, \nMargaret Hu, and Sara Katsanis \nJonathan Barry-Blocker \nJoseph Turow \nJoy Buolamwini \nJoy Mack \nKaren Bureau \nLamont Gholston \nLawyers\u2019 Committee for Civil \nRights Under Law \n60", "43216f70-fa39-49f0-a909-c61fc6c2abca": "APPENDIX\nLisa Feldman Barrett \nMadeline Owens \nMarsha Tudor \nMicrosoft Corporation \nMITRE Corporation \nNational Association for the \nAdvancement of Colored People \nLegal Defense and Educational \nFund \nNational Association of Criminal \nDefense Lawyers \nNational Center for Missing & \nExploited Children \nNational Fair Housing Alliance \nNational Immigration Law Center \nNEC Corporation of America \nNew America\u2019s Open Technology \nInstitute \nNew York Civil Liberties Union \nNo Name Provided \nNotre Dame Technology Ethics \nCenter \nOffice of the Ohio Public Defender \nOnfido \nOosto \nOrissa Rose \nPalantir \nPangiam \nParity Technologies \nPatrick A. Stewart, Jeffrey K. \nMullins, and Thomas J. Greitens \nPel Abbott \nPhiladelphia Unemployment \nProject", "bef03974-7c31-44cf-be99-9af8c09cff69": "Project \nProject On Government Oversight \nRecording Industry Association of \nAmerica \nRobert Wilkens \nRon Hedges \nScience, Technology, and Public \nPolicy Program at University of \nMichigan Ann Arbor \nSecurity Industry Association \nSheila Dean \nSoftware & Information Industry \nAssociation \nStephanie Dinkins and the Future \nHistories Studio at Stony Brook \nUniversity \nTechNet \nThe Alliance for Media Arts and \nCulture, MIT Open Documentary \nLab and Co-Creation Studio, and \nImmerse \nThe International Brotherhood of \nTeamsters \nThe Leadership Conference on \nCivil and Human Rights \nThorn \nU.S. Chamber of Commerce\u2019s \nTechnology Engagement Center \nUber Technologies \nUniversity of Pittsburgh \nUndergraduate Student \nCollaborative \nUpturn", "b6a830dc-e14b-4a1a-94f3-219094067815": "Upturn \nUS Technology Policy Committee \nof the Association of Computing \nMachinery \nVirginia Puccio \nVisar Berisha and Julie Liss \nXR Association \nXR Safety Initiative \n\u2022 As an additional effort to reach out to stakeholders regarding the RFI, OSTP conducted two listening sessions\nfor members of the public. The listening sessions together drew upwards of 300 participants. The Science and\nTechnology Policy Institute produced a synopsis of both the RFI submissions and the feedback at the listening\nsessions.115\n61", "36fa8d95-eeed-4c31-8c1d-0a7261886509": "APPENDIX\n\u2022 OSTP conducted meetings with a variety of stakeholders in the private sector and civil society. Some of these\nmeetings were specifically focused on providing ideas related to the development of the Blueprint for an AI\nBill of Rights while others provided useful general context on the positive use cases, potential harms, and/or\noversight possibilities for these technologies. Participants in these conversations from the private sector and\ncivil society included:\nAdobe \nAmerican Civil Liberties Union \n(ACLU) \nThe Aspen Commission on \nInformation Disorder \nThe Awood Center \nThe Australian Human Rights \nCommission \nBiometrics Institute \nThe Brookings Institute \nBSA | The Software Alliance \nCantellus Group", "4a72c92a-02ae-494d-a157-b0c55a0d0c46": "Cantellus Group \nCenter for American Progress \nCenter for Democracy and \nTechnology \nCenter on Privacy and Technology \nat Georgetown Law \nChristiana Care \nColor of Change \nCoworker \nData Robot \nData Trust Alliance \nData and Society Research Institute \nDeepmind \nEdSAFE AI Alliance \nElectronic Privacy Information \nCenter (EPIC) \nEncode Justice \nEqual AI \nGoogle \nHitachi's AI Policy Committee \nThe Innocence Project \nInstitute of Electrical and \nElectronics Engineers (IEEE) \nIntuit \nLawyers Committee for Civil Rights \nUnder Law \nLegal Aid Society \nThe Leadership Conference on \nCivil and Human Rights \nMeta \nMicrosoft \nThe MIT AI Policy Forum \nMovement Alliance Project \nThe National Association of \nCriminal Defense Lawyers", "77b0528f-9d90-4f8a-9447-7d2ec7c46c92": "O\u2019Neil Risk Consulting & \nAlgorithmic Auditing \nThe Partnership on AI \nPinterest \nThe Plaintext Group \npymetrics \nSAP \nThe Security Industry Association \nSoftware and Information Industry \nAssociation (SIIA) \nSpecial Competitive Studies Project \nThorn \nUnited for Respect \nUniversity of California at Berkeley \nCitris Policy Lab \nUniversity of California at Berkeley \nLabor Center \nUnfinished/Project Liberty \nUpturn \nUS Chamber of Commerce \nUS Chamber of Commerce \nTechnology Engagement Center \nA.I. Working Group\nVibrent Health\nWarehouse Worker Resource\nCenter\nWaymap\n62", "cde65a9d-0d10-4de4-a075-17dc02be0540": "ENDNOTES\n1.The Executive Order On Advancing Racial Equity and Support for Underserved Communities Through the\nFederal\u00a0Government. https://www.whitehouse.gov/briefing-room/presidential-actions/2021/01/20/executive\norder-advancing-racial-equity-and-support-for-underserved-communities-through-the-federal-government/\n2. The White House. Remarks by President Biden on the Supreme Court Decision to Overturn Roe v. Wade. Jun.\n24, 2022. https://www.whitehouse.gov/briefing-room/speeches-remarks/2022/06/24/remarks-by-president\u00ad\nbiden-on-the-supreme-court-decision-to-overturn-roe-v-wade/\n3. The White House. Join the Effort to Create A Bill of Rights for an Automated Society. Nov. 10, 2021. https://", "ca6189b7-21ab-4791-9291-4e5f5c7fdcee": "www.whitehouse.gov/ostp/news-updates/2021/11/10/join-the-effort-to-create-a-bill-of-rights-for-an\u00ad\nautomated-society/\n4. U.S. Dept. of Health, Educ. & Welfare, Report of the Sec\u2019y\u2019s Advisory Comm. on Automated Pers. Data Sys.,\nRecords, Computers, and the Rights of Citizens (July 1973). https://www.justice.gov/opcl/docs/rec-com\u00ad\nrights.pdf.\n5. See, e.g., Office of Mgmt. & Budget, Exec. Office of the President, Circular A-130, Managing Information as a\nStrategic Resource, app. II \u00a7\u00a03 (July 28, 2016); Org. of Econ. Co-Operation & Dev., Revision of the\nRecommendation of the Council Concerning Guidelines Governing the Protection of Privacy and Transborder", "22ec510d-46ad-42fc-aa25-797d3c6bdb0c": "Flows of Personal Data, Annex Part Two (June 20, 2013). https://one.oecd.org/document/C(2013)79/en/pdf.\n6. Andrew Wong et al. External validation of a widely implemented proprietary sepsis prediction model in\nhospitalized patients. JAMA Intern Med. 2021; 181(8):1065-1070. doi:10.1001/jamainternmed.2021.2626\n7. Jessica Guynn. Facebook while black: Users call it getting 'Zucked,' say talking about racism is censored as hate\nspeech. USA Today. Apr. 24, 2019. https://www.usatoday.com/story/news/2019/04/24/facebook-while-black\u00ad\nzucked-users-say-they-get-blocked-racism-discussion/2859593002/\n8. See, e.g., Michael Levitt. AirTags are being used to track people and cars. Here's what is being done about it.", "3ee91061-54c6-400a-9340-9257e1432685": "NPR. Feb. 18, 2022. https://www.npr.org/2022/02/18/1080944193/apple-airtags-theft-stalking-privacy-tech;\nSamantha Cole. Police Records Show Women Are Being Stalked With Apple AirTags Across the Country.\nMotherboard. Apr. 6, 2022. https://www.vice.com/en/article/y3vj3y/apple-airtags-police-reports-stalking\u00ad\nharassment\n9. Kristian Lum and William Isaac. To Predict and Serve? Significance. Vol. 13, No. 5, p. 14-19. Oct. 7, 2016.\nhttps://rss.onlinelibrary.wiley.com/doi/full/10.1111/j.1740-9713.2016.00960.x; Aaron Sankin, Dhruv Mehrotra,\nSurya Mattu, and Annie Gilbertson. Crime Prediction Software Promised to Be Free of Biases. New Data Shows\nIt Perpetuates Them. The Markup and Gizmodo. Dec. 2, 2021. https://themarkup.org/prediction\u00ad", "895ae1bb-1256-45f1-8af5-ad9f2cd32b17": "bias/2021/12/02/crime-prediction-software-promised-to-be-free-of-biases-new-data-shows-it-perpetuates\u00ad\nthem\n10. Samantha Cole. This Horrifying App Undresses a Photo of Any Woman With a Single Click. Motherboard.\nJune 26, 2019. https://www.vice.com/en/article/kzm59x/deepnude-app-creates-fake-nudes-of-any-woman\n11. Lauren Kaori Gurley. Amazon\u2019s AI Cameras Are Punishing Drivers for Mistakes They Didn\u2019t Make.\nMotherboard. Sep. 20, 2021. https://www.vice.com/en/article/88npjv/amazons-ai-cameras-are-punishing\u00ad\ndrivers-for-mistakes-they-didnt-make\n63", "ba53ffb2-c7bd-4a9d-9323-d8297aa088cd": "ENDNOTES\n12. Expectations about reporting are intended for the entity developing or using the automated system. The\nresulting reports can be provided to the public, regulators, auditors, industry standards groups, or others\nengaged in independent review, and should be made public as much as possible consistent with law,\nregulation, and policy, and noting that intellectual property or law enforcement considerations may prevent\npublic release. These reporting expectations are important for transparency, so the American people can\nhave confidence that their rights, opportunities, and access as well as their expectations around\ntechnologies are respected.", "7d77f570-3253-435a-ad0a-1cc8f1351be8": "13. National Artificial Intelligence Initiative Office. Agency Inventories of AI Use Cases. Accessed Sept. 8,\n2022. https://www.ai.gov/ai-use-case-inventories/\n14. National Highway Traffic Safety Administration. https://www.nhtsa.gov/\n15. See, e.g., Charles Pruitt. People Doing What They Do Best: The Professional Engineers and NHTSA. Public\nAdministration Review. Vol. 39, No. 4. Jul.-Aug., 1979. https://www.jstor.org/stable/976213?seq=1\n16. The US Department of Transportation has publicly described the health and other benefits of these\n\u201ctraffic calming\u201d measures. See, e.g.: U.S. Department of Transportation. Traffic Calming to Slow Vehicle", "8dcd6693-f972-429f-a804-add9bd825ef1": "Speeds. Accessed Apr. 17, 2022. https://www.transportation.gov/mission/health/Traffic-Calming-to-Slow\u00ad\nVehicle-Speeds\n17. Karen Hao. Worried about your firm\u2019s AI ethics? These startups are here to help.\nA growing ecosystem of \u201cresponsible AI\u201d ventures promise to help organizations monitor and fix their AI\nmodels. MIT Technology Review. Jan 15., 2021.\nhttps://www.technologyreview.com/2021/01/15/1016183/ai-ethics-startups/; Disha Sinha. Top Progressive\nCompanies Building Ethical AI to Look Out for in 2021. Analytics Insight. June 30, 2021. https://\nwww.analyticsinsight.net/top-progressive-companies-building-ethical-ai-to-look-out-for\u00ad\nin-2021/ https://www.technologyreview.com/2021/01/15/1016183/ai-ethics-startups/; Disha Sinha. Top", "9a5ca8f0-dd57-4b2c-8254-a84f977d0e34": "Progressive Companies Building Ethical AI to Look Out for in 2021. Analytics Insight. June 30, 2021.\n18. Office of Management and Budget. Study to Identify Methods to Assess Equity: Report to the President.\nAug. 2021. https://www.whitehouse.gov/wp-content/uploads/2021/08/OMB-Report-on-E013985\u00ad\nImplementation_508-Compliant-Secure-v1.1.pdf\n19. National Institute of Standards and Technology. AI Risk Management Framework. Accessed May 23,\n2022. https://www.nist.gov/itl/ai-risk-management-framework\n20. U.S. Department of Energy. U.S. Department of Energy Establishes Artificial Intelligence Advancement\nCouncil. U.S. Department of Energy Artificial Intelligence and Technology Office. April 18, 2022. https://", "2d4b9a5b-d031-4f72-8ebb-3fc4aa60a1c9": "www.energy.gov/ai/articles/us-department-energy-establishes-artificial-intelligence-advancement-council\n21. Department of Defense. U.S Department of Defense Responsible Artificial Intelligence Strategy and\nImplementation Pathway. Jun. 2022. https://media.defense.gov/2022/Jun/22/2003022604/-1/-1/0/\nDepartment-of-Defense-Responsible-Artificial-Intelligence-Strategy-and-Implementation\u00ad\nPathway.PDF\n22. Director of National Intelligence. Principles of Artificial Intelligence Ethics for the Intelligence\nCommunity. https://www.dni.gov/index.php/features/2763-principles-of-artificial-intelligence-ethics-for\u00ad\nthe-intelligence-community\n64", "36f37833-bacc-4484-bc9d-04c7dc93017a": "ENDNOTES\n23. National Science Foundation. National Artificial Intelligence Research Institutes. Accessed Sept. 12,\n2022. https://beta.nsf.gov/funding/opportunities/national-artificial-intelligence-research-institutes\n24. National Science Foundation. Cyber-Physical Systems. Accessed Sept. 12, 2022. https://beta.nsf.gov/\nfunding/opportunities/cyber-physical-systems-cps\n25. National Science Foundation. Secure and Trustworthy Cyberspace. Accessed Sept. 12, 2022. https://\nbeta.nsf.gov/funding/opportunities/secure-and-trustworthy-cyberspace-satc\n26. National Science Foundation. Formal Methods in the Field. Accessed Sept. 12, 2022. https://\nbeta.nsf.gov/funding/opportunities/formal-methods-field-fmitf", "9f1cc654-bfab-4767-ae0b-9ddde8438a98": "27. National Science Foundation. Designing Accountable Software Systems. Accessed Sept. 12, 2022.\nhttps://beta.nsf.gov/funding/opportunities/designing-accountable-software-systems-dass\n28. The Leadership Conference Education Fund. The Use Of Pretrial \u201cRisk Assessment\u201d Instruments: A\nShared Statement Of Civil Rights Concerns. Jul. 30, 2018. http://civilrightsdocs.info/pdf/criminal-justice/\nPretrial-Risk-Assessment-Short.pdf; https://civilrights.org/edfund/pretrial-risk-assessments/\n29. Idaho Legislature. House Bill 118. Jul. 1, 2019. https://legislature.idaho.gov/sessioninfo/2019/\nlegislation/H0118/\n30. See, e.g., Executive Office of the President. Big Data: A Report on Algorithmic Systems, Opportunity, and", "85fc5b68-07f0-4ca1-ba53-9f11d4d22521": "Civil Rights. May, 2016. https://obamawhitehouse.archives.gov/sites/default/files/microsites/\nostp/2016_0504_data_discrimination.pdf; Cathy O\u2019Neil. Weapons of Math Destruction. Penguin Books.\n2017. https://en.wikipedia.org/wiki/Weapons_of_Math_Destruction; Ruha Benjamin. Race After\nTechnology: Abolitionist Tools for the New Jim Code. Polity. 2019. https://www.ruhabenjamin.com/race\u00ad\nafter-technology\n31. See, e.g., Kashmir Hill. Another Arrest, and Jail Time, Due to a Bad Facial Recognition Match: A New\nJersey man was accused of shoplifting and trying to hit an officer with a car. He is the third known Black man\nto be wrongfully arrested based on face recognition. New York Times. Dec. 29, 2020, updated Jan. 6, 2021.", "01758ed1-699b-4a12-a34a-1e057238df65": "https://www.nytimes.com/2020/12/29/technology/facial-recognition-misidentify-jail.html; Khari\nJohnson. How Wrongful Arrests Based on AI Derailed 3 Men's Lives. Wired. Mar. 7, 2022. https://\nwww.wired.com/story/wrongful-arrests-ai-derailed-3-mens-lives/\n32. Student Borrower Protection Center. Educational Redlining. Student Borrower Protection Center\nReport. Feb. 2020. https://protectborrowers.org/wp-content/uploads/2020/02/Education-Redlining\u00ad\nReport.pdf\n33. Jeffrey Dastin. Amazon scraps secret AI recruiting tool that showed bias against women. Reuters. Oct.\n10, 2018. https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps\u00ad\nsecret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G", "f2bb2073-d674-4594-9bd1-f11d0f570c5f": "34. Todd Feathers. Major Universities Are Using Race as a \u201cHigh Impact Predictor\u201d of Student Success:\nStudents, professors, and education experts worry that that\u2019s pushing Black students in particular out of math\nand science. The Markup. Mar. 2, 2021. https://themarkup.org/machine-learning/2021/03/02/major\u00ad\nuniversities-are-using-race-as-a-high-impact-predictor-of-student-success\n65", "64af9c2b-78cf-4d88-9a22-f95aadd0f22b": "ENDNOTES\n35. Carrie Johnson. Flaws plague a tool meant to help low-risk federal prisoners win early release. NPR.\nJan. 26, 2022. https://www.npr.org/2022/01/26/1075509175/flaws-plague-a-tool-meant-to-help-low\u00ad\nrisk-federal-prisoners-win-early-release.; Carrie Johnson. Justice Department works to curb racial bias\nin deciding who's released from prison. NPR. Apr. 19, 2022. https://\nwww.npr.org/2022/04/19/1093538706/justice-department-works-to-curb-racial-bias-in-deciding\u00ad\nwhos-released-from-pris; National Institute of Justice. 2021 Review and Revalidation of the First Step Act\nRisk Assessment Tool. National Institute of Justice NCJ 303859. Dec., 2021. https://www.ojp.gov/\npdffiles1/nij/303859.pdf", "1272b39d-6e6d-47a2-b666-aa68ea0fe1e1": "36. Andrew Thompson. Google\u2019s Sentiment Analyzer Thinks Being Gay Is Bad. Vice. Oct. 25, 2017. https://\nwww.vice.com/en/article/j5jmj8/google-artificial-intelligence-bias\n37. Kaggle. Jigsaw Unintended Bias in Toxicity Classification: Detect toxicity across a diverse range of\nconversations. 2019. https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification\n38. Lucas Dixon, John Li, Jeffrey Sorensen, Nithum Thain, and Lucy Vasserman. Measuring and\nMitigating Unintended Bias in Text Classification. Proceedings of AAAI/ACM Conference on AI, Ethics,\nand Society. Feb. 2-3, 2018. https://dl.acm.org/doi/pdf/10.1145/3278721.3278729\n39. Paresh Dave. Google cuts racy results by 30% for searches like 'Latina teenager'. Reuters. Mar. 30,", "2c200e89-561c-4595-855d-6c138482ee24": "2022. https://www.reuters.com/technology/google-cuts-racy-results-by-30-searches-like-latina\u00ad\nteenager-2022-03-30/\n40. Safiya Umoja Noble. Algorithms of Oppression: How Search Engines Reinforce Racism. NYU Press.\nFeb. 2018. https://nyupress.org/9781479837243/algorithms-of-oppression/\n41. Paresh Dave. Google cuts racy results by 30% for searches like 'Latina teenager'. Reuters. Mar. 30,\n2022. https://www.reuters.com/technology/google-cuts-racy-results-by-30-searches-like-latina\u00ad\nteenager-2022-03-30/\n42. Miranda Bogen. All the Ways Hiring Algorithms Can Introduce Bias. Harvard Business Review. May\n6, 2019. https://hbr.org/2019/05/all-the-ways-hiring-algorithms-can-introduce-bias", "37101cb2-67a0-4069-a2dc-581286515834": "43. Arli Christian. Four Ways the TSA Is Making Flying Easier for Transgender People. American Civil\nLiberties Union. Apr. 5, 2022. https://www.aclu.org/news/lgbtq-rights/four-ways-the-tsa-is-making\u00ad\nflying-easier-for-transgender-people\n44. U.S. Transportation Security Administration. Transgender/ Non Binary / Gender Nonconforming\nPassengers. TSA. Accessed Apr. 21, 2022. https://www.tsa.gov/transgender-passengers\n45. See, e.g., National Disabled Law Students Association. Report on Concerns Regarding Online\nAdministration of Bar Exams. Jul. 29, 2020. https://ndlsa.org/wp-content/uploads/2020/08/\nNDLSA_Online-Exam-Concerns-Report1.pdf; Lydia X. Z. Brown. How Automated Test Proctoring", "b33cdf17-69bf-493f-a095-006e250f63ac": "Software Discriminates Against Disabled Students. Center for Democracy and Technology. Nov. 16, 2020.\nhttps://cdt.org/insights/how-automated-test-proctoring-software-discriminates-against-disabled\u00ad\nstudents/\n46. Ziad Obermeyer, et al., Dissecting racial bias in an algorithm used to manage the health of\npopulations, 366 Science (2019), https://www.science.org/doi/10.1126/science.aax2342.\n66", "1f95a910-874f-4ce5-9598-ae3c3a9f778a": "ENDNOTES\n47. Darshali A. Vyas et al., Hidden in Plain Sight \u2013 Reconsidering the Use of Race Correction in Clinical\nAlgorithms, 383 N. Engl. J. Med.874, 876-78 (Aug. 27, 2020), https://www.nejm.org/doi/full/10.1056/\nNEJMms2004740.\n48. The definitions of 'equity' and 'underserved communities' can be found in the Definitions section of\nthis framework as well as in Section 2 of The Executive Order On Advancing Racial Equity and Support\nfor Underserved Communities Through the Federal Government. https://www.whitehouse.gov/\nbriefing-room/presidential-actions/2021/01/20/executive-order-advancing-racial-equity-and-support\u00ad\nfor-underserved-communities-through-the-federal-government/\n49. Id.", "c3fa6ae1-d5cd-4e90-acfd-c200818d5b5c": "49. Id.\n50. Various organizations have offered proposals for how such assessments might be designed. See, e.g.,\nEmanuel Moss, Elizabeth Anne Watkins, Ranjit Singh, Madeleine Clare Elish, and Jacob Metcalf.\nAssembling Accountability: Algorithmic Impact Assessment for the Public Interest. Data & Society\nResearch Institute Report. June 29, 2021. https://datasociety.net/library/assembling-accountability\u00ad\nalgorithmic-impact-assessment-for-the-public-interest/; Nicol Turner Lee, Paul Resnick, and Genie\nBarton. Algorithmic bias detection and mitigation: Best practices and policies to reduce consumer harms.\nBrookings Report. May 22, 2019.\nhttps://www.brookings.edu/research/algorithmic-bias-detection-and-mitigation-best-practices-and\u00ad", "418543b2-ee33-4df9-8a3d-69789812a562": "policies-to-reduce-consumer-harms/; Andrew D. Selbst. An Institutional View Of Algorithmic Impact\nAssessments. Harvard Journal of Law & Technology. June 15, 2021. https://ssrn.com/abstract=3867634;\nDillon Reisman, Jason Schultz, Kate Crawford, and Meredith Whittaker. Algorithmic Impact\nAssessments: A Practical Framework for Public Agency Accountability. AI Now Institute Report. April\n2018. https://ainowinstitute.org/aiareport2018.pdf\n51. Department of Justice. Justice Department Announces New Initiative to Combat Redlining. Oct. 22,\n2021. https://www.justice.gov/opa/pr/justice-department-announces-new-initiative-combat-redlining\n52. PAVE Interagency Task Force on Property Appraisal and Valuation Equity. Action Plan to Advance", "6afdb57b-ab0b-405d-a19d-d7588ebf6bdd": "Property Appraisal and Valuation Equity: Closing the Racial Wealth Gap by Addressing Mis-valuations for\nFamilies and Communities of Color. March 2022. https://pave.hud.gov/sites/pave.hud.gov/files/\ndocuments/PAVEActionPlan.pdf\n53. U.S. Equal Employment Opportunity Commission. The Americans with Disabilities Act and the Use of\nSoftware, Algorithms, and Artificial Intelligence to Assess Job Applicants and Employees. EEOC\u00ad\nNVTA-2022-2. May 12, 2022. https://www.eeoc.gov/laws/guidance/americans-disabilities-act-and-use\u00ad\nsoftware-algorithms-and-artificial-intelligence; U.S. Department of Justice. Algorithms, Artificial\nIntelligence, and Disability Discrimination in Hiring. May 12, 2022. https://beta.ada.gov/resources/ai\u00ad\nguidance/", "41bf260e-3300-4502-8f29-e692ad5caf1f": "guidance/\n54. Ziad Obermeyer, Brian Powers, Christine Vogeli, and Sendhil Mullainathan. Dissecting racial bias in\nan algorithm used to manage the health of populations. Science. Vol. 366, No. 6464. Oct. 25, 2019. https://\nwww.science.org/doi/10.1126/science.aax2342\n55. Data & Trust Alliance. Algorithmic Bias Safeguards for Workforce: Overview. Jan. 2022. https://\ndataandtrustalliance.org/Algorithmic_Bias_Safeguards_for_Workforce_Overview.pdf\n56. Section 508.gov. IT Accessibility Laws and Policies. Access Board. https://www.section508.gov/\nmanage/laws-and-policies/\n67", "1394202f-d8a8-4e19-a59c-4c9f9fb6fb62": "ENDNOTES\n57. ISO Technical Management Board. ISO/IEC Guide 71:2014. Guide for addressing accessibility in\nstandards. International Standards Organization. 2021. https://www.iso.org/standard/57385.html\n58. World Wide Web Consortium. Web Content Accessibility Guidelines (WCAG) 2.0. Dec. 11, 2008.\nhttps://www.w3.org/TR/WCAG20/\n59. Reva Schwartz, Apostol Vassilev, Kristen Greene, Lori Perine, and Andrew Bert. NIST Special\nPublication 1270: Towards a Standard for Identifying and Managing Bias in Artificial Intelligence. The\nNational Institute of Standards and Technology. March, 2022. https://nvlpubs.nist.gov/nistpubs/\nSpecialPublications/NIST.SP.1270.pdf", "80f98fe0-e885-4096-8094-82b771b77ca2": "60. See, e.g., the 2014 Federal Trade Commission report \u201cData Brokers A Call for Transparency and\nAccountability\u201d. https://www.ftc.gov/system/files/documents/reports/data-brokers-call-transparency\u00ad\naccountability-report-federal-trade-commission-may-2014/140527databrokerreport.pdf\n61. See, e.g., Nir Kshetri. School surveillance of students via laptops may do more harm than good. The\nConversation. Jan. 21, 2022.\nhttps://theconversation.com/school-surveillance-of-students-via-laptops-may-do-more-harm-than\u00ad\ngood-170983; Matt Scherer. Warning: Bossware May be Hazardous to Your Health. Center for Democracy\n& Technology Report.\nhttps://cdt.org/wp-content/uploads/2021/07/2021-07-29-Warning-Bossware-May-Be-Hazardous-To\u00ad", "19273e70-0dc7-4d9e-80e4-8ebea56bf851": "Your-Health-Final.pdf; Human Impact Partners and WWRC. The Public Health Crisis Hidden in Amazon\nWarehouses. HIP and WWRC report. Jan. 2021.\nhttps://humanimpact.org/wp-content/uploads/2021/01/The-Public-Health-Crisis-Hidden-In-Amazon\u00ad\nWarehouses-HIP-WWRC-01-21.pdf; Drew Harwell. Contract lawyers face a growing invasion of\nsurveillance programs that monitor their work. The Washington Post. Nov. 11, 2021. https://\nwww.washingtonpost.com/technology/2021/11/11/lawyer-facial-recognition-monitoring/;\nVirginia Doellgast and Sean O'Brady. Making Call Center Jobs Better: The Relationship between\nManagement Practices and Worker Stress. A Report for the CWA. June 2020. https://\nhdl.handle.net/1813/74307", "67a09d8e-a68a-4757-8d72-0e3c9567a32d": "62. See, e.g., Federal Trade Commission. Data Brokers: A Call for Transparency and Accountability. May\n2014.\nhttps://www.ftc.gov/system/files/documents/reports/data-brokers-call-transparency-accountability\u00ad\nreport-federal-trade-commission-may-2014/140527databrokerreport.pdf; Cathy O\u2019Neil.\nWeapons of Math Destruction. Penguin Books. 2017.\nhttps://en.wikipedia.org/wiki/Weapons_of_Math_Destruction\n63. See, e.g., Rachel Levinson-Waldman, Harsha Pandurnga, and Faiza Patel. Social Media Surveillance by\nthe U.S. Government. Brennan Center for Justice. Jan. 7, 2022.\nhttps://www.brennancenter.org/our-work/research-reports/social-media-surveillance-us-government;", "457eaf9d-cc6d-407b-958d-241a13a65f47": "Shoshana Zuboff. The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of\nPower. Public Affairs. 2019.\n64. Angela Chen. Why the Future of Life Insurance May Depend on Your Online Presence. The Verge. Feb.\n7, 2019.\nhttps://www.theverge.com/2019/2/7/18211890/social-media-life-insurance-new-york-algorithms-big\u00ad\ndata-discrimination-online-records\n68", "2041aef2-054d-4b01-87dc-259c0b37dd04": "65. See, e.g., Scott Ikeda. Major Data Broker Exposes 235 Million Social Media Profiles in Data Lead: Info\nAppears to Have Been Scraped Without Permission. CPO Magazine. Aug. 28, 2020. https://\nwww.cpomagazine.com/cyber-security/major-data-broker-exposes-235-million-social-media-profiles\u00ad\nin-data-leak/; Lily Hay Newman. 1.2 Billion Records Found Exposed Online in a Single Server. WIRED,\nNov. 22, 2019. https://www.wired.com/story/billion-records-exposed-online/\n66. Lola Fadulu. Facial Recognition Technology in Public Housing Prompts Backlash. New York Times.\nSept. 24, 2019.\nhttps://www.nytimes.com/2019/09/24/us/politics/facial-recognition-technology-housing.html", "339a9678-f5f2-4f08-b4fc-72ba57bfa24e": "67. Jo Constantz. \u2018They Were Spying On Us\u2019: Amazon, Walmart, Use Surveillance Technology to Bust\nUnions. Newsweek. Dec. 13, 2021.\nhttps://www.newsweek.com/they-were-spying-us-amazon-walmart-use-surveillance-technology-bust\u00ad\nunions-1658603\n68. See, e.g., enforcement actions by the FTC against the photo storage app Everalbaum\n(https://www.ftc.gov/legal-library/browse/cases-proceedings/192-3172-everalbum-inc-matter), and\nagainst Weight Watchers and their subsidiary Kurbo\n(https://www.ftc.gov/legal-library/browse/cases-proceedings/1923228-weight-watchersww)\n69. See, e.g., HIPAA, Pub. L 104-191 (1996); Fair Debt Collection Practices Act (FDCPA), Pub. L. 95-109", "a3f392f6-8d4b-435c-a168-b6ed2284510f": "(1977); Family Educational Rights and Privacy Act (FERPA) (20 U.S.C. \u00a7 1232g), Children's Online\nPrivacy Protection Act of 1998, 15 U.S.C. 6501\u20136505, and Confidential Information Protection and\nStatistical Efficiency Act (CIPSEA) (116 Stat. 2899)\n70. Marshall Allen. You Snooze, You Lose: Insurers Make The Old Adage Literally True. ProPublica. Nov.\n21, 2018.\nhttps://www.propublica.org/article/you-snooze-you-lose-insurers-make-the-old-adage-literally-true\n71. Charles Duhigg. How Companies Learn Your Secrets. The New York Times. Feb. 16, 2012.\nhttps://www.nytimes.com/2012/02/19/magazine/shopping-habits.html\n72. Jack Gillum and Jeff Kao. Aggression Detectors: The Unproven, Invasive Surveillance Technology", "5cae1fe9-118c-44f9-8320-1a5b5b433a73": "Schools are Using to Monitor Students. ProPublica. Jun. 25, 2019.\nhttps://features.propublica.org/aggression-detector/the-unproven-invasive-surveillance-technology\u00ad\nschools-are-using-to-monitor-students/\n73. Drew Harwell. Cheating-detection companies made millions during the pandemic. Now students are\nfighting back. Washington Post. Nov. 12, 2020.\nhttps://www.washingtonpost.com/technology/2020/11/12/test-monitoring-student-revolt/\n74. See, e.g., Heather Morrison. Virtual Testing Puts Disabled Students at a Disadvantage. Government\nTechnology. May 24, 2022.\nhttps://www.govtech.com/education/k-12/virtual-testing-puts-disabled-students-at-a-disadvantage;", "60167c92-dbd2-494c-963b-3f31e181a800": "Lydia X. Z. Brown, Ridhi Shetty, Matt Scherer, and Andrew Crawford. Ableism And Disability\nDiscrimination In New Surveillance Technologies: How new surveillance technologies in education,\npolicing, health care, and the workplace disproportionately harm disabled people. Center for Democracy\nand Technology Report. May 24, 2022.\nhttps://cdt.org/insights/ableism-and-disability-discrimination-in-new-surveillance-technologies-how\u00ad\nnew-surveillance-technologies-in-education-policing-health-care-and-the-workplace\u00ad\ndisproportionately-harm-disabled-people/\n69", "30660f82-2d89-46a6-a3fd-3bf67a9776d4": "ENDNOTES\n75. See., e.g., Sam Sabin. Digital surveillance in a post-Roe world. Politico. May 5, 2022. https://\nwww.politico.com/newsletters/digital-future-daily/2022/05/05/digital-surveillance-in-a-post-roe\u00ad\nworld-00030459; Federal Trade Commission. FTC Sues Kochava for Selling Data that Tracks People at\nReproductive Health Clinics, Places of Worship, and Other Sensitive Locations. Aug. 29, 2022. https://\nwww.ftc.gov/news-events/news/press-releases/2022/08/ftc-sues-kochava-selling-data-tracks-people\u00ad\nreproductive-health-clinics-places-worship-other\n76. Todd Feathers. This Private Equity Firm Is Amassing Companies That Collect Data on America\u2019s\nChildren. The Markup. Jan. 11, 2022.", "caa96f9a-0685-47c7-ae68-743c98d7b0d3": "https://themarkup.org/machine-learning/2022/01/11/this-private-equity-firm-is-amassing-companies\u00ad\nthat-collect-data-on-americas-children\n77. Reed Albergotti. Every employee who leaves Apple becomes an \u2018associate\u2019: In job databases used by\nemployers to verify resume information, every former Apple employee\u2019s title gets erased and replaced with\na generic title. The Washington Post. Feb. 10, 2022.\nhttps://www.washingtonpost.com/technology/2022/02/10/apple-associate/\n78. National Institute of Standards and Technology. Privacy Framework Perspectives and Success\nStories. Accessed May 2, 2022.\nhttps://www.nist.gov/privacy-framework/getting-started-0/perspectives-and-success-stories", "117e0473-7d4a-4409-957e-4db24f4d0f1e": "79. ACLU of New York. What You Need to Know About New York\u2019s Temporary Ban on Facial\nRecognition in Schools. Accessed May 2, 2022.\nhttps://www.nyclu.org/en/publications/what-you-need-know-about-new-yorks-temporary-ban-facial\u00ad\nrecognition-schools\n80. New York State Assembly. Amendment to Education Law. Enacted Dec. 22, 2020.\nhttps://nyassembly.gov/leg/?default_fld=&leg_video=&bn=S05140&term=2019&Summary=Y&Text=Y\n81. U.S Department of Labor. Labor-Management Reporting and Disclosure Act of 1959, As Amended.\nhttps://www.dol.gov/agencies/olms/laws/labor-management-reporting-and-disclosure-act (Section\n203). See also: U.S Department of Labor. Form LM-10. OLMS Fact Sheet, Accessed May 2, 2022. https://", "1efaf9f1-7365-4988-8b93-849ff3a01745": "www.dol.gov/sites/dolgov/files/OLMS/regs/compliance/LM-10_factsheet.pdf\n82. See, e.g., Apple. Protecting the User\u2019s Privacy. Accessed May 2, 2022.\nhttps://developer.apple.com/documentation/uikit/protecting_the_user_s_privacy; Google Developers.\nDesign for Safety: Android is secure by default and private by design. Accessed May 3, 2022.\nhttps://developer.android.com/design-for-safety\n83. Karen Hao. The coming war on the hidden algorithms that trap people in poverty. MIT Tech Review.\nDec. 4, 2020.\nhttps://www.technologyreview.com/2020/12/04/1013068/algorithms-create-a-poverty-trap-lawyers\u00ad\nfight-back/\n84. Anjana Samant, Aaron Horowitz, Kath Xu, and Sophie Beiers. Family Surveillance by Algorithm.\nACLU. Accessed May 2, 2022.", "ffe4bd5e-e851-4131-bb3d-bafc8a9b19b5": "https://www.aclu.org/fact-sheet/family-surveillance-algorithm\n70", "c30675d3-1e25-4e33-8e63-3df8fa79b543": "ENDNOTES\n85. Mick Dumke and Frank Main. A look inside the watch list Chicago police fought to keep secret. The\nChicago Sun Times. May 18, 2017.\nhttps://chicago.suntimes.com/2017/5/18/18386116/a-look-inside-the-watch-list-chicago-police-fought\u00ad\nto-keep-secret\n86. Jay Stanley. Pitfalls of Artificial Intelligence Decisionmaking Highlighted In Idaho ACLU Case.\nACLU. Jun. 2, 2017.\nhttps://www.aclu.org/blog/privacy-technology/pitfalls-artificial-intelligence-decisionmaking\u00ad\nhighlighted-idaho-aclu-case\n87. Illinois General Assembly. Biometric Information Privacy Act. Effective Oct. 3, 2008.\nhttps://www.ilga.gov/legislation/ilcs/ilcs3.asp?ActID=3004&ChapterID=57\n88. Partnership on AI. ABOUT ML Reference Document. Accessed May 2, 2022.", "fb35d71d-76fe-4b4e-9e59-fb408612d321": "https://partnershiponai.org/paper/about-ml-reference-document/1/\n89. See, e.g., the model cards framework: Margaret Mitchell, Simone Wu, Andrew Zaldivar, Parker\nBarnes, Lucy Vasserman, Ben Hutchinson, Elena Spitzer, Inioluwa Deborah Raji, and Timnit Gebru.\nModel Cards for Model Reporting. In Proceedings of the Conference on Fairness, Accountability, and\nTransparency (FAT* '19). Association for Computing Machinery, New York, NY, USA, 220\u2013229. https://\ndl.acm.org/doi/10.1145/3287560.3287596\n90. Sarah Ammermann. Adverse Action Notice Requirements Under the ECOA and the FCRA. Consumer\nCompliance Outlook. Second Quarter 2013.\nhttps://consumercomplianceoutlook.org/2013/second-quarter/adverse-action-notice-requirements\u00ad\nunder-ecoa-fcra/", "de7bf04d-361d-4a01-8bf6-2acd9380375c": "under-ecoa-fcra/\n91. Federal Trade Commission. Using Consumer Reports for Credit Decisions: What to Know About\nAdverse Action and Risk-Based Pricing Notices. Accessed May 2, 2022.\nhttps://www.ftc.gov/business-guidance/resources/using-consumer-reports-credit-decisions-what\u00ad\nknow-about-adverse-action-risk-based-pricing-notices#risk\n92. Consumer Financial Protection Bureau. CFPB Acts to Protect the Public from Black-Box Credit\nModels Using Complex Algorithms. May 26, 2022.\nhttps://www.consumerfinance.gov/about-us/newsroom/cfpb-acts-to-protect-the-public-from-black\u00ad\nbox-credit-models-using-complex-algorithms/\n93. Anthony Zaller. California Passes Law Regulating Quotas In Warehouses \u2013 What Employers Need to", "5a612712-29fb-4831-9aff-aed10fd5c196": "Know About AB 701. Zaller Law Group California Employment Law Report. Sept. 24, 2021.\nhttps://www.californiaemploymentlawreport.com/2021/09/california-passes-law-regulating-quotas\u00ad\nin-warehouses-what-employers-need-to-know-about-ab-701/\n94. National Institute of Standards and Technology. AI Fundamental Research \u2013 Explainability.\nAccessed Jun. 4, 2022.\nhttps://www.nist.gov/artificial-intelligence/ai-fundamental-research-explainability\n95. DARPA. Explainable Artificial Intelligence (XAI). Accessed July 20, 2022.\nhttps://www.darpa.mil/program/explainable-artificial-intelligence\n71", "1f866a62-f886-473e-8beb-79265e963505": "ENDNOTES\n96. National Science Foundation. NSF Program on Fairness in Artificial Intelligence in Collaboration\nwith Amazon (FAI). Accessed July 20, 2022.\nhttps://www.nsf.gov/pubs/2021/nsf21585/nsf21585.htm\n97. Kyle Wiggers. Automatic signature verification software threatens to disenfranchise U.S. voters.\nVentureBeat. Oct. 25, 2020.\nhttps://venturebeat.com/2020/10/25/automatic-signature-verification-software-threatens-to\u00ad\ndisenfranchise-u-s-voters/\n98. Ballotpedia. Cure period for absentee and mail-in ballots. Article retrieved Apr 18, 2022.\nhttps://ballotpedia.org/Cure_period_for_absentee_and_mail-in_ballots\n99. Larry Buchanan and Alicia Parlapiano. Two of these Mail Ballot Signatures are by the Same Person.", "871dc8a3-6efc-48c6-bf23-e53aa58a51f9": "Which Ones? New York Times. Oct. 7, 2020.\nhttps://www.nytimes.com/interactive/2020/10/07/upshot/mail-voting-ballots-signature\u00ad\nmatching.html\n100. Rachel Orey and Owen Bacskai. The Low Down on Ballot Curing. Nov. 04, 2020.\nhttps://bipartisanpolicy.org/blog/the-low-down-on-ballot-curing/\n101. Andrew Kenney. 'I'm shocked that they need to have a smartphone': System for unemployment\nbenefits exposes digital divide. USA Today. May 2, 2021.\nhttps://www.usatoday.com/story/tech/news/2021/05/02/unemployment-benefits-system-leaving\u00ad\npeople-behind/4915248001/\n102. Allie Gross. UIA lawsuit shows how the state criminalizes the unemployed. Detroit Metro-Times.\nSep. 18, 2015.", "c301569e-1326-428a-8c93-19fe6cec8432": "Sep. 18, 2015.\nhttps://www.metrotimes.com/news/uia-lawsuit-shows-how-the-state-criminalizes-the\u00ad\nunemployed-2369412\n103. Maia Szalavitz. The Pain Was Unbearable. So Why Did Doctors Turn Her Away? Wired. Aug. 11,\n2021. https://www.wired.com/story/opioid-drug-addiction-algorithm-chronic-pain/\n104. Spencer Soper. Fired by Bot at Amazon: \"It's You Against the Machine\". Bloomberg, Jun. 28, 2021.\nhttps://www.bloomberg.com/news/features/2021-06-28/fired-by-bot-amazon-turns-to-machine\u00ad\nmanagers-and-workers-are-losing-out\n105. Definitions of \u2018equity\u2019 and \u2018underserved communities\u2019 can be found in the Definitions section of\nthis document as well as in Executive Order on Advancing Racial Equity and Support for Underserved", "e7997965-0254-4999-b856-0fd6a21cc5d0": "Communities Through the Federal Government:\nhttps://www.whitehouse.gov/briefing-room/presidential-actions/2021/01/20/executive-order\u00ad\nadvancing-racial-equity-and-support-for-underserved-communities-through-the-federal-government/\n106. HealthCare.gov. Navigator - HealthCare.gov Glossary. Accessed May 2, 2022.\nhttps://www.healthcare.gov/glossary/navigator/\n72", "d1337aff-43c1-45a4-9091-84095101cb65": "ENDNOTES\n107. Centers for Medicare & Medicaid Services. Biden-Harris Administration Quadruples the Number\nof Health Care Navigators Ahead of HealthCare.gov Open Enrollment Period. Aug. 27, 2021.\nhttps://www.cms.gov/newsroom/press-releases/biden-harris-administration-quadruples-number\u00ad\nhealth-care-navigators-ahead-healthcaregov-open\n108. See, e.g., McKinsey & Company. The State of Customer Care in 2022. July 8, 2022. https://\nwww.mckinsey.com/business-functions/operations/our-insights/the-state-of-customer-care-in-2022;\nSara Angeles. Customer Service Solutions for Small Businesses. Business News Daily.\nJun. 29, 2022. https://www.businessnewsdaily.com/7575-customer-service-solutions.html", "335c0645-b28f-4ced-9b6e-800aaae18c62": "109. Mike Hughes. Are We Getting The Best Out Of Our Bots? Co-Intelligence Between Robots &\nHumans. Forbes. Jul. 14, 2022.\nhttps://www.forbes.com/sites/mikehughes1/2022/07/14/are-we-getting-the-best-out-of-our-bots-co\u00ad\nintelligence-between-robots--humans/?sh=16a2bd207395\n110. Rachel Orey and Owen Bacskai. The Low Down on Ballot Curing. Nov. 04, 2020. https://\nbipartisanpolicy.org/blog/the-low-down-on-ballot-curing/; Zahavah Levine and Thea Raymond-\nSeidel. Mail Voting Litigation in 2020, Part IV: Verifying Mail Ballots. Oct. 29, 2020.\nhttps://www.lawfareblog.com/mail-voting-litigation-2020-part-iv-verifying-mail-ballots\n111. National Conference of State Legislatures. Table 15: States With Signature Cure Processes. Jan. 18,\n2022.", "929a108d-4fd7-4484-8efd-13d00b6dc989": "2022.\nhttps://www.ncsl.org/research/elections-and-campaigns/vopp-table-15-states-that-permit-voters-to\u00ad\ncorrect-signature-discrepancies.aspx\n112. White House Office of Science and Technology Policy. Join the Effort to Create A Bill of Rights for\nan Automated Society. Nov. 10, 2021.\nhttps://www.whitehouse.gov/ostp/news-updates/2021/11/10/join-the-effort-to-create-a-bill-of\u00ad\nrights-for-an-automated-society/\n113. White House Office of Science and Technology Policy. Notice of Request for Information (RFI) on\nPublic and Private Sector Uses of Biometric Technologies. Issued Oct. 8, 2021.\nhttps://www.federalregister.gov/documents/2021/10/08/2021-21975/notice-of-request-for\u00ad", "4ea3b58c-574b-473c-8a8c-5e4506a3ea43": "information-rfi-on-public-and-private-sector-uses-of-biometric-technologies\n114. National Artificial Intelligence Initiative Office. Public Input on Public and Private Sector Uses of\nBiometric Technologies. Accessed Apr. 19, 2022.\nhttps://www.ai.gov/86-fr-56300-responses/\n115. Thomas D. Olszewski, Lisa M. Van Pay, Javier F. Ortiz, Sarah E. Swiersz, and Laurie A. Dacus.\nSynopsis of Responses to OSTP\u2019s Request for Information on the Use and Governance of Biometric\nTechnologies in the Public and Private Sectors. Science and Technology Policy Institute. Mar. 2022.\nhttps://www.ida.org/-/media/feature/publications/s/sy/synopsis-of-responses-to-request-for\u00ad\ninformation-on-the-use-and-governance-of-biometric-technologies/ida-document-d-33070.ashx", "83d7842d-92fd-4896-8c9a-4e741273470f": "73", "91172346-fd8a-4b29-adf7-515e348a47cd": "NIST Trustworthy and Responsible AI  \nNIST AI 600-1 \nArtificial Intelligence Risk Management \nFramework: Generative Artificial \nIntelligence Profile \n \n \n \nThis publication is available free of charge from: \nhttps://doi.org/10.6028/NIST.AI.600-1", "a0a7c40d-a51f-4766-807d-1e94e0b84a77": "NIST Trustworthy and Responsible AI  \nNIST AI 600-1 \nArtificial Intelligence Risk Management \nFramework: Generative Artificial \nIntelligence Profile \n \n \n \nThis publication is available free of charge from: \nhttps://doi.org/10.6028/NIST.AI.600-1 \n \nJuly 2024 \n \n \n \n \nU.S. Department of Commerce  \nGina M. Raimondo, Secretary \nNational Institute of Standards and Technology  \nLaurie E. Locascio, NIST Director and Under Secretary of Commerce for Standards and Technology", "50863956-c8ba-4b76-8e9f-ed5aaad6d70c": "About AI at NIST: The National Institute of Standards and Technology (NIST) develops measurements, \ntechnology, tools, and standards to advance reliable, safe, transparent, explainable, privacy-enhanced, \nand fair arti\ufb01cial intelligence (AI) so that its full commercial and societal bene\ufb01ts can be realized without \nharm to people or the planet. NIST, which has conducted both fundamental and applied work on AI for \nmore than a decade, is also helping to ful\ufb01ll the 2023 Executive Order on Safe, Secure, and Trustworthy \nAI. NIST established the U.S. AI Safety Institute and the companion AI Safety Institute Consortium to \ncontinue the e\ufb00orts set in motion by the E.O. to build the science necessary for safe, secure, and", "fe0107a5-6633-4353-9f43-d4f162a7cf04": "trustworthy development and use of AI. \nAcknowledgments: This report was accomplished with the many helpful comments and contributions \nfrom the community, including the NIST Generative AI Public Working Group, and NIST sta\ufb00 and guest \nresearchers: Chloe Autio, Jesse Dunietz, Patrick Hall, Shomik Jain, Kamie Roberts, Reva Schwartz, Martin \nStanley, and Elham Tabassi. \nNIST Technical Series Policies \nCopyright, Use, and Licensing Statements \nNIST Technical Series Publication Identifier Syntax \nPublication History \nApproved by the NIST Editorial Review Board on 07-25-2024 \nContact Information \nai-inquiries@nist.gov \nNational Institute of Standards and Technology \nAttn: NIST AI Innovation Lab, Information Technology Laboratory", "778d5af1-9db8-46dd-bd57-1bb4a358dc31": "100 Bureau Drive (Mail Stop 8900) Gaithersburg, MD 20899-8900 \nAdditional Information \nAdditional information about this publication and other NIST AI publications are available at \nhttps://airc.nist.gov/Home. \n \nDisclaimer: Certain commercial entities, equipment, or materials may be identi\ufb01ed in this document in \norder to adequately describe an experimental procedure or concept. Such identi\ufb01cation is not intended to \nimply recommendation or endorsement by the National Institute of Standards and Technology, nor is it \nintended to imply that the entities, materials, or equipment are necessarily the best available for the \npurpose. Any mention of commercial, non-pro\ufb01t, academic partners, or their products, or references is", "83cceff9-b38e-4a3c-8695-acd37305c793": "for information only; it is not intended to imply endorsement or recommendation by any U.S. \nGovernment agency.", "22960e5d-cbad-404c-b7c0-9d316b4a4542": "Table of Contents \n1. \nIntroduction ..............................................................................................................................................1 \n2. \nOverview of Risks Unique to or Exacerbated by GAI .....................................................................2 \n3. \nSuggested Actions to Manage GAI Risks ......................................................................................... 12 \nAppendix A. Primary GAI Considerations ............................................................................................... 47 \nAppendix B. References ................................................................................................................................ 54", "ffda8e51-f721-48b7-8b1d-3456a25fa6a1": "1 \n1. \nIntroduction \nThis document is a cross-sectoral pro\ufb01le of and companion resource for the AI Risk Management \nFramework (AI RMF 1.0) for Generative AI,1 pursuant to President Biden\u2019s Executive Order (EO) 14110 on \nSafe, Secure, and Trustworthy Arti\ufb01cial Intelligence.2 The AI RMF was released in January 2023, and is \nintended for voluntary use and to improve the ability of organizations to incorporate trustworthiness \nconsiderations into the design, development, use, and evaluation of AI products, services, and systems.  \nA pro\ufb01le is an implementation of the AI RMF functions, categories, and subcategories for a speci\ufb01c \nsetting, application, or technology \u2013 in this case, Generative AI (GAI) \u2013 based on the requirements, risk", "a70912ca-1bdc-4cae-b938-e03d4b7a2e17": "tolerance, and resources of the Framework user. AI RMF pro\ufb01les assist organizations in deciding how to \nbest manage AI risks in a manner that is well-aligned with their goals, considers legal/regulatory \nrequirements and best practices, and re\ufb02ects risk management priorities. Consistent with other AI RMF \npro\ufb01les, this pro\ufb01le o\ufb00ers insights into how risk can be managed across various stages of the AI lifecycle \nand for GAI as a technology.  \nAs GAI covers risks of models or applications that can be used across use cases or sectors, this document \nis an AI RMF cross-sectoral pro\ufb01le. Cross-sectoral pro\ufb01les can be used to govern, map, measure, and", "c8e6a5ef-c53f-422b-8c75-0026f399106b": "manage risks associated with activities or business processes common across sectors, such as the use of \nlarge language models (LLMs), cloud-based services, or acquisition. \nThis document de\ufb01nes risks that are novel to or exacerbated by the use of GAI. After introducing and \ndescribing these risks, the document provides a set of suggested actions to help organizations govern, \nmap, measure, and manage these risks. \n \n \n1 EO 14110 de\ufb01nes Generative AI as \u201cthe class of AI models that emulate the structure and characteristics of input \ndata in order to generate derived synthetic content. This can include images, videos, audio, text, and other digital", "5ef3c350-ec64-4b02-9ace-127d8f1f8324": "content.\u201d While not all GAI is derived from foundation models, for purposes of this document, GAI generally refers \nto generative foundation models. The foundation model subcategory of \u201cdual-use foundation models\u201d is de\ufb01ned by \nEO 14110 as \u201can AI model that is trained on broad data; generally uses self-supervision; contains at least tens of \nbillions of parameters; is applicable across a wide range of contexts.\u201d  \n2 This pro\ufb01le was developed per Section 4.1(a)(i)(A) of EO 14110, which directs the Secretary of Commerce, acting \nthrough the Director of the National Institute of Standards and Technology (NIST), to develop a companion \nresource to the AI RMF, NIST AI 100\u20131, for generative AI.", "135b45e2-ccf1-4747-90fc-79a245039430": "2 \nThis work was informed by public feedback and consultations with diverse stakeholder groups as part of NIST\u2019s \nGenerative AI Public Working Group (GAI PWG). The GAI PWG was an open, transparent, and collaborative \nprocess, facilitated via a virtual workspace, to obtain multistakeholder input on GAI risk management and to \ninform NIST\u2019s approach. \nThe focus of the GAI PWG was limited to four primary considerations relevant to GAI: Governance, Content \nProvenance, Pre-deployment Testing, and Incident Disclosure (further described in Appendix A). As such, the \nsuggested actions in this document primarily address these considerations.", "0e85145d-5fa3-417e-808d-54610a5c18f3": "Future revisions of this pro\ufb01le will include additional AI RMF subcategories, risks, and suggested actions based \non additional considerations of GAI as the space evolves and empirical evidence indicates additional risks. A \nglossary of terms pertinent to GAI risk management will be developed and hosted on NIST\u2019s Trustworthy & \nResponsible AI Resource Center (AIRC), and added to The Language of Trustworthy AI: An In-Depth Glossary of \nTerms. \nThis document was also informed by public comments and consultations from several Requests for Information. \n \n2. \nOverview of Risks Unique to or Exacerbated by GAI \nIn the context of the AI RMF, risk refers to the composite measure of an event\u2019s probability (or", "8be765a1-29bb-4db2-8ff5-02aa5335f03e": "likelihood) of occurring and the magnitude or degree of the consequences of the corresponding event. \nSome risks can be assessed as likely to materialize in a given context, particularly those that have been \nempirically demonstrated in similar contexts. Other risks may be unlikely to materialize in a given \ncontext, or may be more speculative and therefore uncertain. \nAI risks can di\ufb00er from or intensify traditional software risks. Likewise, GAI can exacerbate existing AI \nrisks, and creates unique risks. GAI risks can vary along many dimensions: \n\u2022 \nStage of the AI lifecycle: Risks can arise during design, development, deployment, operation, \nand/or decommissioning. \n\u2022", "f3ea99ed-bd39-4d7e-9159-2ccfb1b50c4d": "\u2022 \nScope: Risks may exist at individual model or system levels, at the application or implementation \nlevels (i.e., for a speci\ufb01c use case), or at the ecosystem level \u2013 that is, beyond a single system or \norganizational context. Examples of the latter include the expansion of \u201calgorithmic \nmonocultures,3\u201d resulting from repeated use of the same model, or impacts on access to \nopportunity, labor markets, and the creative economies.4 \n\u2022 \nSource of risk: Risks may emerge from factors related to the design, training, or operation of the \nGAI model itself, stemming in some cases from GAI model or system inputs, and in other cases, \nfrom GAI system outputs. Many GAI risks, however, originate from human behavior, including", "778311b4-ae28-41bd-a3ed-d34844586897": "3 \u201cAlgorithmic monocultures\u201d refers to the phenomenon in which repeated use of the same model or algorithm in \nconsequential decision-making settings like employment and lending can result in increased susceptibility by \nsystems to correlated failures (like unexpected shocks), due to multiple actors relying on the same algorithm.  \n4 Many studies have projected the impact of AI on the workforce and labor markets. Fewer studies have examined \nthe impact of GAI on the labor market, though some industry surveys indicate that that both employees and \nemployers are pondering this disruption.", "6f491c10-2010-4536-8b18-8cc87c43620e": "3 \nthe abuse, misuse, and unsafe repurposing by humans (adversarial or not), and others result \nfrom interactions between a human and an AI system.  \n\u2022 \nTime scale: GAI risks may materialize abruptly or across extended periods. Examples include \nimmediate (and/or prolonged) emotional harm and potential risks to physical safety due to the \ndistribution of harmful deepfake images, or the long-term e\ufb00ect of disinformation on societal \ntrust in public institutions. \nThe presence of risks and where they fall along the dimensions above will vary depending on the \ncharacteristics of the GAI model, system, or use case at hand. These characteristics include but are not", "a695a967-93aa-47ea-be00-37580a0adb14": "limited to GAI model or system architecture, training mechanisms and libraries, data types used for \ntraining or \ufb01ne-tuning, levels of model access or availability of model weights, and application or use \ncase context. \nOrganizations may choose to tailor how they measure GAI risks based on these characteristics. They may \nadditionally wish to allocate risk management resources relative to the severity and likelihood of \nnegative impacts, including where and how these risks manifest, and their direct and material impacts \nharms in the context of GAI use. Mitigations for model or system level risks may di\ufb00er from mitigations \nfor use-case or ecosystem level risks.", "b06033c9-d4c8-4e7a-aa22-22a9bbc72ace": "Importantly, some GAI risks are unknown, and are therefore di\ufb03cult to properly scope or evaluate given \nthe uncertainty about potential GAI scale, complexity, and capabilities. Other risks may be known but \ndi\ufb03cult to estimate given the wide range of GAI stakeholders, uses, inputs, and outputs. Challenges with \nrisk estimation are aggravated by a lack of visibility into GAI training data, and the generally immature \nstate of the science of AI measurement and safety today. This document focuses on risks for which there \nis an existing empirical evidence base at the time this pro\ufb01le was written; for example, speculative risks \nthat may potentially arise in more advanced, future GAI systems are not considered. Future updates may", "405a360a-d099-4ca1-af06-5c08d9f5d64f": "incorporate additional risks or provide further details on the risks identi\ufb01ed below. \nTo guide organizations in identifying and managing GAI risks, a set of risks unique to or exacerbated by \nthe development and use of GAI are de\ufb01ned below.5 Each risk is labeled according to the outcome, \nobject, or source of the risk (i.e., some are risks \u201cto\u201d a subject or domain and others are risks \u201cof\u201d or \n\u201cfrom\u201d an issue or theme). These risks provide a lens through which organizations can frame and execute \nrisk management e\ufb00orts. To help streamline risk management e\ufb00orts, each risk is mapped in Section 3 \n(as well as in tables in Appendix B) to relevant Trustworthy AI Characteristics identi\ufb01ed in the AI RMF.", "9b34855e-aef0-4908-b7a1-634324a25e9a": "5 These risks can be further categorized by organizations depending on their unique approaches to risk de\ufb01nition \nand management. One possible way to further categorize these risks, derived in part from the UK\u2019s International \nScienti\ufb01c Report on the Safety of Advanced AI, could be: 1) Technical / Model risks (or risk from malfunction): \nConfabulation; Dangerous or Violent Recommendations; Data Privacy; Value Chain and Component Integration; \nHarmful Bias, and Homogenization; 2) Misuse by humans (or malicious use): CBRN Information or Capabilities; \nData Privacy; Human-AI Con\ufb01guration; Obscene, Degrading, and/or Abusive Content; Information Integrity;", "c3db2379-d822-4360-b5a8-dbbcaff89447": "Information Security; 3) Ecosystem / societal risks (or systemic risks): Data Privacy; Environmental; Intellectual \nProperty. We also note that some risks are cross-cutting between these categories.", "389d71c3-6613-4e7d-9d12-8f61150e6a57": "4 \n1. CBRN Information or Capabilities: Eased access to or synthesis of materially nefarious \ninformation or design capabilities related to chemical, biological, radiological, or nuclear (CBRN) \nweapons or other dangerous materials or agents. \n2. Confabulation: The production of con\ufb01dently stated but erroneous or false content (known \ncolloquially as \u201challucinations\u201d or \u201cfabrications\u201d) by which users may be misled or deceived.6 \n3. Dangerous, Violent, or Hateful Content: Eased production of and access to violent, inciting, \nradicalizing, or threatening content as well as recommendations to carry out self-harm or \nconduct illegal activities. Includes di\ufb03culty controlling public exposure to hateful and disparaging \nor stereotyping content.", "1a74427b-5479-4e89-8abb-c71ff8c57074": "4. Data Privacy: Impacts due to leakage and unauthorized use, disclosure, or de-anonymization of \nbiometric, health, location, or other personally identi\ufb01able information or sensitive data.7 \n5. Environmental Impacts: Impacts due to high compute resource utilization in training or \noperating GAI models, and related outcomes that may adversely impact ecosystems.  \n6. Harmful Bias or Homogenization: Ampli\ufb01cation and exacerbation of historical, societal, and \nsystemic biases; performance disparities8 between sub-groups or languages, possibly due to \nnon-representative training data, that result in discrimination, ampli\ufb01cation of biases, or \nincorrect presumptions about performance; undesired homogeneity that skews system or model", "7a511679-10b2-4427-90d9-ca4b329329d5": "outputs, which may be erroneous, lead to ill-founded decision-making, or amplify harmful \nbiases.  \n7. Human-AI Con\ufb01guration: Arrangements of or interactions between a human and an AI system \nwhich can result in the human inappropriately anthropomorphizing GAI systems or experiencing \nalgorithmic aversion, automation bias, over-reliance, or emotional entanglement with GAI \nsystems. \n8. Information Integrity: Lowered barrier to entry to generate and support the exchange and \nconsumption of content which may not distinguish fact from opinion or \ufb01ction or acknowledge \nuncertainties, or could be leveraged for large-scale dis- and mis-information campaigns.", "4ee64941-0e7a-42f7-ac71-696a24a49cf3": "9. Information Security: Lowered barriers for o\ufb00ensive cyber capabilities, including via automated \ndiscovery and exploitation of vulnerabilities to ease hacking, malware, phishing, o\ufb00ensive cyber \n \n \n6 Some commenters have noted that the terms \u201challucination\u201d and \u201cfabrication\u201d anthropomorphize GAI, which \nitself is a risk related to GAI systems as it can inappropriately attribute human characteristics to non-human \nentities.  \n7 What is categorized as sensitive data or sensitive PII can be highly contextual based on the nature of the \ninformation, but examples of sensitive information include information that relates to an information subject\u2019s \nmost intimate sphere, including political opinions, sex life, or criminal convictions.", "27c89c57-c154-4b04-b98c-a6fe5c7398b2": "8 The notion of harm presumes some baseline scenario that the harmful factor (e.g., a GAI model) makes worse. \nWhen the mechanism for potential harm is a disparity between groups, it can be di\ufb03cult to establish what the \nmost appropriate baseline is to compare against, which can result in divergent views on when a disparity between \nAI behaviors for di\ufb00erent subgroups constitutes a harm. In discussing harms from disparities such as biased \nbehavior, this document highlights examples where someone\u2019s situation is worsened relative to what it would have \nbeen in the absence of any AI system, making the outcome unambiguously a harm of the system.", "0dbc9c68-0788-4491-a0d0-afcb8ee2b6a2": "5 \noperations, or other cyberattacks; increased attack surface for targeted cyberattacks, which may \ncompromise a system\u2019s availability or the con\ufb01dentiality or integrity of training data, code, or \nmodel weights.  \n10. Intellectual Property: Eased production or replication of alleged copyrighted, trademarked, or \nlicensed content without authorization (possibly in situations which do not fall under fair use); \neased exposure of trade secrets; or plagiarism or illegal replication.  \n11. Obscene, Degrading, and/or Abusive Content: Eased production of and access to obscene, \ndegrading, and/or abusive imagery which can cause harm, including synthetic child sexual abuse \nmaterial (CSAM), and nonconsensual intimate images (NCII) of adults.", "d3c6cf0b-a630-4376-aa31-9051595a4683": "12. Value Chain and Component Integration: Non-transparent or untraceable integration of \nupstream third-party components, including data that has been improperly obtained or not \nprocessed and cleaned due to increased automation from GAI; improper supplier vetting across \nthe AI lifecycle; or other issues that diminish transparency or accountability for downstream \nusers. \n2.1. CBRN Information or Capabilities \nIn the future, GAI may enable malicious actors to more easily access CBRN weapons and/or relevant \nknowledge, information, materials, tools, or technologies that could be misused to assist in the design, \ndevelopment, production, or use of CBRN weapons or other dangerous materials or agents. While", "9d76471d-3a9f-439c-a426-abc2987358ad": "relevant biological and chemical threat knowledge and information is often publicly accessible, LLMs \ncould facilitate its analysis or synthesis, particularly by individuals without formal scienti\ufb01c training or \nexpertise.  \nRecent research on this topic found that LLM outputs regarding biological threat creation and attack \nplanning provided minimal assistance beyond traditional search engine queries, suggesting that state-of-\nthe-art LLMs at the time these studies were conducted do not substantially increase the operational \nlikelihood of such an attack. The physical synthesis development, production, and use of chemical or \nbiological agents will continue to require both applicable expertise and supporting materials and", "ef0a2737-25f6-4f88-87ac-9bdf68d40eb5": "infrastructure. The impact of GAI on chemical or biological agent misuse will depend on what the key \nbarriers for malicious actors are (e.g., whether information access is one such barrier), and how well GAI \ncan help actors address those barriers.  \nFurthermore, chemical and biological design tools (BDTs) \u2013 highly specialized AI systems trained on \nscienti\ufb01c data that aid in chemical and biological design \u2013 may augment design capabilities in chemistry \nand biology beyond what text-based LLMs are able to provide. As these models become more \ne\ufb03cacious, including for bene\ufb01cial uses, it will be important to assess their potential to be used for \nharm, such as the ideation and design of novel harmful chemical or biological agents.", "a2811877-bb7f-4a73-abe3-45b9cc5c240e": "While some of these described capabilities lie beyond the reach of existing GAI tools, ongoing \nassessments of this risk would be enhanced by monitoring both the ability of AI tools to facilitate CBRN \nweapons planning and GAI systems\u2019 connection or access to relevant data and tools. \nTrustworthy AI Characteristic: Safe, Explainable and Interpretable", "b7581976-f63a-42b4-8001-1f6c4b65ceb7": "6 \n2.2. Confabulation \n\u201cConfabulation\u201d refers to a phenomenon in which GAI systems generate and con\ufb01dently present \nerroneous or false content in response to prompts. Confabulations also include generated outputs that \ndiverge from the prompts or other input or that contradict previously generated statements in the same \ncontext. These phenomena are colloquially also referred to as \u201challucinations\u201d or \u201cfabrications.\u201d \nConfabulations can occur across GAI outputs and contexts.9,10 Confabulations are a natural result of the \nway generative models are designed: they generate outputs that approximate the statistical distribution \nof their training data; for example, LLMs predict the next token or word in a sentence or phrase. While", "015ec0fb-9137-4c2e-8b37-f6b91ecd3a8c": "such statistical prediction can produce factually accurate and consistent outputs, it can also produce \noutputs that are factually inaccurate or internally inconsistent. This dynamic is particularly relevant when \nit comes to open-ended prompts for long-form responses and in domains which require highly \ncontextual and/or domain expertise.  \nRisks from confabulations may arise when users believe false content \u2013 often due to the con\ufb01dent nature \nof the response \u2013 leading users to act upon or promote the false information. This poses a challenge for \nmany real-world applications, such as in healthcare, where a confabulated summary of patient \ninformation reports could cause doctors to make incorrect diagnoses and/or recommend the wrong", "f56cc5c5-251d-4ac9-b4ab-4ed404c20012": "treatments. Risks of confabulated content may be especially important to monitor when integrating GAI \ninto applications involving consequential decision making. \nGAI outputs may also include confabulated logic or citations that purport to justify or explain the \nsystem\u2019s answer, which may further mislead humans into inappropriately trusting the system\u2019s output. \nFor instance, LLMs sometimes provide logical steps for how they arrived at an answer even when the \nanswer itself is incorrect. Similarly, an LLM could falsely assert that it is human or has human traits, \npotentially deceiving humans into believing they are speaking with another human.", "f1b8262d-b5ef-4dba-90c1-578234592c3e": "The extent to which humans can be deceived by LLMs, the mechanisms by which this may occur, and the \npotential risks from adversarial prompting of such behavior are emerging areas of study. Given the wide \nrange of downstream impacts of GAI, it is di\ufb03cult to estimate the downstream scale and impact of \nconfabulations. \nTrustworthy AI Characteristics: Fair with Harmful Bias Managed, Safe, Valid and Reliable, Explainable \nand Interpretable \n2.3. Dangerous, Violent, or Hateful Content \nGAI systems can produce content that is inciting, radicalizing, or threatening, or that glori\ufb01es violence, \nwith greater ease and scale than other technologies. LLMs have been reported to generate dangerous or", "8ab603b4-0897-49d1-a797-66e7d7c5e904": "violent recommendations, and some models have generated actionable instructions for dangerous or \n \n \n9 Confabulations of falsehoods are most commonly a problem for text-based outputs; for audio, image, or video \ncontent, creative generation of non-factual content can be a desired behavior.  \n10 For example, legal confabulations have been shown to be pervasive in current state-of-the-art LLMs. See also, \ne.g.,", "996f1e36-148d-4204-9c38-fa728560b7fd": "7 \nunethical behavior. Text-to-image models also make it easy to create images that could be used to \npromote dangerous or violent messages. Similar concerns are present for other GAI media, including \nvideo and audio. GAI may also produce content that recommends self-harm or criminal/illegal activities.  \nMany current systems restrict model outputs to limit certain content or in response to certain prompts, \nbut this approach may still produce harmful recommendations in response to other less-explicit, novel \nprompts (also relevant to CBRN Information or Capabilities, Data Privacy, Information Security, and \nObscene, Degrading and/or Abusive Content). Crafting such prompts deliberately is known as", "66967d52-c7b1-4982-9f9a-717d4df482d4": "\u201cjailbreaking,\u201d or, manipulating prompts to circumvent output controls. Limitations of GAI systems can be \nharmful or dangerous in certain contexts. Studies have observed that users may disclose mental health \nissues in conversations with chatbots \u2013 and that users exhibit negative reactions to unhelpful responses \nfrom these chatbots during situations of distress. \nThis risk encompasses di\ufb03culty controlling creation of and public exposure to o\ufb00ensive or hateful \nlanguage, and denigrating or stereotypical content generated by AI. This kind of speech may contribute \nto downstream harm such as fueling dangerous or violent behaviors. The spread of denigrating or", "544c807e-98c9-4d9d-a0cb-faa47055f69f": "stereotypical content can also further exacerbate representational harms (see Harmful Bias and \nHomogenization below).  \nTrustworthy AI Characteristics: Safe, Secure and Resilient \n2.4. Data Privacy \nGAI systems raise several risks to privacy. GAI system training requires large volumes of data, which in \nsome cases may include personal data. The use of personal data for GAI training raises risks to widely \naccepted privacy principles, including to transparency, individual participation (including consent), and \npurpose speci\ufb01cation. For example, most model developers do not disclose speci\ufb01c data sources on \nwhich models were trained, limiting user awareness of whether personally identi\ufb01ably information (PII)", "4c2ca60d-29b9-47ab-9b1c-b9aba2f7547c": "was trained on and, if so, how it was collected.  \nModels may leak, generate, or correctly infer sensitive information about individuals. For example, \nduring adversarial attacks, LLMs have revealed sensitive information (from the public domain) that was \nincluded in their training data. This problem has been referred to as data memorization, and may pose \nexacerbated privacy risks even for data present only in a small number of training samples.  \nIn addition to revealing sensitive information in GAI training data, GAI models may be able to correctly \ninfer PII or sensitive data that was not in their training data nor disclosed by the user by stitching", "957dafe8-ccf7-4b5d-8887-6625c5cf9503": "together information from disparate sources. These inferences can have negative impact on an individual \neven if the inferences are not accurate (e.g., confabulations), and especially if they reveal information \nthat the individual considers sensitive or that is used to disadvantage or harm them. \nBeyond harms from information exposure (such as extortion or dignitary harm), wrong or inappropriate \ninferences of PII can contribute to downstream or secondary harmful impacts. For example, predictive \ninferences made by GAI models based on PII or protected attributes can contribute to adverse decisions, \nleading to representational or allocative harms to individuals or groups (see Harmful Bias and \nHomogenization below).", "ec56134e-1995-47e0-bcc1-3e00a48d2229": "8 \nTrustworthy AI Characteristics: Accountable and Transparent, Privacy Enhanced, Safe, Secure and \nResilient \n2.5. Environmental Impacts \nTraining, maintaining, and operating (running inference on) GAI systems are resource-intensive activities, \nwith potentially large energy and environmental footprints. Energy and carbon emissions vary based on \nwhat is being done with the GAI model (i.e., pre-training, \ufb01ne-tuning, inference), the modality of the \ncontent, hardware used, and type of task or application. \nCurrent estimates suggest that training a single transformer LLM can emit as much carbon as 300 round-\ntrip \ufb02ights between San Francisco and New York. In a study comparing energy consumption and carbon", "e4d77a78-ba19-4954-be88-77c5b4430a07": "emissions for LLM inference, generative tasks (e.g., text summarization) were found to be more energy- \nand carbon-intensive than discriminative or non-generative tasks (e.g., text classi\ufb01cation).  \nMethods for creating smaller versions of trained models, such as model distillation or compression, \ncould reduce environmental impacts at inference time, but training and tuning such models may still \ncontribute to their environmental impacts. Currently there is no agreed upon method to estimate \nenvironmental impacts from GAI.  \nTrustworthy AI Characteristics: Accountable and Transparent, Safe \n2.6. Harmful Bias and Homogenization \nBias exists in many forms and can become ingrained in automated systems. AI systems, including GAI", "559da222-4baa-47b5-b46b-313d111febae": "systems, can increase the speed and scale at which harmful biases manifest and are acted upon, \npotentially perpetuating and amplifying harms to individuals, groups, communities, organizations, and \nsociety. For example, when prompted to generate images of CEOs, doctors, lawyers, and judges, current \ntext-to-image models underrepresent women and/or racial minorities, and people with disabilities. \nImage generator models have also produced biased or stereotyped output for various demographic \ngroups and have di\ufb03culty producing non-stereotyped content even when the prompt speci\ufb01cally \nrequests image features that are inconsistent with the stereotypes. Harmful bias in GAI models, which", "808e8fff-15a9-413c-8917-37b3aac27c73": "may stem from their training data, can also cause representational harms or perpetuate or exacerbate \nbias based on race, gender, disability, or other protected classes.  \nHarmful bias in GAI systems can also lead to harms via disparities between how a model performs for \ndi\ufb00erent subgroups or languages (e.g., an LLM may perform less well for non-English languages or \ncertain dialects). Such disparities can contribute to discriminatory decision-making or ampli\ufb01cation of \nexisting societal biases. In addition, GAI systems may be inappropriately trusted to perform similarly \nacross all subgroups, which could leave the groups facing underperformance with worse outcomes than", "3674534d-fa75-4343-8c4e-ca172de56870": "if no GAI system were used. Disparate or reduced performance for lower-resource languages also \npresents challenges to model adoption, inclusion, and accessibility, and may make preservation of \nendangered languages more di\ufb03cult if GAI systems become embedded in everyday processes that would \notherwise have been opportunities to use these languages.  \nBias is mutually reinforcing with the problem of undesired homogenization, in which GAI systems \nproduce skewed distributions of outputs that are overly uniform (for example, repetitive aesthetic styles", "94f08b11-e4ad-415e-891d-5136f266d96e": "9 \nand reduced content diversity). Overly homogenized outputs can themselves be incorrect, or they may \nlead to unreliable decision-making or amplify harmful biases. These phenomena can \ufb02ow from \nfoundation models to downstream models and systems, with the foundation models acting as \n\u201cbottlenecks,\u201d or single points of failure.  \nOverly homogenized content can contribute to \u201cmodel collapse.\u201d Model collapse can occur when model \ntraining over-relies on synthetic data, resulting in data points disappearing from the distribution of the \nnew model\u2019s outputs. In addition to threatening the robustness of the model overall, model collapse \ncould lead to homogenized outputs, including by amplifying any homogenization from the model used to", "99c80147-6176-4789-97db-30a485a9d898": "generate the synthetic training data. \nTrustworthy AI Characteristics: Fair with Harmful Bias Managed, Valid and Reliable \n2.7. Human-AI Con\ufb01guration \nGAI system use can involve varying risks of miscon\ufb01gurations and poor interactions between a system \nand a human who is interacting with it. Humans bring their unique perspectives, experiences, or domain-\nspeci\ufb01c expertise to interactions with AI systems but may not have detailed knowledge of AI systems and \nhow they work. As a result, human experts may be unnecessarily \u201caverse\u201d to GAI systems, and thus \ndeprive themselves or others of GAI\u2019s bene\ufb01cial uses.  \nConversely, due to the complexity and increasing reliability of GAI technology, over time, humans may", "d78354fd-3d5f-4a3c-9bf2-99ef005bf7ec": "over-rely on GAI systems or may unjusti\ufb01ably perceive GAI content to be of higher quality than that \nproduced by other sources. This phenomenon is an example of automation bias, or excessive deference \nto automated systems. Automation bias can exacerbate other risks of GAI, such as risks of confabulation \nor risks of bias or homogenization. \nThere may also be concerns about emotional entanglement between humans and GAI systems, which \ncould lead to negative psychological impacts. \nTrustworthy AI Characteristics: Accountable and Transparent, Explainable and Interpretable, Fair with \nHarmful Bias Managed, Privacy Enhanced, Safe, Valid and Reliable \n2.8. Information Integrity"}}